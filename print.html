<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>BPC-PRP - Practical Robotics and Computer Vision</title>
                <meta name="robots" content="noindex" />
                

        <!-- Custom HTML head -->
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="favicon.svg">
                        <link rel="shortcut icon" href="favicon.png">
                <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
                <link rel="stylesheet" href="css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="title-page.html">Introduction</a></li><li class="chapter-item expanded "><a href="1_lectures/text/intro.html"><strong aria-hidden="true">1.</strong> Lectures</a></li><li class="chapter-item expanded "><a href="2_labs/text/intro.html"><strong aria-hidden="true">2.</strong> Labs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="2_labs/text/1_lab.html"><strong aria-hidden="true">2.1.</strong> Lab 1 - Introduction &amp; Linux Installation</a></li><li class="chapter-item expanded "><a href="2_labs/text/2_lab.html"><strong aria-hidden="true">2.2.</strong> Lab 2 - IDE, C++ &amp; CMake</a></li><li class="chapter-item expanded "><a href="2_labs/text/3_lab.html"><strong aria-hidden="true">2.3.</strong> Lab 3 - Git &amp; C++ Project Template</a></li><li class="chapter-item expanded "><a href="2_labs/text/4_lab.html"><strong aria-hidden="true">2.4.</strong> Lab 4 - Data Capture &amp; Visualization (ROS)</a></li><li class="chapter-item expanded "><a href="2_labs/text/5_lab.html"><strong aria-hidden="true">2.5.</strong> Lab 5 - Motor, Kinematics &amp; Gamepad</a></li><li class="chapter-item expanded "><a href="2_labs/text/6_lab.html"><strong aria-hidden="true">2.6.</strong> Lab 6 - Line Estimation</a></li><li class="chapter-item expanded "><a href="2_labs/text/7_lab.html"><strong aria-hidden="true">2.7.</strong> Lab 7 - Line Following &amp; PID</a></li><li class="chapter-item expanded "><a href="2_labs/text/8_lab.html"><strong aria-hidden="true">2.8.</strong> Lab 8 - Exam (Line Following)</a></li><li class="chapter-item expanded "><a href="2_labs/text/9_lab.html"><strong aria-hidden="true">2.9.</strong> Lab 9 - Obstacle Detection &amp; Corridor Following</a></li><li class="chapter-item expanded "><a href="2_labs/text/10_lab.html"><strong aria-hidden="true">2.10.</strong> Lab 10 - Orientation-Aware Corridor Navigation</a></li><li class="chapter-item expanded "><a href="2_labs/text/11_lab.html"><strong aria-hidden="true">2.11.</strong> Lab 11 - Camera Data Processing</a></li><li class="chapter-item expanded "><a href="2_labs/text/12_lab.html"><strong aria-hidden="true">2.12.</strong> Lab 12 - Exam (Corridor Following)</a></li><li class="chapter-item expanded "><a href="2_labs/text/13_exam.html"><strong aria-hidden="true">2.13.</strong> Main Exam - Maze Escape</a></li></ol></li><li class="chapter-item expanded "><a href="3_navigation/text/intro.html"><strong aria-hidden="true">3.</strong> Robotic Topics</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="3_navigation/text/1_differential_chassis.html"><strong aria-hidden="true">3.1.</strong> Differential Chassis</a></li><li class="chapter-item expanded "><a href="3_navigation/text/2_pid.html"><strong aria-hidden="true">3.2.</strong> PID</a></li><li class="chapter-item expanded "><a href="3_navigation/text/3_line_following.html"><strong aria-hidden="true">3.3.</strong> Line Following</a></li><li class="chapter-item expanded "><a href="3_navigation/text/4_corridor_following.html"><strong aria-hidden="true">3.4.</strong> Corridor Following</a></li><li class="chapter-item expanded "><a href="3_navigation/text/5_imu.html"><strong aria-hidden="true">3.5.</strong> IMU</a></li><li class="chapter-item expanded "><a href="3_navigation/text/6_maze_escape.html"><strong aria-hidden="true">3.6.</strong> Maze Escape</a></li></ol></li><li class="chapter-item expanded "><a href="4_others/text/intro.html"><strong aria-hidden="true">4.</strong> Others</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="4_others/text/1_linux.html"><strong aria-hidden="true">4.1.</strong> Linux</a></li><li class="chapter-item expanded "><a href="4_others/text/2_cpp.html"><strong aria-hidden="true">4.2.</strong> C++</a></li><li class="chapter-item expanded "><a href="4_others/text/7_cmake.html"><strong aria-hidden="true">4.3.</strong> CMake</a></li><li class="chapter-item expanded "><a href="4_others/text/3_git.html"><strong aria-hidden="true">4.4.</strong> Git</a></li><li class="chapter-item expanded "><a href="4_others/text/4_clion.html"><strong aria-hidden="true">4.5.</strong> CLion</a></li><li class="chapter-item expanded "><a href="4_others/text/8_multithreading.html"><strong aria-hidden="true">4.6.</strong> Multithreading</a></li><li class="chapter-item expanded "><a href="4_others/text/9_rviz2_visualizations.html"><strong aria-hidden="true">4.7.</strong> RViz2 Visualizations</a></li><li class="chapter-item expanded "><a href="4_others/text/10_coordinate_system.html"><strong aria-hidden="true">4.8.</strong> Coordinate Systems</a></li><li class="chapter-item expanded "><a href="4_others/text/11_communication_buses.html"><strong aria-hidden="true">4.9.</strong> Communication Buses</a></li><li class="chapter-item expanded "><a href="4_others/text/12_ubuntu_environment.html"><strong aria-hidden="true">4.10.</strong> Ubuntu Environment</a></li></ol></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">BPC-PRP - Practical Robotics and Computer Vision</h1>

                    <div class="right-buttons">
                                                <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="practical-robotics-and-computer-vision-bpc-prp"><a class="header" href="#practical-robotics-and-computer-vision-bpc-prp">Practical Robotics and Computer Vision (BPC-PRP)</a></h1>
<h2 id="authors"><a class="header" href="#authors">Authors</a></h2>
<ul>
<li>Ing. Adam Ligocki, Ph.D.</li>
<li>...</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lectures"><a class="header" href="#lectures">Lectures</a></h1>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<h3 id="week-1---course-introduction"><a class="header" href="#week-1---course-introduction">Week 1 - Course Introduction</a></h3>
<ul>
<li>Course introductions</li>
<li>Teachers</li>
<li>Organization</li>
<li>Tests &amp; Final Exam overview</li>
</ul>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<h3 id="week-2---linux-os-c-cmake-unit-tests"><a class="header" href="#week-2---linux-os-c-cmake-unit-tests">Week 2 - Linux OS, C++, CMake, Unit Tests</a></h3>
<ul>
<li>Linux OS overview, command line interface, basic programs</li>
<li>Compiling simple program using Gcc</li>
<li>Simple CMake project</li>
<li>Unit tests</li>
</ul>
<p>Responsible: Ing. Jakub Minařík</p>
<h3 id="week-3---git"><a class="header" href="#week-3---git">Week 3 - Git</a></h3>
<ul>
<li>Git basics</li>
<li>Online git services</li>
<li>Code quality (formating, static analysis, ...)</li>
</ul>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<h3 id="week-4---ros2-basics"><a class="header" href="#week-4---ros2-basics">Week 4 - ROS2 Basics</a></h3>
<ul>
<li>Elementary concepts of ROS2</li>
<li>RViz</li>
</ul>
<p>Responsible: Ing. Jakub Minařík</p>
<h3 id="week-5---kinematics--odometry"><a class="header" href="#week-5---kinematics--odometry">Week 5 - Kinematics &amp; Odometry</a></h3>
<ul>
<li>Differential chassis</li>
<li>Wheel Odometry</li>
</ul>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<h3 id="week-6---line-detection--estimation"><a class="header" href="#week-6---line-detection--estimation">Week 6 - Line Detection &amp; Estimation</a></h3>
<ul>
<li>Line sensor</li>
<li>Differential sensor</li>
<li>Line distance estimation</li>
</ul>
<p>Responsible: Ing. Petr Šopák</p>
<h3 id="week-7---control-loop"><a class="header" href="#week-7---control-loop">Week 7 - Control Loop</a></h3>
<ul>
<li>Line following principles</li>
<li>Bang-bang controller</li>
<li>PID controller</li>
</ul>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<h3 id="week-8---ros2-advanced"><a class="header" href="#week-8---ros2-advanced">Week 8 - ROS2 Advanced</a></h3>
<ul>
<li>DDS, node discovery</li>
<li>launch system</li>
<li>Visualization (markers, TFs, URDF, ...)</li>
<li>Gazebo
Responsible: Ing. Jakub Minařík</li>
</ul>
<h3 id="week-9---robots-sensory-equipment"><a class="header" href="#week-9---robots-sensory-equipment">Week 9 - Robot's Sensory Equipment</a></h3>
<ul>
<li>Understanding full range of robot's sensors</li>
<li>Deep dive into robot's architecture</li>
</ul>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<h3 id="week-10---computer-vision-1"><a class="header" href="#week-10---computer-vision-1">Week 10 - Computer Vision 1</a></h3>
<ul>
<li>CV overview</li>
<li>Bacis algorithms</li>
<li>Image sensors</li>
<li>RPi &amp; Camera</li>
</ul>
<p>Responsible: Ing. Petr Šopák</p>
<h3 id="week-11---computer-vision-2"><a class="header" href="#week-11---computer-vision-2">Week 11 - Computer Vision 2</a></h3>
<ul>
<li>OpenCV usage</li>
<li>ArUco Detection</li>
</ul>
<p>Responsible: Ing. Petr Šopák</p>
<h3 id="week-12---substitute-lecture"><a class="header" href="#week-12---substitute-lecture">Week 12 - Substitute Lecture</a></h3>
<ul>
<li>Content to be announced later</li>
</ul>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<h3 id="exam-period---final-exam"><a class="header" href="#exam-period---final-exam">Exam Period - Final Exam</a></h3>
<ul>
<li>a</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="laboratories"><a class="header" href="#laboratories">Laboratories</a></h1>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<h3 id="lab-1---laboratory-introduction--linux"><a class="header" href="#lab-1---laboratory-introduction--linux">Lab 1 - Laboratory Introduction &amp; Linux</a></h3>
<ul>
<li>Introduction to laboratory</li>
<li>Linux installation</li>
<li>Linuc Command Line Interface (CLI)</li>
</ul>
<p>Responsible: Ing. Jakub Minařík</p>
<h3 id="lab-2---c-cmake--ide"><a class="header" href="#lab-2---c-cmake--ide">Lab 2 - C++, CMake &amp; IDE</a></h3>
<ul>
<li>C++ Review</li>
<li>CLI compilation</li>
<li>Simple CMake project</li>
<li>Unit tests</li>
</ul>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<h3 id="lab-3---git--c-project-template"><a class="header" href="#lab-3---git--c-project-template">Lab 3 - Git &amp; C++ Project Template</a></h3>
<ul>
<li>Git Basics and workflow</li>
<li>Online repository</li>
<li>Course project template</li>
</ul>
<p>Responsible: Ing. Jakub Minařík</p>
<h3 id="lab-4---data-capture--visualization-ros"><a class="header" href="#lab-4---data-capture--visualization-ros">Lab 4 - Data Capture &amp; Visualization (ROS)</a></h3>
<ul>
<li>ROS2 in CLI</li>
<li>Simple Node, Publisher, Subscriber</li>
<li>RViz, Data Visualization</li>
</ul>
<p>Responsible: Ing. Petr Šopák</p>
<h3 id="lab-5---motor-kinematics--gamepad"><a class="header" href="#lab-5---motor-kinematics--gamepad">Lab 5 - Motor, Kinematics &amp; Gamepad</a></h3>
<ul>
<li>Motor Control</li>
<li>Forward and Inverse Kinematics</li>
<li>Gamepad</li>
</ul>
<p>Responsible: Ing. Jakub Minařík</p>
<h3 id="lab-6---line-estimation"><a class="header" href="#lab-6---line-estimation">Lab 6 - Line Estimation</a></h3>
<ul>
<li>Line Sensor Usage</li>
<li>Line Position Estimation</li>
<li>Line Sensor Calibration</li>
</ul>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<h3 id="lab-7---line-following--pid"><a class="header" href="#lab-7---line-following--pid">Lab 7 - Line Following &amp; PID</a></h3>
<ul>
<li>Line Following Control Loop Implementation</li>
</ul>
<p>Responsible: Ing. Petr Šopák</p>
<h3 id="lab-8---midterm-test-line-following"><a class="header" href="#lab-8---midterm-test-line-following">Lab 8 - Midterm Test (Line Following)</a></h3>
<ul>
<li>Good Luck</li>
</ul>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<h3 id="lab-9---lidar"><a class="header" href="#lab-9---lidar">Lab 9 - LiDAR</a></h3>
<ul>
<li>Understanding LiDAR data</li>
<li>LiDAR Data Filtration</li>
<li>Corridor Following Algorithm</li>
</ul>
<p>Responsible: Ing. Petr Šopák</p>
<h3 id="lab-10---inertial-measurement-unit-imu"><a class="header" href="#lab-10---inertial-measurement-unit-imu">Lab 10 - Inertial Measurement Unit (IMU)</a></h3>
<ul>
<li>Understanding IMU Data</li>
<li>Orientation Estimation Using IMU</li>
</ul>
<p>Responsible: Ing. Petr Šopák</p>
<h3 id="lab-11---camera-data-processing"><a class="header" href="#lab-11---camera-data-processing">Lab 11 - Camera Data Processing</a></h3>
<ul>
<li>Understanding Camera Data</li>
<li>ArUco Detection Library</li>
</ul>
<p>Responsible: Ing. Petr Šopák</p>
<h3 id="lab-12---midterm-test-corridor-following"><a class="header" href="#lab-12---midterm-test-corridor-following">Lab 12 - Midterm Test (Corridor Following)</a></h3>
<ul>
<li>Good Luck!</li>
</ul>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<h1 id="final-exam---maze-escape"><a class="header" href="#final-exam---maze-escape">Final Exam - Maze Escape</a></h1>
<ul>
<li>Good Luck!</li>
</ul>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-1---laboratory-introduction--linux-1"><a class="header" href="#lab-1---laboratory-introduction--linux-1">Lab 1 - Laboratory Introduction &amp; Linux</a></h1>
<p>Responsible: Ing. Jakub Minařík</p>
<p>This lab is going to make a brief introduction onto the environment that will be used for development and testing through the entire BPC-PRP course.</p>
<p>The following 3 chapters will take you through the installation and setup of the basic environment and you will practice the Linux CLI</p>
<h2 id="linux-1h"><a class="header" href="#linux-1h">Linux (1h)</a></h2>
<h3 id="installation-optional"><a class="header" href="#installation-optional">Installation (optional)</a></h3>
<p>To Install the Linux, please follow the <a href="2_labs/text/../../4_others/text/1_linux.html">Linux</a> chapter.</p>
<h3 id="exercise"><a class="header" href="#exercise">Exercise</a></h3>
<ul>
<li>Get familiar with the system's GUI.</li>
<li>Open the command line and try navigating the file system.</li>
<li>Practice your CLI skills. Commands overview in <a href="2_labs/text/../../4_others/text/1_linux.html">Linux</a> chapter.
<ul>
<li>check you current working directory <code>pwd</code></li>
<li>create directory <code>mkdir</code></li>
<li>enter created directory <code>cd</code></li>
<li>create file <code>touch</code></li>
<li>list directory content <code>ls</code></li>
<li>rename file <code>mv</code></li>
<li>copy file <code>cp</code></li>
<li>remove file <code>rm</code></li>
<li>create and remove directory <code>mkdir</code> and <code>rm</code></li>
<li>...</li>
</ul>
</li>
<li>try some text editor <code>nano</code>, <code>vim</code></li>
</ul>
<details> <summary>I installed vim and accidentally opened it. What now?</summary>
You can exit vim with the following sequence: press ESC, release it, then hold LSHIFT and press Z twice.
For those interested, a tutorial on using vim can be found here.
</details>
<p>More details about the Linux is going to be introduced during the course</p>
<h2 id="ros2-30-min"><a class="header" href="#ros2-30-min">ROS2 (30 min)</a></h2>
<p>The ROS 2 (Robot Operating System 2) framework is a modern, open-source platform for developing robotic systems. It builds on the success of the original ROS while addressing the limitations of its predecessor, particularly in scalability, security, and real-time performance. Designed for a wide range of robotic applications, ROS 2 is suitable for research, education, and industrial use.</p>
<p>Key features of ROS 2 include a distributed architecture for modular development, enabling nodes (individual processes) to communicate efficiently. It employs the Data Distribution Service (DDS) middleware standard, providing robust and flexible communication mechanisms, including publish/subscribe and service/request paradigms.</p>
<p>ROS 2 supports multiple platforms, such as Linux, Windows, and macOS, making it versatile for diverse hardware and software ecosystems. It integrates well with modern tools and languages, offering Python and C++ APIs, among others. Real-time capabilities are significantly improved, ensuring precise control and response in time-critical robotic systems.</p>
<p>The framework includes a rich ecosystem of libraries and tools, such as Gazebo for simulation, RViz for visualization, and Nav2 for navigation. Its modular design encourages collaboration and code reuse, fostering an active global community. With ROS 2, developers can create scalable, reliable, and innovative robotics applications tailored to real-world challenges.</p>
<p>For installation and commands overview, please follow the chapter: <a href="2_labs/text/../../4_others/text/6_ros_2.html">Robotic Operating System</a>.</p>
<h2 id="clion-sdk-15-min"><a class="header" href="#clion-sdk-15-min">CLion SDK (15 min)</a></h2>
<h3 id="installation"><a class="header" href="#installation">Installation</a></h3>
<p>Install CLion using the Snap package manager:</p>
<pre><code class="language-shell">sudo snap install --classic clion
</code></pre>
<p>Alternatively, download the CLion IDE from the <a href="https://www.jetbrains.com/clion/">official website</a> and get familiar with it (see <a href="2_labs/text/../chap_1_software/text/clion.html">CLion IDE</a>). By registering with your school email, you can obtain a free software license.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-2---c-cmake--ide-1"><a class="header" href="#lab-2---c-cmake--ide-1">Lab 2 - C++, CMake &amp; IDE</a></h1>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<p>If you are not familiar with Linux CLI commands, please follow the <a href="2_labs/text/../../4_others/text/1_linux.html">Linux</a> chapter.</p>
<h2 id="cli-compilation-30-min"><a class="header" href="#cli-compilation-30-min">CLI Compilation (30 min)</a></h2>
<p>This exercise will show you how to write and compile the most basic c++ project in Linux OS.</p>
<p>In your home directory create a project folder and enter it.</p>
<p>Write a simple program into the <code>main.cpp</code> file.</p>
<pre><code class="language-c++">#include &lt;iostream&gt;

#define A 5

int sum(int a, int b) {
    return a + b;
}

int main() {
    std::cout &lt;&lt; &quot;My Cool CLI Compiled Program&quot; &lt;&lt; std::endl;
    int b = 10;
    std::cout &lt;&lt; &quot;Sum result: &quot; &lt;&lt; sum(A, b) &lt;&lt; std::endl;
    return 0;
}
</code></pre>
<p>Save file and compile it using the <code>gcc</code> call (<a href="https://gcc.gnu.org/">GCC</a> a C/C++ compiler). </p>
<pre><code class="language-shell">g++ -o my_cool_program main.cpp
</code></pre>
<p>And run binary</p>
<pre><code class="language-shell">./my_cool_program
</code></pre>
<p>There are other alternatives, like <a href="https://clang.llvm.org/">CLang</a>, <a href="https://llvm.org/">LLVM</a>, and many <a href="https://en.wikipedia.org/wiki/List_of_compilers#C++_compilers">others</a></p>
<h3 id="challenge-1"><a class="header" href="#challenge-1">Challenge 1</a></h3>
<ul>
<li>In your project folder, create and <code>include</code> folder</li>
<li>in the <code>include</code> folder create and <code>lib.hpp</code> file and write some function into it</li>
<li>use the function from <code>lib.hpp</code> in the <code>main.cpp</code></li>
<li>compile and run program (tip: use <code>-I &lt;folder&gt;</code> argument for <code>gcc</code> to specify folder with header files)</li>
</ul>
<h3 id="challenge-2"><a class="header" href="#challenge-2">Challenge 2</a></h3>
<ul>
<li>
<p>in the projet folder create the <code>lib.cpp</code></p>
</li>
<li>
<p>move the function implementation from <code>lib.hpp</code> to <code>lib.cpp</code>; keep function declaration in <code>lib.hpp</code></p>
</li>
<li>
<p>compile and run program (tip: you have to compile both <code>main.cpp</code> and <code>lib.cpp</code>)</p>
</li>
<li>
<p>helper: <code>gcc -o &lt;output_binary&gt; &lt;source_1.cpp source_2.cpp ...&gt; -I &lt;folder_with_headers&gt;</code></p>
</li>
<li>
<p>Discuss the difference between preprocessing code, compiling code and linking objects.</p>
</li>
<li>
<p>Delete project folder</p>
</li>
</ul>
<h2 id="cmake-project-30-min"><a class="header" href="#cmake-project-30-min">CMake Project (30 min)</a></h2>
<p>Before reading following text, please get familiar with <a href="2_labs/text/../../4_others/text/7_cmake.html">CMake</a>.</p>
<p>Now let's create a similar project, but using <code>CMake</code>.</p>
<ul>
<li>Determine your current location in the file system.</li>
<li>Switch to your home directory.</li>
<li>Create a new project folder.</li>
<li>Inside this folder, create several subdirectories so that the structure looks like this (use the tree command to verify):</li>
</ul>
<pre><code>/MyProject
 |--build
 |--include
 | \--MyProject
 \--src
</code></pre>
<ul>
<li>Using any text editor (like <code>nano</code> or <code>vim</code>) to create the following files: <code>main.cpp</code>, <code>lib.cpp</code>, <code>lib.hpp</code>, and <code>CMakeLists.txt</code> in your <code>home directory</code>. </li>
<li>Move (do not copy) the <code>main.cpp</code> adn <code>lib.cpp</code> files into the <code>src</code> subdirectory.</li>
<li>Move the <code>lib.hpp</code> file into the <code>include/MyProject</code> subdirectory.</li>
<li>Move the <code>CMakeLists.txt</code> file into the root of the project folder.</li>
</ul>
<p>Now your project should look like this:</p>
<pre><code>/MyProject
 |--build
 |--CMakeLists.txt
 |--include
 | \--MyProject
 |   \--lib.hpp
 \--src
   |--lib.cpp
   \--main.cpp
   
</code></pre>
<ul>
<li>Using text editor fill the <code>main.cpp</code>, <code>lib.cpp</code> and <code>lib.hpp</code> files with required code.</li>
<li>Using the text editor fill the <code>CMakeLists.txt</code></li>
</ul>
<pre><code class="language-cmake">cmake_minimum_required(VERSION 3.10)
project(MyProject)
set(CMAKE_CXX_STANDARD 17)
include_directories(include/)
add_executable(my_program src/main.cpp src/lib.cpp)
</code></pre>
<p>Now try co compile project. In the project folder follows:</p>
<pre><code class="language-shell">cd my_project_dir  # go to your project directoyr
mkdir build  # create build folder
cd build   # enter the build folder
cmake ..   # call cmake and search for CMakeLists.txt in the folder above
make    # build program
./&lt;binary_name&gt;   # run program
</code></pre>
<p>Optional: try to compile program manualy.</p>
<pre><code class="language-shell">g++ &lt;source1 source2 source3 ...&gt; -I &lt;include_directory&gt; -o &lt;output_binary&gt;
</code></pre>
<ul>
<li>Delete project folder </li>
</ul>
<h2 id="clion-ide-30-min"><a class="header" href="#clion-ide-30-min">CLion IDE (30 min)</a></h2>
<p>Create a same project using the CLion IDE. </p>
<p>To learn how to control CLion, please take a look on <a href="2_labs/text/../../4_others/text/4_clion.html">tutorial</a> or <a href="https://www.jetbrains.com/help/clion/clion-quick-start-guide.html#code-assistance">official doc</a>.</p>
<h2 id="unit-tests-gtest-30-min"><a class="header" href="#unit-tests-gtest-30-min">Unit Tests, GTest (30 min)</a></h2>
<p>The unit tests are an effective way of developing software. It is called test-oriented-development. First we define the required functionality, than we write a tests that covers requirements and finally we implement the algorithms. When the tests are passing, it means we fulfilled requirements.</p>
<p>In the same time, if we work on large scale projects where many people cooperates and many changes are done, the unit tests allows us to trace the potential bugs that might be introduced with changes. It is called Continuous Integration (CI). </p>
<p>There are many frameworks that helps implement testing. In this course we are going to use the GTest by Google as it is one of the most common tool in this field.</p>
<h3 id="gtest-installation"><a class="header" href="#gtest-installation">GTest Installation</a></h3>
<p>If there is no GTest installed on the system follow these instructions.</p>
<pre><code class="language-shell"># install necessary packages 
sudo apt update
sudo apt install cmake build-essential libgtest-dev

# compile gtest
cd /usr/src/gtest
sudo cmake .
sudo make

# install libs into system
sudo cp lib/*.a /usr/lib
</code></pre>
<p>Take a look if the libraries are in the system</p>
<pre><code class="language-shell">ls /usr/lib | grep gtest

# you shoul see:
# libgtest.a
# libgtest_main.a
</code></pre>
<h3 id="adding-unit-test-to-project"><a class="header" href="#adding-unit-test-to-project">Adding Unit Test to Project</a></h3>
<p>In your project directory add the <code>test</code> folder.</p>
<pre><code>/MyProject
 |--include
 |--src
 \--test
</code></pre>
<p>Add the <code>add_subdirectory(test)</code> line at the end of <code>CMakeLists.txt</code> file.</p>
<p>Create <code>CMakeLists.txt</code> file in the <code>test</code> folder.</p>
<pre><code class="language-cmake">cmake_minimum_required(VERSION 3.10)

find_package(GTest REQUIRED)
enable_testing()

add_executable(my_test my_test.cpp)
target_link_libraries(my_test GTest::GTest GTest::Main)
gtest_discover_tests(my_test)
</code></pre>
<p>Create <code>my_test.cpp</code> file.</p>
<pre><code class="language-c++">#include &lt;gtest/gtest.h&gt;

float add(float a, float b) {
    return a + b;
}

TEST(test, test_should_pass) {
    EXPECT_EQ(add(5.0f, 10.0), 15.0);
    EXPECT_NE(add(5.0f, 10.0), 0.0);
}

TEST(test, test_should_fail) {
    EXPECT_EQ(add(10.0f, 10.0), 20.0);
}

int main(int argc, char** argv) {
    testing::InitGoogleTest(&amp;argc, argv);
    return RUN_ALL_TESTS();
}
</code></pre>
<p>In the bottom of the CLion open console and run</p>
<pre><code class="language-shell">mkdir build &amp;&amp; cd build
cmake ..
make
cd test
ctest
</code></pre>
<p>You should see the test evaluation.</p>
<p>You can also evaluate tests in directly in the CLion by reloading the CMake and the test will be available as an executable on the top of the window.</p>
<p><img src="2_labs/text/../images/clion_tests.png" alt="CLion Ctest" /></p>
<h2 id="c-trainig-2h"><a class="header" href="#c-trainig-2h">C++ Trainig (2h)</a></h2>
<p>Take a look on <a href="2_labs/text/../../4_others/text/2_cpp.html">basic c++ tutorial</a> and more advanced <a href="2_labs/text/../../4_others/text/8_multithreading.html">multithreading tutorial</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-3---git--c-project-template-1"><a class="header" href="#lab-3---git--c-project-template-1">Lab 3 - Git &amp; C++ Project Template</a></h1>
<p>Responsible: Ing. Jakub Minařík</p>
<h2 id="git-1h-30min"><a class="header" href="#git-1h-30min">Git (1h 30min)</a></h2>
<p>First, read the <a href="2_labs/text/../../4_others/text/3_git.html">Git Tutorial</a> chapter to get familiar with the workflow and commands</p>
<h3 id="exercise-1"><a class="header" href="#exercise-1">Exercise</a></h3>
<h3 id="sign-on"><a class="header" href="#sign-on">Sign On</a></h3>
<p>Select any of the following free Git Services and register for it</p>
<ul>
<li><a href="https://github.com/">GitHub</a></li>
<li><a href="https://about.gitlab.com/">GitLab</a></li>
<li><a href="https://bitbucket.org/product/">Bitbucket</a></li>
</ul>
<p>This server will serve as your <strong>&quot;origin&quot;</strong> (remote repository) for the rest of the <strong>BPC-PRP</strong> course.</p>
<p>The instructors will have access to all your repositories, including their history, and can monitor your progress, including who, when, and how frequently commits were made.</p>
<p>Create a repository on the server to maintain your code throughout the course.</p>
<hr />
<h3 id="cloning-repository-in-labs"><a class="header" href="#cloning-repository-in-labs">Cloning repository in labs</a></h3>
<h4 id="https---github-token"><a class="header" href="#https---github-token">HTTPS - GitHub Token</a></h4>
<p>When cloning a repository via HTTPS, you cannot push changes using your username and password. Instead, you must use a generated GitHub token.</p>
<p>To generate a token, go to <strong>Profile picture (top-right corner)</strong> &gt; <strong>Settings</strong> &gt; <strong>Developer Settings</strong> &gt; <strong>Personal Access Tokens</strong> &gt; <strong>Tokens (classic)</strong> or click <a href="https://github.com/settings/tokens">here</a>. Your generated token will be shown only once, after which you can use it as a password when pushing changes via HTTPS until the token expires.</p>
<h4 id="ssh---setting-a-different-key"><a class="header" href="#ssh---setting-a-different-key">SSH - Setting a Different Key</a></h4>
<p>You can generate an SSH key using the <code>ssh-keygen</code> command. It will prompt you in a single input for both the location and name of your key, followed by a passphrase. For use in a laboratory set a passphrase. The default location where the system recognizes the keys is <code>~/.ssh</code>.</p>
<p>When cloning a repository via SSH in labs, you may encounter a problem with Git using the wrong SSH key.<br />
You'll need to configure Git to use your generated key:</p>
<pre><code class="language-bash">git config core.sshCommand &quot;ssh -i ~/.ssh/&lt;your_key&gt;&quot;
</code></pre>
<p>In this command, <code>&lt;your_key&gt;</code> refers to the private part of your generated key.</p>
<p>On GitHub, you can add the <strong>public</strong> part of your key to either a specific repository or your entire account.</p>
<ul>
<li>
<p><strong>To add a key to a project (repository level):</strong><br />
Go to <strong>Project</strong> &gt; <strong>Settings</strong> &gt; <strong>Deploy keys</strong> &gt; <strong>Add deploy key</strong>, then check <strong>Allow write access</strong> if needed.</p>
</li>
<li>
<p><strong>To add a key to your GitHub account (global access):</strong><br />
Go to <strong>Profile picture (top-right corner)</strong> &gt; <strong>Settings</strong> &gt; <strong>SSH and GPG keys</strong> &gt; <strong>New SSH key</strong>.</p>
</li>
</ul>
<h3 id="team-exercise"><a class="header" href="#team-exercise">Team Exercise</a></h3>
<p>As a team, complete the following steps:</p>
<ol>
<li>One team member creates a repository on the server.</li>
<li>All team members clone the repository to their local machines.</li>
<li>One team member creates a &quot;Hello, World!&quot; program locally, commits it, and pushes it to the origin.</li>
<li>The rest of the team pulls the changes to their local repositories.</li>
<li>Two team members intentionally create a conflict by modifying the same line of code simultaneously and attempting to push their changes to the server. The second member to push will receive an error from Git indicating a conflict.</li>
<li>The team member who encounters the conflict resolves it and pushes the corrected version to the origin.</li>
<li>All team members pull the updated version of the repository. Each member then creates their own <code>.h</code> file containing a function that prints their name. Everyone pushes their changes to the server.</li>
<li>One team member pulls the newly created <code>.h</code> files and modifies the &quot;Hello, World!&quot; program to use all the newly created code. The changes are then pushed to the origin.</li>
<li>All team members pull the latest state of the repository.</li>
</ol>
<h2 id="c-project-template-30-min"><a class="header" href="#c-project-template-30-min">C++ Project Template (30 min)</a></h2>
<p>Now it is time to create your main project for this course.</p>
<ol>
<li>Create a project on the web page of your Git service.</li>
<li>Clone project to the local</li>
<li>Create the following project structure</li>
</ol>
<pre><code class="language-/bpc-prp-project-team-x"> |--docs
 | \--placeholder
 |--README.md
 |--CMakeLists.txt
 |--.gitignore
 |--include
 | \--&lt;project_name&gt;
 |   \--lib.hpp
 \--src
   |--lib.cpp
   \--main.cpp
</code></pre>
<ol start="4">
<li>Fill all required files</li>
</ol>
<ul>
<li>README.md is a brief description and how-to-use your project.</li>
<li>folder <code>docs</code> will be used later. Now just create file <code>placeholder</code>. </li>
<li>Write some basic code into the <code>cpp</code> adn <code>hpp</code> files.</li>
<li>Fill the <code>.gitignore</code> file. It is used to inform <code>git</code> to ignore some files, folders or extensions, not to commit it into the repository.</li>
</ul>
<pre><code class="language-.gitignore"># Ignore build directories
/build/
/cmake-build-debug/
/cmake-build-release/

# Ignore CMake-generated files
CMakeFiles/
CMakeCache.txt
cmake_install.cmake
Makefile

# Ignore IDE-specific files (CLion and JetBrains)
.idea/
*.iml
</code></pre>
<ol start="5">
<li></li>
<li>Commit and push your project to the server and share it with other members of the team.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-4---data-capture--visualization-ros-1"><a class="header" href="#lab-4---data-capture--visualization-ros-1">Lab 4 - Data Capture &amp; Visualization (ROS)</a></h1>
<p><strong>Responsible:</strong> Ing. Petr Šopák</p>
<h3 id="learning-objectives"><a class="header" href="#learning-objectives">Learning Objectives</a></h3>
<p><strong>1) Fundamentals of ROS 2</strong></p>
<ul>
<li>Setting Up a <strong>ROS 2 workspace</strong> (optional)</li>
<li>Creating a <strong>custom ROS 2 node</strong> - implementing a basic <strong>publisher &amp; subscriber</strong></li>
<li>Exploring essential <strong>ROS 2 CLI commands</strong></li>
<li>Utilizing <strong>visualization tools</strong> - <code>rqt_plot</code> and <code>rqt_graph</code></li>
</ul>
<p><strong>2) Implementing Basic Behaviour for BPC-PRP robots</strong></p>
<ul>
<li>Establishing <strong>connection to the robots</strong></li>
<li>Implementing <strong>IO node</strong> - Reading button inputs and controlling LEDs</li>
</ul>
<p><strong>BONUS: Advanced Visualizations</strong></p>
<ul>
<li>Using <code>RViz</code> for graphical representation</li>
<li>Creating basic graphical objects and defining their behavior</li>
</ul>
<blockquote>
<p>If you are using your own notebook, make sure to configure everything necessary in the Ubuntu environment! Refer to <a href="2_labs/text/../../4_others/text/12_ubuntu_environment.html">Ubuntu Environment Chapter</a> for details.</p>
</blockquote>
<h2 id="fundamentals-of-ros-2-approx-1-hour"><a class="header" href="#fundamentals-of-ros-2-approx-1-hour">Fundamentals of ROS 2 (Approx. 1 Hour)</a></h2>
<h3 id="setting-up-a-ros-workspace-5-min---optional"><a class="header" href="#setting-up-a-ros-workspace-5-min---optional">Setting Up a ROS Workspace (5 min) - optional</a></h3>
<p>Last week, you cloned a basic template that we will gradually extend with additional functionalities. The first step is to establish communication between the existing project and <strong>ROS 2</strong>.</p>
<p>There are many ways to set up a ROS project, but typically, a <a href="https://docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Creating-A-Workspace/Creating-A-Workspace.html"><strong>ROS workspace</strong></a> is created, which is a structured directory for managing multiple packages. However, for this course, we <em>do not need a full ROS workspace</em>, as we will be working with only one package. Let’s review the commands from <a href="https://github.com/Robotics-BUT/BPC-PRP/blob/master/src/2_labs/text/1_lab.md"><strong>Lab 1</strong></a>. Using the CLI, create a workspace folder structured as follows:</p>
<pre><code class="language-shell">mkdir -p ~/ros_w/src
cd ~/ros_w
</code></pre>
<p>Next, copy the folders from previous labs into the <code>src</code> directory or re-clone the repository from Git (<a href="https://github.com/Robotics-BUT/BPC-PRP/blob/master/src/2_labs/text/3_lab.md"><strong>Lab 3</strong></a>). You can rename the template to something like <strong>&quot;ros_package&quot;</strong>, but this is optional.
Finally, you need to <strong>compile the package</strong> and set up the environment:</p>
<pre><code class="language-shell">colcon build
source install/setup.bash
</code></pre>
<blockquote>
<p><strong>Recap Notes: What is a ROS Workspace?</strong></p>
<p>A <strong>ROS workspace</strong> is a structured environment for developing and managing multiple ROS packages. In this case, we created a workspace named <strong>ros_w</strong> (you can choose any name, but this follows common convention).</p>
<p>A ROS workspace allows for <strong>unified compilation</strong> and <strong>management</strong> of multiple packages. Each <strong>ROS package</strong> is a <strong>CMake project</strong> stored in the <code>src</code> folder. Packages contain:</p>
<ul>
<li>Implementations of <strong>nodes</strong> (executable programs running in ROS),</li>
<li>Definitions of <strong>messages</strong> (custom data structures used for communication),</li>
<li>Configuration files,</li>
<li>Other resources required for running ROS functionalities.</li>
</ul>
<p>After (or before) setting up the workspace, <strong>always remember</strong> to source your environment before using ROS:</p>
<pre><code class="language-shell">source ~/ros_w/install/setup.bash
</code></pre>
<p>or add sourcing to your shell startup script</p>
<pre><code class="language-shell">echo &quot;source /opt/ros/&lt;distro&gt;/setup.bash&quot; &gt;&gt; ~/.bashrc
</code></pre>
</blockquote>
<h1 id="creating-a-custom-node-55-min"><a class="header" href="#creating-a-custom-node-55-min">Creating a custom node (55 min)</a></h1>
<p>In this section, we will create a <strong>ROS 2 node</strong> that will <strong>publish</strong> and <strong>receive data</strong> (<a href="https://docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html">info</a>). We will then visualize the data accordingly.</p>
<p><strong>Required Tools:</strong></p>
<ul>
<li><a href="https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Topics/Understanding-ROS2-Topics.html#rqt-graph"><code>rqt_graph</code></a></li>
<li><a href="https://wiki.ros.org/rqt_plot"><code>rqt_plot</code></a></li>
</ul>
<p><strong>Instructions:</strong></p>
<ol>
<li>
<p>Open a terminal and set the ROS_DOMAIN_ID to match the ID on your computer’s case:</p>
<pre><code class="language-shell">export ROS_DOMAIN_ID=&lt;robot_ID&gt;
</code></pre>
<p>This change is temporary and applies <strong>only to the current terminal session</strong>. If you want to make it permanent, you need to update your configuration file:</p>
<pre><code class="language-shell">echo &quot;export ROS_DOMAIN_ID=&lt;robot_ID&gt;&quot; &gt;&gt; ~/.bashrc
source ~/.bashrc
</code></pre>
<p>Check the <code>~/.bashrc</code> content using. The <code>~/.bashrc</code> is a script that runs every time the new bash session (cli) is opened and it is used to setup bash environment.</p>
<pre><code>cat ~/.bashrc
</code></pre>
<p>To <strong>verify the domain ID</strong>, use:</p>
<pre><code class="language-shell">echo $ROS_DOMAIN_ID
</code></pre>
<blockquote>
<p>If there are any issues with the .bashrc file, please let me know.</p>
</blockquote>
</li>
<li>
<p>Open your <strong>CMake project</strong> in <strong>CLion</strong> or another <strong>Editor/IDE</strong></p>
</li>
<li>
<p>Ensure that the <strong>IDE is launched from a terminal where the ROS environment is sourced</strong></p>
</li>
</ol>
<pre><code class="language-shell">source /opt/ros/&lt;distro&gt;/setup.bash  # We are using the Humble distribution
</code></pre>
<ol start="3">
<li>Write the following code in <code>main.cpp</code>:</li>
</ol>
<pre><code class="language-c++">#include &lt;rclcpp/rclcpp.hpp&gt;
#include &quot;RosExampleClass.h&quot;

int main(int argc, char* argv[]) {
    rclcpp::init(argc, argv);

    // Create an executor (for handling multiple nodes)
    auto executor = std::make_shared&lt;rclcpp::executors::MultiThreadedExecutor&gt;();

    // Create multiple nodes
    auto node1 = std::make_shared&lt;rclcpp::Node&gt;(&quot;node1&quot;);
    auto node2 = std::make_shared&lt;rclcpp::Node&gt;(&quot;node2&quot;);

    // Create instances of RosExampleClass using the existing nodes
    auto example_class1 = std::make_shared&lt;RosExampleClass&gt;(node1, &quot;topic1&quot;, 1.0);
    auto example_class2 = std::make_shared&lt;RosExampleClass&gt;(node2, &quot;topic2&quot;, 2.0);

    // Add nodes to the executor
    executor-&gt;add_node(node1);
    executor-&gt;add_node(node2);

    // Run the executor (handles callbacks for both nodes)
    executor-&gt;spin();

    // Shutdown ROS 2
    rclcpp::shutdown();
    return 0;
}
</code></pre>
<ol start="4">
<li>Create a <strong>header file</strong> in the <code>include</code> directury to ensure the code runs properly.</li>
<li>Adds the following code tot he header file:</li>
</ol>
<pre><code class="language-c++">
#pragma once

#include &lt;iostream&gt;
#include &lt;rclcpp/rclcpp.hpp&gt;
#include &lt;std_msgs/msg/float32.hpp&gt;

class RosExampleClass {
public:
    // Constructor takes a shared_ptr to an existing node instead of creating one.
    RosExampleClass(const rclcpp::Node::SharedPtr &amp;node, const std::string &amp;topic, double freq)
        : node_(node), start_time_(node_-&gt;now()) {

        // Initialize the publisher
        publisher_ = node_-&gt;create_publisher&lt;std_msgs::msg::Float32&gt;(topic, 1);

        // Initialize the subscriber
        subscriber_ = node_-&gt;create_subscription&lt;std_msgs::msg::Float32&gt;(
            topic, 1, std::bind(&amp;RosExampleClass::subscriber_callback, this, std::placeholders::_1));

        // Create a timer
        timer_ = node_-&gt;create_wall_timer(
            std::chrono::milliseconds(static_cast&lt;int&gt;(freq * 1000)),
            std::bind(&amp;RosExampleClass::timer_callback, this));

        RCLCPP_INFO(node_-&gt;get_logger(), &quot;Node setup complete for topic: %s&quot;, topic.c_str());
    }

private:
    void timer_callback() {
        RCLCPP_INFO(node_-&gt;get_logger(), &quot;Timer triggered. Publishing uptime...&quot;);

        double uptime = (node_-&gt;now() - start_time_).seconds();
        publish_message(uptime);
    }

    void subscriber_callback(const std_msgs::msg::Float32::SharedPtr msg) {
        RCLCPP_INFO(node_-&gt;get_logger(), &quot;Received: %f&quot;, msg-&gt;data);
    }

    void publish_message(float value_to_publish) {
        auto msg = std_msgs::msg::Float32();
        msg.data = value_to_publish;
        publisher_-&gt;publish(msg);
        RCLCPP_INFO(node_-&gt;get_logger(), &quot;Published: %f&quot;, msg.data);
    }

    // Shared pointer to the main ROS node
    rclcpp::Node::SharedPtr node_;

    // Publisher, subscriber, and timer
    rclcpp::Publisher&lt;std_msgs::msg::Float32&gt;::SharedPtr publisher_;
    rclcpp::Subscription&lt;std_msgs::msg::Float32&gt;::SharedPtr subscriber_;
    rclcpp::TimerBase::SharedPtr timer_;

    // Start time for uptime calculation
    rclcpp::Time start_time_;
};

</code></pre>
<p>At this point, you can <strong>compile and run</strong> your project. Alternatively, you can use the CLI:</p>
<pre><code class="language-shell">colcon build --packages-select &lt;package_name&gt;
source install/setup.bash
ros2 run &lt;package_name&gt; &lt;executable_file&gt;
</code></pre>
<p>This will <strong>compile the ROS 2 workspace</strong>, <strong>load the compiled packages</strong>, and <strong>execute the program</strong> from the specified package.</p>
<hr />
<p><strong>TASK 1:</strong> </p>
<ul>
<li><strong>Review the code</strong> – Try to understand what each part does and connect it with concepts from the lecture.</li>
<li><strong>Observe the program’s output</strong> in the terminal.</li>
</ul>
<hr />
<p><strong>How to Check Published data</strong></p>
<p>There are two main ways to analyze and visualize data in ROS 2 - using <strong>CLI commands</strong> in the terminal or <strong>ROS visualization tools</strong>. </p>
<p><strong>1) Inspecting Published Data via CLI</strong></p>
<p>In a new terminal (Don't forget to <strong>source the ROS environment!</strong>), you can inspect the data published to a specific topic:</p>
<pre><code class="language-shell">ros2 topic echo &lt;topic_name&gt;
</code></pre>
<p>If you are unsure about the topic name, you can list all available topics:</p>
<pre><code class="language-shell">ros2 topic list
</code></pre>
<blockquote>
<p>Similar commands exist for <strong>nodes, services, and actions</strong> – refer to the <a href="https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools.html">documentation</a> for more details.</p>
</blockquote>
<p><strong>2) Using ROS Visualization Tools</strong></p>
<p>ROS 2 offers built-in tools for graphical visualization of data and system architecture. <strong>Real-Time Data Visualization</strong> - <code>rqt_plot</code> - allows you to <strong>graphically plot topic values</strong> in real-time:</p>
<pre><code class="language-shell">ros2 run rqt_plot rqt_plot
</code></pre>
<blockquote>
<p>In the GUI, enter <code>/&lt;topic_name&gt;/data</code> into the <strong>input field</strong>, click <strong>+</strong>, and configure the <strong>X and Y axes</strong> accordingly.</p>
</blockquote>
<p><strong>System Architecture Visualization</strong> - <code>rqt_graph</code> - displays the <strong>ROS 2 node connections and data flow</strong> within the system:</p>
<pre><code class="language-shell">rqt_graph
</code></pre>
<blockquote>
<p>When the system's architecture changes, simply refresh the visualization by clicking the <strong>refresh button</strong>.</p>
</blockquote>
<hr />
<p><strong>TASK 2</strong></p>
<p>Modify or extend the code to <strong>publish sine wave (or other mathematical function) values</strong>.</p>
<p><strong>Don't forget to check the results using ROS 2 tools</strong></p>
<p><em>(Hint: Include the <cmath> library for the mathemtical functions like <code>std::sin</code>)</em></p>
<p><strong>(Bonus for fast finishers)</strong>: Modify the code so that each node publishes different data, such as two distinct mathematical functions.</p>
<hr />
<h2 id="implementing-basic-behaviour-for-bpc-prp-robots-1-hour"><a class="header" href="#implementing-basic-behaviour-for-bpc-prp-robots-1-hour">Implementing Basic Behaviour for BPC-PRP robots (1 hour)</a></h2>
<p>In this section, we will get familiar with the PRP robot, <strong>learn how to connect to it, explore potential issues, and then write a basic input-output node for handling buttons and LEDs</strong>. Finally, we will experiment with these components.</p>
<h3 id="connecting-to-the-robot"><a class="header" href="#connecting-to-the-robot">Connecting to the Robot</a></h3>
<p>The robot operates as an independent unit, meaning it <strong>has its own computing system</strong> (Raspberry Pi) running Ubuntu with an already installed ROS 2 program. <em>Our goal is to connect to the robot and send instructions to control its behavior.</em></p>
<ol>
<li>First, power on the robot and connect to it using SSH. Ensure that you are on the same network as the robot.</li>
</ol>
<pre><code class="language-shell">   ssh robot@prp-&lt;color&gt;
</code></pre>
<blockquote>
<p>The password will be written on the classroom board.
The robot may take about a minute to boot up. Please <strong>wait before attempting to connect</strong>.</p>
</blockquote>
<ol start="2">
<li>Once connected to the Robot:</li>
</ol>
<ul>
<li>examine the system architecture to understand which ROS 2 nodes are running on the robot and what topics they publish or subscribe to.</li>
<li>Additionally, check the important environment variables using:
<pre><code class="language-shell">env | grep ROS
</code></pre>
</li>
</ul>
<blockquote>
<p>The <code>ROS_DOMAIN_ID</code> is particularly important. It is an identifier used by the <code>DDS</code> (Data Distribution Service), which serves as the middleware for communication in ROS 2. <strong>Only ROS 2 nodes with the same ROS_DOMAIN_ID can discover and communicate with each other.</strong></p>
</blockquote>
<ol start="3">
<li>
<p><em>(if it is necessary)</em> Open a new terminal <strong>on your local machine</strong> (not on the robot) and change the <code>ROS_DOMAIN_ID</code> to match the robot’s domain:</p>
<pre><code class="language-shell">export ROS_DOMAIN_ID=&lt;robot_ID&gt;
</code></pre>
<p>This change is temporary and applies <strong>only to the current terminal session</strong>. If you want to make it permanent, you need to update your configuration file:</p>
<pre><code class="language-shell">echo &quot;export ROS_DOMAIN_ID=&lt;robot_ID&gt;&quot; &gt;&gt; ~/.bashrc
source ~/.bashrc
</code></pre>
<p>Alternatively, you can change it by modifying the .bashrc file:</p>
<ol>
<li>Open the ~/.bashrc file in an editor, for example, using nano:</li>
</ol>
<pre><code class="language-shell">nano ~/.bashrc
</code></pre>
<ol start="2">
<li>Add/modify the following line at the end of the file:</li>
</ol>
<pre><code class="language-shell">export ROS_DOMAIN_ID=&lt;your_ID&gt;
</code></pre>
<ol start="3">
<li>Save the changes and close the editor (in nano, press CTRL+X, then Y to confirm saving, and Enter to finalize).</li>
<li>To apply the changes, run the following command:</li>
</ol>
<pre><code class="language-shell">source ~/.bashrc
</code></pre>
<p>To <strong>verify the domain ID</strong>, use:</p>
<pre><code class="language-shell">echo $ROS_DOMAIN_ID
</code></pre>
</li>
<li>
<p>After successfully setting the <code>ROS_DOMAIN_ID</code>, verify whether you can see the topics published by the robot from your local machine terminal.</p>
</li>
</ol>
<h3 id="implementing-the-io-node"><a class="header" href="#implementing-the-io-node">Implementing the IO node</a></h3>
<p>At this point, you should be able to interact with the robot—sending and receiving data. Now, let's set up the basic project structure where you will progressively add files.</p>
<h4 id="setting-up-the-project-structure"><a class="header" href="#setting-up-the-project-structure">Setting Up the Project Structure</a></h4>
<ol>
<li>(Open CLion.) Create a <code>nodes</code> directory inside both the <code>include</code> and <code>src</code> folders of your <strong>CMake project</strong>. These directories will hold your node scripts for different components.</li>
</ol>
<blockquote>
<p>You can also create additional directories such as <code>algorithms</code> if needed.
2) Inside the <code>nodes</code> directories, create two files:</p>
</blockquote>
<ul>
<li><code>include/nodes/io_node.hpp</code> (for declarations)</li>
<li><code>src/nodes/io_node.cpp</code> (for implementation)</li>
</ul>
<ol start="3">
<li>Open <code>CMakeLists.txt</code>, review it, and modify it to ensure that your project can be built successfully.</li>
</ol>
<blockquote>
<p><strong>!Remember to update CMakeLists.txt whenever you create new files!</strong></p>
</blockquote>
<h4 id="writing-an-io-node-for-buttons"><a class="header" href="#writing-an-io-node-for-buttons">Writing an IO Node for Buttons</a></h4>
<ol start="4">
<li>First, gather <strong>information about the published topic</strong> for buttons (<code>/bpc_prp_robot/buttons</code>). Determine the <strong>message type</strong> and its <strong>structure</strong> using the following <a href="https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Topics/Understanding-ROS2-Topics.html#ros2-topic-info">commands</a>:</li>
</ol>
<pre><code class="language-shell">ros2 topic type &lt;topic_name&gt; # Get the type of the message
ros2 interface show &lt;type_of_msg&gt; # Show the structure of the message
</code></pre>
<blockquote>
<p>Ensure that you are using the correct topic name.</p>
</blockquote>
<ol start="5">
<li>(Optional) To simplify implementation, create a header file named helper.hpp inside the include folder. Copy and paste the provided code snippet into this file. This helper file will assist you in working with topics efficiently.</li>
</ol>
<pre><code class="language-c++">#pragma once

#include &lt;iostream&gt;
 
static const int MAIN_LOOP_PERIOD_MS = 50;
 
namespace Topic {
   const std::string buttons = &quot;/bpc_prp_robot/buttons&quot;;
   const std::string set_rgb_leds = &quot;/bpc_prp_robot/rgb_leds&quot;;
};

namespace Frame {
    const std::string origin = &quot;origin&quot;;
    const std::string robot = &quot;robot&quot;;
    const std::string lidar = &quot;lidar&quot;;
};
</code></pre>
<hr />
<p><strong>TASK 3</strong></p>
<ol>
<li>Using the previous tasks as a reference, complete the code for <code>io_node.hpp</code> and <code>io_node.cpp</code> to retrieve button press data.
<blockquote>
<p>Hint: Below is an example <code>.hpp</code> file. You can use it for inspiration, but modifications are allowed based on your needs.</p>
<pre><code class="language-c++">#pragma once

#include &lt;rclcpp/rclcpp.hpp&gt;
#include &lt;std_msgs/msg/u_int8.hpp&gt;

namespace nodes {
     class IoNode : public rclcpp::Node {
     public:
         // Constructor
         IoNode();
         // Destructor (default)
         ~IoNode() override = default;

         // Function to retireve the last pressed button value
         int get_button_pressed() const;
 
     private:
         // Variable to store the last received button press value
         int button_pressed_ = -1;

         // Subscriber for button press messages
         rclcpp::Subscription&lt;std_msgs::msg::UInt8&gt;::SharedPtr button_subscriber_; 
 
         // Callback - preprocess received message
         void on_button_callback(const std_msgs::msg::UInt8::SharedPtr msg);
     };
 }
</code></pre>
<p>Here is an example of a <code>.cpp</code> file. However, you need to complete it yourself before you can compile it.</p>
<pre><code class="language-c++">#include &quot;my_project/nodes/io_node.hpp&quot;
namespace {
    IoNode::IoNode() {
       // ...
    }

    IoNode::get_button_pressed() const {
       // ...
    }

    // ...
}   

&gt; ```
</code></pre>
</blockquote>
</li>
<li>Run your program and check if the button press data is being received and processed as expected.</li>
</ol>
<hr />
<p><strong>TASK 4</strong></p>
<ol>
<li>Add Code for Controlling LEDs
<blockquote>
<p>Hints: - The robot subscribes to a topic for controlling LEDs.
- Find out which message type is used for controlling LEDs.
- Use the CLI to <a href="https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Topics/Understanding-ROS2-Topics.html#ros2-topic-pub">publish test messages</a> and analyze their effect:</p>
<pre><code class="language-shell">ros2 topic pub &lt;led_topic&gt; &lt;message_type&gt; &lt;message_data&gt;
</code></pre>
</blockquote>
</li>
<li>Test LED Functionality with Simple Publishing</li>
<li>Now, <strong>integrate button input with LED output</strong>:
<ul>
<li><strong>Pressing the first button</strong> → All LEDs turn on.</li>
<li><strong>Pressing the second button</strong> → LEDs cycle through colors in a <strong>your defined sequence</strong>.</li>
<li><strong>Pressing the third button</strong> → The intensity of <em>each LED color component</em> will change according to a mathematical function, with <strong>each color phase-shifted by one-third of the cycle</strong>.</li>
</ul>
</li>
</ol>
<hr />
<h1 id="bonus-advanced-visualizations-30-min"><a class="header" href="#bonus-advanced-visualizations-30-min">BONUS: Advanced Visualizations (30 min)</a></h1>
<p><strong>Required Tools:</strong> <code>rviz2</code></p>
<p>Official documentation: <a href="https://docs.ros.org/en/humble/Tutorials/Intermediate/RViz/RViz-User-Guide/RViz-User-Guide.html">RViz2</a>.</p>
<p>In this section, we will learn how to create <strong>visualizations in ROS 2</strong> using <code>RViz</code>. You should refer to the <a href="https://wiki.ros.org/rviz"><strong>official RViz documentation</strong></a> and the <a href="https://wiki.ros.org/rviz/DisplayTypes/Marker"><strong>marker tutorial</strong></a> to get a deeper understanding.</p>
<p>ROS 2 provides <strong>visualization messages</strong> via the <a href="https://wiki.ros.org/visualization_msgs"><code>visualization_msgs</code></a> package. These messages allow <strong>rendering of various geometric shapes, arrows, lines, polylines, point clouds, text, and mesh grids.</strong></p>
<p>Our objective will be to implement a <strong>class that visualizes a floating cube in 3D space</strong> while displaying its real-time position next to it.</p>
<ol>
<li>
<p>Create the Header File <code>rviz_example_class.hpp</code>:</p>
<pre><code class="language-c++"> #pragma once

 #include &lt;iostream&gt;
 #include &lt;memory&gt;
 #include &lt;rclcpp/rclcpp.hpp&gt;
 #include &lt;visualization_msgs/msg/marker_array.hpp&gt;prp_project
 #include &lt;cmath&gt;
 #include &lt;iomanip&gt;
 #include &lt;sstream&gt;
 
 #define FORMAT std::fixed &lt;&lt; std::setw(5) &lt;&lt; std::showpos &lt;&lt; std::setprecision(2)
 
 class RvizExampleClass : public rclcpp::Node {
 public:
     RvizExampleClass(const std::string&amp; topic, double freq)
         : Node(&quot;rviz_example_node&quot;) // Node name in ROS 2
     {
         // Create a timer with the specified frequency (Hz)
         timer_ = this-&gt;create_wall_timer(
             std::chrono::milliseconds(static_cast&lt;int&gt;(1000.0 / freq)),
             std::bind(&amp;RvizExampleClass::timer_callback, this)
         );
 
         // Create a publisher for MarkerArray messages
         markers_publisher_ = this-&gt;create_publisher&lt;visualization_msgs::msg::MarkerArray&gt;(topic, 10);
     }
 
 private:
     class Pose {
     public:
         Pose(float x, float y, float z) : x_{x}, y_{y}, z_{z} {}
         float x() const { return x_; }
         float y() const { return y_; }
         float z() const { return z_; }
     private:
         const float x_, y_, z_;
     };
 
     void timer_callback() {
         auto time = this-&gt;now().seconds();
         auto pose = Pose(sin(time), cos(time), 0.5 * sin(time * 3));
 
         // Create a MarkerArray message
         visualization_msgs::msg::MarkerArray msg;
         msg.markers.push_back(make_cube_marker(pose));
         msg.markers.push_back(make_text_marker(pose));
 
         // Publish the marker array
         markers_publisher_-&gt;publish(msg);
     }
 
     visualization_msgs::msg::Marker make_cube_marker(const Pose&amp; pose) {
         visualization_msgs::msg::Marker cube;
 
         // Coordinate system
         cube.header.frame_id = &quot;map&quot;; // In ROS 2, &quot;map&quot; or &quot;odom&quot; is recommended
         cube.header.stamp = this-&gt;now();
 
         // Marker Type
         cube.type = visualization_msgs::msg::Marker::CUBE;
         cube.action = visualization_msgs::msg::Marker::ADD;
         cube.id = 0;
 
         // Position
         cube.pose.position.x = pose.x();
         cube.pose.position.y = pose.y();
         cube.pose.position.z = pose.z();
 
         // Orientation (Quaternion)
         cube.pose.orientation.x = 0.0;
         cube.pose.orientation.y = 0.0;
         cube.pose.orientation.z = 0.0;
         cube.pose.orientation.w = 1.0;
 
         // Size
         cube.scale.x = cube.scale.y = cube.scale.z = 0.1;
 
         // Color
         cube.color.a = 1.0; // Alpha (visibility)
         cube.color.r = 0.0;
         cube.color.g = 1.0;
         cube.color.b = 0.0;
 
         return cube;
     }
 
     visualization_msgs::msg::Marker make_text_marker(const Pose&amp; pose) {
         visualization_msgs::msg::Marker text;
 
         // Coordinate system
         text.header.frame_id = &quot;map&quot;;
         text.header.stamp = this-&gt;now();
 
         // Marker Type
         text.type = visualization_msgs::msg::Marker::TEXT_VIEW_FACING;
         text.action = visualization_msgs::msg::Marker::ADD;
         text.id = 1;
 
         // Position (slightly above the cube)
         text.pose.position.x = pose.x();
         text.pose.position.y = pose.y();
         text.pose.position.z = pose.z() + 0.2;
 
         // Size
         text.scale.z = 0.1;
 
         // Text content
         std::stringstream stream;
         stream &lt;&lt; &quot;* Cool Cube *&quot; &lt;&lt; std::endl
                &lt;&lt; &quot;  x: &quot; &lt;&lt; FORMAT &lt;&lt; pose.x() &lt;&lt; std::endl
                &lt;&lt; &quot;  y: &quot; &lt;&lt; FORMAT &lt;&lt; pose.y() &lt;&lt; std::endl
                &lt;&lt; &quot;  z: &quot; &lt;&lt; FORMAT &lt;&lt; pose.z();
         text.text = stream.str();
 
         // Color
         text.color.a = 1.0;
         text.color.r = 1.0;
         text.color.g = 1.0;
         text.color.b = 0.0;
 
         return text;
     }
 
     // ROS 2 timer
     rclcpp::TimerBase::SharedPtr timer_;
 
     // ROS 2 publisher
     rclcpp::Publisher&lt;visualization_msgs::msg::MarkerArray&gt;::SharedPtr markers_publisher_;
 };
</code></pre>
</li>
<li>
<p>Add the Following Code to <code>main.cpp</code>:</p>
<pre><code class="language-c++">  #include &quot;rviz_example_class.hpp&quot;
  #include &lt;rclcpp/rclcpp.hpp&gt;

  int main(int argc, char** argv) {
      // Initialize ROS 2
      rclcpp::init(argc, argv);
  
      // Create a node and run it
      auto node = std::make_shared&lt;RvizExampleClass&gt;(&quot;rviz_topic&quot;, 30.0);
      rclcpp::spin(node);
  
      // Shutdown ROS 2
      rclcpp::shutdown();
      return 0;
  }
</code></pre>
</li>
<li>
<p>Build and run your project. Then open <code>Rviz</code></p>
<pre><code class="language-shell">rviz2
</code></pre>
</li>
<li>
<p>Add the Visualization Topic</p>
<ol>
<li>In <code>RViz</code>, go to <code>Add</code> → <code>By Topic</code></li>
<li>Locate the created topic <code>rviz_topic</code></li>
<li>Select <code>MarkerArray</code> to display the cube and text</li>
</ol>
</li>
</ol>
<hr />
<p><strong>TASK BONUS</strong>: </p>
<ol>
<li>Check the Code and <code>RViz</code> Features</li>
<li>Experiment with modifying the code to explore different visualization features. </li>
</ol>
<blockquote>
<p>The goal of this task is to familiarize yourself with RViz. RViz will be used in future exercises, e.g., visualizing LiDAR data.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-5---motor-kinematics--gamepad-1"><a class="header" href="#lab-5---motor-kinematics--gamepad-1">Lab 5 - Motor, Kinematics &amp; Gamepad</a></h1>
<p>Responsible: Ing. Jakub Minařík</p>
<h2 id="tasks"><a class="header" href="#tasks">Tasks</a></h2>
<p>End result of this laboratory should be estimate of position in Cartesian coordinates with origin in start position after driving robot.</p>
<h3 id="1-motor-publisher-implementation"><a class="header" href="#1-motor-publisher-implementation">1. Motor publisher Implementation</a></h3>
<ul>
<li>Develop a <strong>motor node</strong> that publishes wheel velocity commands to a ROS topic (<code>/bpc_prp_robot/set_motor_speeds</code>).</li>
<li>Ensure the node can send appropriate velocity commands to drive the robot’s wheels.</li>
</ul>
<h3 id="2-encoder-subscriber-implementation"><a class="header" href="#2-encoder-subscriber-implementation">2. Encoder subscriber Implementation</a></h3>
<ul>
<li>Extend the <strong>motor node</strong>  or create separate <strong>encoder node</strong>to subscribe to an encoder topic for both wheels(<code>/bpc_prp_robot/encoders</code>).</li>
</ul>
<h3 id="3-robot-parameter-estimation"><a class="header" href="#3-robot-parameter-estimation">3. Robot Parameter Estimation</a></h3>
<ul>
<li>Measure, estimate, or derive key robot parameters, such as:
<ul>
<li>The relationship between commanded wheel velocity and actual wheel rotation speed.</li>
<li>The relationship between wheel velocity, wheel radius, and chassis dimensions.</li>
<li>The kinematic constraints affecting the robot’s movement.</li>
</ul>
</li>
<li>Motor control values are represented as unsigned 8-bit integers (0–255):
<ul>
<li>A value of 127 corresponds to a neutral state (motors do not move).</li>
<li>Values greater than 127 cause the wheels to rotate forward.</li>
<li>Values less than 127 cause the wheels to rotate backward.</li>
</ul>
</li>
<li>The robot should execute the commanded speed for 1 second before stopping.</li>
<li>Gearbox ration should be 1:48 and number of poles is propably 3 pairs of poles. Recomended to test if number of ticks makes full rotation of wheel.</li>
<li>Test whether the number of encoder ticks corresponds to a full wheel rotation by counting the ticks per revolution.</li>
<li>For additional information, refer to the motor datasheets and check the <a href="https://github.com/Robotics-BUT/fenrir-project">robot's repository</a>.</li>
</ul>
<h3 id="4-kinematics-and-odometry-computation"><a class="header" href="#4-kinematics-and-odometry-computation">4. Kinematics and Odometry Computation</a></h3>
<ul>
<li>Implement a <strong>class for kinematics and odometry calculations</strong> for a differential drive robot.</li>
<li>Compute the robot's pose (position and orientation) based on wheel velocities and time.</li>
<li>Implement dead reckoning using wheel encoders.</li>
</ul>
<h3 id="5-encoder-data-processing"><a class="header" href="#5-encoder-data-processing">5. Encoder Data Processing</a></h3>
<ul>
<li>Develop a <strong>class for processing encoder data</strong> or add to kinematics/odometry class:
<ul>
<li>Estimate the robot’s displacement and position.</li>
<li>Apply correction mechanisms using encoder feedback to improve localization accuracy.</li>
</ul>
</li>
</ul>
<h3 id="6-optional-gamepad-control"><a class="header" href="#6-optional-gamepad-control">6. (Optional) Gamepad Control</a></h3>
<ul>
<li>Implement a <strong>gamepad</strong> node to manually control the robot’s movement.</li>
<li>Handle relevant gamepad events and publish speed for them.</li>
</ul>
<h4 id="instruction-for-gamepad---sdl2"><a class="header" href="#instruction-for-gamepad---sdl2">Instruction for Gamepad - SDL2</a></h4>
<ul>
<li>Include SLD2 library <code>#include &lt;SDL2/SDL.h&gt;</code></li>
<li>Inicialize SDL2 - <code>SDL_Init(SDL_INIT_VIDEO | SDL_INIT_GAMECONTROLLER)</code></li>
<li>Find if joystick/gamepad is connected - <code>SDL_NumJoysticks()</code></li>
<li>Create gamepad object - <code>SDL_GameControllerOpen(0)</code></li>
<li>Poll events in time loop - made using ROS2 timer
<ul>
<li>Create event object - <code>SDL_Event</code></li>
<li>Poll events - <code>SDL_PollEvent()</code></li>
<li>check event types - e.g. <code>SDL_CONTROLLERBUTTONDOWN,SDL_CONTROLLERBUTTONUP,SDL_CONTROLLERAXISMOTION</code></li>
<li>handle the events and set speed and rotation</li>
<li>publish ROS2 message</li>
</ul>
</li>
<li>Close gamepad object correctly - <code>SDL_GameControllerClose()</code></li>
</ul>
<h2 id="tests-example"><a class="header" href="#tests-example">Tests Example</a></h2>
<p>You can copy and create a test file from the example. You will propably need to rename the Kinematics class and its methods or correct parameter types as needed.</p>
<pre><code class="language-c++">#include &lt;gtest/gtest.h&gt;
#include &quot;../include/kinematics.hpp&quot;
#include &lt;cmath&gt;

using namespace algorithms;

constexpr float ERROR = 0.001;
constexpr float WHEEL_BASE = 0.12;
constexpr float WHEEL_RADIUS = 0.033;
constexpr float WHEEL_CIRCUMFERENCE = 2 * M_PI * WHEEL_RADIUS;
constexpr int32_t PULSES_PER_ROTATION = 550;


TEST(KinematicsTest, BackwardZeroVelocitySI) {
    constexpr float linear = 0;
    constexpr float angular = 0;
    constexpr float expected_l = 0;
    constexpr float expected_r = 0;

    Kinematics kin(WHEEL_RADIUS, WHEEL_BASE, PULSES_PER_ROTATION);
    auto result = kin.inverse(RobotSpeed {linear, angular});
    EXPECT_NEAR(result.l, expected_l, ERROR);
    EXPECT_NEAR(result.r, expected_r, ERROR);
}

TEST(KinematicsTest, BackwardPositiveLinearVelocitySI) {
    constexpr float linear = 1.0;
    constexpr float angular = 0;
    constexpr float expected_l = 1.0 / WHEEL_CIRCUMFERENCE * 2 * M_PI;
    constexpr float expected_r = 1.0 / WHEEL_CIRCUMFERENCE * 2 * M_PI;

    Kinematics kin(WHEEL_RADIUS, WHEEL_BASE, PULSES_PER_ROTATION);
    auto result = kin.inverse(RobotSpeed {linear,angular});
    EXPECT_NEAR(result.l, expected_l, ERROR);
    EXPECT_NEAR(result.r, expected_r, ERROR);
}

TEST(KinematicsTest, BackwardPositiveAngularVelocitySI) {
    constexpr float linear = 1.0;
    constexpr float angular = 0;
    constexpr float expected_l = -(0.5 * WHEEL_BASE) / WHEEL_CIRCUMFERENCE * (2 * M_PI);
    constexpr float expected_r = +(0.5 * WHEEL_BASE) / WHEEL_CIRCUMFERENCE * (2 * M_PI);

    Kinematics kin(WHEEL_RADIUS, WHEEL_BASE, PULSES_PER_ROTATION);
    auto result = kin.inverse(RobotSpeed{linear, angular});
    EXPECT_NEAR(result.l, expected_l, ERROR);
    EXPECT_NEAR(result.r, expected_r, ERROR);
}

TEST(KinematicsTest, ForwardZeroWheelSpeedSI) {
    constexpr float wheel_l = 0;
    constexpr float wheel_r = 0;
    constexpr float expected_l = 0;
    constexpr float expected_a= 0;

    Kinematics kin(WHEEL_RADIUS, WHEEL_BASE, PULSES_PER_ROTATION);
    auto result = kin.forward(WheelSpeed {wheel_l,wheel_r});
    EXPECT_NEAR(result.v, expected_l, ERROR);
    EXPECT_NEAR(result.w, expected_a, ERROR);
}

TEST(KinematicsTest, ForwardEqualWheelSpeedsSI) {
    constexpr float wheel_l = 1;
    constexpr float wheel_r = 1;
    constexpr float expected_l = WHEEL_RADIUS;
    constexpr float expected_a= 0;

    Kinematics kin(WHEEL_RADIUS, WHEEL_BASE, PULSES_PER_ROTATION);
    auto result = kin.forward(WheelSpeed {wheel_l,wheel_r});
    EXPECT_NEAR(result.v, expected_l, ERROR);
    EXPECT_NEAR(result.w, expected_a, ERROR);
}

TEST(KinematicsTest, ForwardOppositeWheelSpeedsSI) {
    constexpr float wheel_l = -1;
    constexpr float wheel_r = 1;
    constexpr float expected_l = 0;
    constexpr float expected_a= (WHEEL_RADIUS / (0.5 * WHEEL_BASE));

    Kinematics kin(WHEEL_RADIUS, WHEEL_BASE, PULSES_PER_ROTATION);
    auto result = kin.forward(WheelSpeed {wheel_l,wheel_r});
    EXPECT_NEAR(result.v, expected_l, ERROR);
    EXPECT_NEAR(result.w, expected_a, ERROR);;
}

TEST(KinematicsTest, ForwardAndBackwardSI) {
    constexpr float wheel_l = 1;
    constexpr float wheel_r = -0.5;

    Kinematics kin(WHEEL_RADIUS, WHEEL_BASE, PULSES_PER_ROTATION);
    auto lin_ang = kin.forward(WheelSpeed {wheel_l,wheel_r});
    auto result = kin.inverse(lin_ang);
    EXPECT_NEAR(result.l, wheel_l, ERROR);
    EXPECT_NEAR(result.r, wheel_r, ERROR);
}


TEST(KinematicsTest, ForwardAndBackwardEncoderDiff) {
    constexpr int encoder_l = 0;
    constexpr int encoder_r = 550;

    Kinematics kin(WHEEL_RADIUS, WHEEL_BASE, PULSES_PER_ROTATION);
    auto d_robot_pose = kin.forward(Encoders {encoder_l,encoder_r});
    auto result = kin.inverse(d_robot_pose);
    EXPECT_NEAR(result.l, encoder_l, 1);
    EXPECT_NEAR(result.r, encoder_r, 1);
}

// Main function to run all tests
int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&amp;argc, argv);
    return RUN_ALL_TESTS();
}
</code></pre>
<h2 id="kinematics-header-example"><a class="header" href="#kinematics-header-example">Kinematics Header Example</a></h2>
<p>Only example of header - types needs to be corrected. Instead of structures you can use for example <code>std::pair</code>. Funtion working with coordinates are working with differences.</p>
<pre><code class="language-c++"> struct RobotSpeed{
  float v; //linear
  float w; //angluar
 }

 struct WheelSpeed{ //depends on you in what units
  float l; //left
  float r; //right
 }

struct Encoders{
  int l; //left
  int r; //right
}
Coordinates{ //Cartesian coordinates
  float x; 
  float y;
}

class Kinematics{
  Kinematics(double wheel_radius, double wheel_base, int ticks_revolution);
  RobotSpeed forward(WheelSpeed x) const;
  WheelSpeed inverse(RobotSpeed x) const;
  Coordinates forward(Encoders x) const;
  Encoders inverse(Coordinates x) const;
}
</code></pre>
<h2 id="be-aware-of-parallel-programming"><a class="header" href="#be-aware-of-parallel-programming">Be Aware of Parallel Programming</a></h2>
<p>When a variable is accessed by multiple threads—such as in the case of an encoder node, where a callback writes the encoder’s value to a variable while another thread reads it—you must use std::mutex or std::atomic to ensure thread safety. More about parallel computing in <a href="2_labs/text/../../4_others/text/8_multithreading.html">Multithreading</a>.</p>
<h3 id="atomic-variables"><a class="header" href="#atomic-variables">Atomic variables</a></h3>
<p>Atomic variables are thread save, but only simple types such as int, float. 
Name is from atomic operation/instruction - this type of instruction cannot be interrupted when executed, so its blocks the memory until done and other threads are waiting.</p>
<pre><code class="language-c++">std::atomic&lt;int&gt; atomic_int;
</code></pre>
<h3 id="mutex"><a class="header" href="#mutex">Mutex</a></h3>
<p>Mutex can be used to safely modify complex data structures such as std::vector or std::map.
A mutex works by locking a resource when a thread accesses it and unlocking it after the operation is complete. Other threads attempting to access the resource must wait until the mutex is released.</p>
<pre><code class="language-c++">std::mutex mtx;
int shared_value = 0;

void increment()
{
    std::lock_guard&lt;std::mutex&gt; lock(mtx); 
    shared_value++;
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-6---line-estimation-1"><a class="header" href="#lab-6---line-estimation-1">Lab 6 - Line Estimation</a></h1>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<h2 id="line-sensor-usage-1h"><a class="header" href="#line-sensor-usage-1h">Line Sensor Usage (1h)</a></h2>
<p>In the first section we are going to write a basic interface with the line sensor backend and we will study the raw data.</p>
<h3 id="line-sensor-explained"><a class="header" href="#line-sensor-explained">Line Sensor Explained</a></h3>
<p>We are using the <code>TCRT5000</code> line sensor. </p>
<p>It consists of an infrared LED and a phototransistor placed next to each other. When powered, the LED emits infrared light, and if a reflective surface (such as a white line) is placed in front of it, the phototransistor detects the reflected signal. The amount of reflected light changes depending on the color and surface characteristics of the object below the sensor, allowing the TCRT5000 to distinguish between light and dark areas. By interpreting the output of the phototransistor, microcontrollers or other circuitry can determine whether the sensor is over a reflective (light) line or a non-reflective (dark) background, enabling robust line tracking and detection functionality.</p>
<p><img src="2_labs/text/../images/line_sensor_schematics.png" alt="" /></p>
<p>Schamatics from: https://osoyoo.com/2017/08/15/tcrt5000-infrared-line-tracking-sensor/</p>
<p>To understand the output value of the line sensor, please study and understand the following sensor characteristics.</p>
<p><img src="2_labs/text/../images/line_sensor_char.png" alt="" /></p>
<p>If the sensor is above the dark line, there is no interaction between the IR LED and phototransisor. The phototransistor is closed and the voltage produce large voltage on the analog output.</p>
<p>If the sensor is above the white (reflective) surface, the IR light from photodiode opens transistor and the analog output <code>A0</code> is grounded. The voltage drops low.</p>
<p>Study the slope of the characteristics and discuss the sensor range.</p>
<h3 id="differential-sensor-usage"><a class="header" href="#differential-sensor-usage">Differential Sensor Usage</a></h3>
<p>Consider using two line sensors in the differential connection. One sensor is considered as a signal with positive sign and the other sensor is considered as a sensor with negative sign.</p>
<p>If we make a cleaver design, we can get a very good guess of robot's position relative to the line just by adding the sensor output values together.</p>
<p><img src="2_labs/text/../images/line_sensor_diff.png" alt="" />.</p>
<p>What about the gap in between the sensors? How it effects line following process?</p>
<h3 id="line-node-implementation"><a class="header" href="#line-node-implementation">Line Node Implementation</a></h3>
<p>Now it is time to implement the <code>LineNode</code>, the class that will receive data and encapsulate the line estimation process for the rest of the program.</p>
<p>Create a new files according to you project's code conventions and implement the data receiving from the <code>/bpc_prp_robot/line_sensors</code>.</p>
<p>The message on the <code>/bpc_prp_robot/line_sensors</code> topic is of the <code>std_msgs::msg::UInt16MultiArray</code> type.</p>
<pre><code class="language-c++">    enum class DiscreteLinePose {
        LineOnLeft,
        LineOnRight,
        LineNone,
        LineBoth,
    };
    
    class LineNode : public rclcpp::Node {
    public:
        
        LineNode();
        
        ~LineNode();

        // relative pose to line in meters
        float get_continuous_line_pose() const;
    
        DiscreteLinePose get_discrete_line_pose() const;
    
    private:
  
        rclcpp::Subscription&lt;std_msgs::msg::UInt16MultiArray&gt;::SharedPtr line_sensors_subscriber_;
    
        void on_line_sensors_msg(std::shared_ptr&lt;std_msgs::msg::UInt16MultiArray&gt; msg);
    
        float estimate_continuous_line_pose(float left_value, float right_value);
    
        DiscreteLinePose estimate_descrete_line_pose(float l_norm, float r_norm);
    };
</code></pre>
<p>Run the program and try to print out the measured values.</p>
<h2 id="line-position-estimation-1h"><a class="header" href="#line-position-estimation-1h">Line Position Estimation (1H)</a></h2>
<p>In this section we will focus on the line position estimation. Our target is to write a class that will encapsulate line position estimation. The input of this algorithm is the left and right sensor values. The output is both, the discrete or Continuous position of the robot relativelly to the line.</p>
<p>Try to develop this class by the <a href="https://en.wikipedia.org/wiki/Test-driven_development">Test Driven Development</a>. First write tests, than implement the algorithm.</p>
<pre><code class="language-c++">
#include &lt;iostream&gt;
#include &lt;gtest/gtest.h&gt;
TEST(LineEstimator, line_estimator_test_1) {
    uint16_t left_value = 0;
    uint16_t right_value = 1024;
    auto result = LineEstimator::estimate_discrete(left, right);
    
    EXPECT_EQ(result, /* ... */);
}

// ...

int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&amp;argc, argv);
    return RUN_ALL_TESTS();
}
</code></pre>
<p>By separating the line estimation algorithm into separated class, you will improve the test writing experience compared to the line estimation directly in the <code>LineNode</code> class.</p>
<h3 id="discrete-approach"><a class="header" href="#discrete-approach">Discrete Approach</a></h3>
<p>Write and test method that will provide your future program with discrete position of the robot relative to the line. See previous examples. </p>
<pre><code class="language-c++">    class LineEstimator {
    
        static DiscreteLinePose estimate_discrete_line_pose(uint16_t left_val, uint16_t right_val);
    
    };
</code></pre>
<h3 id="continuous-approach"><a class="header" href="#continuous-approach">Continuous Approach</a></h3>
<p>Try the same for the continuous domain. Sensor's raw values on input and float or double value on the output. Tip: scale output to SI units.</p>
<pre><code class="language-c++">    class LineEstimator {
    
        static float estimate_continuous_line_pose(uint16_t left_val, uint16_t right_val);
    
    };
</code></pre>
<h2 id="line-sensor-calibration-and-arrangement-1h"><a class="header" href="#line-sensor-calibration-and-arrangement-1h">Line Sensor Calibration and Arrangement (1h)</a></h2>
<p>Now it is time to take a closer look on the sensor setup. On every robot the sensors are places a little bit differently (different place, rotation, height above the ground, different electrical composition (wiring, resistos values, ICs, etc.). </p>
<p>At the beginning of each ride, you should calibrate the sensors, so the algorithm can expect similar if not the same values on thi input,</p>
<h3 id="how-to-calibrate-sensor"><a class="header" href="#how-to-calibrate-sensor">How to calibrate sensor</a></h3>
<p>Basically, the most important is to catch the maximum and minimum sensor response (max reflexcion and minimum leflexion) an normalize the output, so your algorithm always works with same data range.</p>
<pre><code class="language-c++">    auto calibrated_val = (raw_val - min_val) / (max_val - min_val);
</code></pre>
<p>The sensor output value normalized in this vay will always be truncated in range or &lt;0.0, 1.0&gt;</p>
<h3 id="sensor-arrangement"><a class="header" href="#sensor-arrangement">Sensor arrangement</a></h3>
<p>On the robot there is several spots to put the sensors on. Think how the sensor position, it's range and dynamic range influence your line following algorithm.</p>
<p>What about the dead zone between the sensors?</p>
<p>What if you put sensors to close to each other?</p>
<p>Should one of the sensors has amplified output compared to the other one?</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-7---line-following--pid-1"><a class="header" href="#lab-7---line-following--pid-1">Lab 7 - Line Following &amp; PID</a></h1>
<p><strong>Responsible:</strong> Ing. Petr Šopák</p>
<h3 id="learning-objectives-1"><a class="header" href="#learning-objectives-1">Learning Objectives</a></h3>
<ol>
<li><strong>Bang-Bang Line Following (ON/OFF Control)</strong></li>
<li><strong>Line Following with P-Control</strong></li>
<li><strong>Line Following with PID Control</strong></li>
</ol>
<p>In previous lab sessions, <em>you developed ROS 2 nodes for</em>:</p>
<ul>
<li><em>Collecting data</em> from reflection-based sensors</li>
<li><em>Estimating the position</em> of a line</li>
<li><em>Controlling the robot's motion</em></li>
</ul>
<p>Now, your task is to develop a <strong>strategy for line following</strong> – that is, responding to the estimated line position and ensuring the robot tracks the line correctly. You will start with the <em>simplest approach</em> (Bang-Bang control) and progressively refine it to implement <em>PID regulation</em>.</p>
<p>For more details, see the <a href="https://github.com/Robotics-BUT/BPC-PRP/blob/lab_7_branch/src/3_navigation/text/3_line_following.md">Line Following section</a>.</p>
<h2 id="bang-bang-line-following-approx-1-hour"><a class="header" href="#bang-bang-line-following-approx-1-hour">Bang-Bang Line Following (Approx. 1 hour)</a></h2>
<p>Bang-Bang is the most basic control method. Instead of smoothly adjusting the speed, the robot makes <strong>hard, discrete decisions</strong> based on sensor readings. Think of it as a light switch – either ON or OFF:</p>
<ol>
<li>Line is detected on the left → Turn right</li>
<li>Line is detected on the right → Turn left</li>
<li>Line is centered → Move straight</li>
</ol>
<p>This method <strong>can be implemented using either digital or analog sensor outputs</strong>. Since digital outputs already behave like ON/OFF signals, Bang-Bang logic is straightforward. However, in this lab, we will focus on the <strong>analog output</strong>, which requires setting a threshold to decide when the robot should turn.</p>
<p>The entire algorithm is illustrated in <a href="2_labs/text/bangDiagram">Figure 1</a>. The process consists of reading the estimated line position and comparing it to a <strong>user-defined threshold</strong>. Based on this comparison, the robot's movement is determined.</p>
<p>The flowchart provides a <strong>generalized structure</strong> for Bang-Bang control. However, the specific <strong>comparison logic</strong> and the <strong>velocity values</strong> sent to the wheels <strong>depend on your own implementation</strong>. It is up to you to decide how to structure the control logic in your code.</p>
<p id="bangDiagram" align="center">
  <img src="2_labs/text/../images/bang_bang_flowchart.png" alt="alt text" width="450" height="400">
</p>
<p align="center">
    <em> Figure 1: Flowchart for Bang-Bang Control </em>
</p>
<p>To fine-tune the performance, it is recommended to start with a <strong>higher threshold and gradually decrease it</strong>. Observe how the robot’s behavior changes and try to understand why this approach leads to better results.</p>
<hr />
<p><strong>TASK 1</strong></p>
<ol>
<li>Project Structure:</li>
</ol>
<ul>
<li>Inside the <code>src</code> and <code>include</code> directories, create a new folder named <code>loops</code>.</li>
<li>In this folder, create two files: <code>line_loop.cpp</code> and <code>line_loop.hpp</code>.</li>
<li>These files will define a ROS 2 node that implements a periodic control loop using a timer callback (e.g., <code>line_loop_timer_callback()</code>).</li>
<li>The loop should regularly read the estimated line position, compute the control action and send appropriate speed commands to the robot's motors.</li>
</ul>
<ol start="2">
<li>Implement <strong>Bang-Bang Line Control</strong> based on the guidelines provided in the lab description.</li>
<li>Experiment with different threshold values and observe how the robot behaves and analyze the <strong>advantages and limitations</strong> of Bang-Bang control.</li>
</ol>
<h2 id="line-following-with-p-control-approx-1-hour"><a class="header" href="#line-following-with-p-control-approx-1-hour">Line Following with P-Control (Approx. 1 hour)</a></h2>
<p>Now you will refine your line-following strategy by implementing <strong>Proportional Control (P-Control)</strong>. Unlike Bang-Bang control, which causes abrupt movements, P-Control allows the robot to adjust its movement smoothly based on how far the estimated line position deviates from the robot’s center. The goal is to achieve smoother and more stable tracking of the line.</p>
<p><strong>Previously you implemented Bang-Bang control</strong>, which relied on strict ON/OFF decisions. This approach worked but led to <strong>oscillations and jerky movement</strong>, as the robot continuously switched between turning left and right. These issues make it <strong>difficult for the robot to follow curves or move efficiently at higher speeds</strong>.</p>
<p>Proportional control solves this by introducing a <strong>continuous adjustment</strong> to the robot’s turning speed. Instead of making binary decisions, the angular velocity <em>ω</em> is determined using a <strong>proportional gain <em>K<sub>P</sub></em></strong> and the error <em>e</em>, which represents the difference between the estimated line position <em>x</em> and the robot's center <em>x<sub>0</sub></em>:</p>
<p>$$
e = x - x_{0}
$$</p>
<p>By multiplying this error by <em>K<sub>P</sub></em>, we obtain the angular velocity:</p>
<p>$$
ω = K_{P} \cdot e
$$</p>
<p>This means that when the robot is <strong>far from the center</strong>, it <strong>turns more sharply</strong>. When it is <strong>close to the center</strong>, it makes <strong>minor corrections</strong>. If the line is perfectly centered, the robot moves straight. The higher the proportional gain <em>K<sub>P</sub></em>, the stronger the response to the error. However, if <em>K<sub>P</sub></em> is too high, the robot may start oscillating.</p>
<p>The process of P-Control is illustrated in <a href="2_labs/text/pContDiagram">Figure 2</a>. The robot reads the estimated position of the line, calculates the error, applies the proportional formula to determine angular velocity, and then sends this velocity to the motion control node, which executes the movement.</p>
<p id="pContDiagram" align="center">
  <img src="2_labs/text/../images/p_control_flowchart.png" alt="P Control Flowchart" width="200" height="350">
</p>
<p align="center">
    <em> Figure 2: Flowchart for P-Control Line Follower </em>
</p>
<p>A key part of implementing P-Control is choosing the right value for <em>K<sub>P</sub></em>. If <em>K<sub>P</sub></em> is too small, the robot will react very slowly and may fail to follow the line accurately. If <em>K<sub>P</sub></em> is too large, the robot might oscillate too much and become unstable. The best approach is to start with a low value of <em>K<sub>P</sub></em> and gradually increase it, observing how the robot’s movement improves.</p>
<hr />
<p><strong>TASK 2</strong></p>
<ol>
<li>Insert the provided <code>pid.hpp</code> file into the <code>include/algorithms</code> directory. This header defines a basic PID controller class, which you will use for both <strong>Task 2 (P-control)</strong> and <strong>Task 3 (full PID)</strong>.</li>
</ol>
<pre><code class="language-c++">#pragma once

#include &lt;iostream&gt;
#include &lt;chrono&gt;

namespace algorithms {

    class Pid {
    public:
        Pid(float kp, float ki, float kd)
            : kp_(kp), ki_(ki), kd_(kd), prev_error_(0), integral_(0) {}

        float step(float error, float dt) {
            integral_ += error * dt;
            float derivative = (error - prev_error_) / dt;
            float output = kp_ * error + ki_ * integral_ + kd_ * derivative;
            prev_error_ = error;
            return output;
        }

        void reset() {
            prev_error_ = 0;
            integral_ = 0;
        }

    private:
        float kp_;
        float ki_;
        float kd_;
        float prev_error_;
        float integral_;
    };
}
</code></pre>
<ol start="2">
<li>Reuse your <code>Lineloop</code> class from Task 1 and modify the control logic inside <code>line_loop_timer_callback()</code> to implement a <strong>Proportional controller</strong>.</li>
<li>Experiment with different values of the proportional gain <em>K<sub>P</sub></em> and determine the most suitable value.</li>
<li>Observe the performance and assess if further refinement is needed.</li>
<li>Write simple unit tests for the <code>Pid</code> class in a separate file named <code>pid_test.cpp</code>. Here's an example that tests the response of the P-controller to a unit step input:</li>
</ol>
<pre><code class="language-c++">#include &quot;solution/algorithms/pid.hpp&quot;
#include &lt;iostream&gt;
#include &lt;cassert&gt;
#include &lt;cmath&gt;

using namespace algorithms;

bool nearly_equal(float a, float b, float eps = 1e-5f) {
    return std::fabs(a - b) &lt; eps;
}

// Unit step input (constant error = 1.0)
void test_unit_step() {
    Pid pid(2.0f, 0.0f, 0.0f); // P-only
    float dt = 0.1f;

    float error = 1.0f;

    for (int i = 0; i &lt; 5; ++i) {
        float output = pid.step(error, dt);
        assert(nearly_equal(output, 2.0f));
    }

    std::cout &lt;&lt; &quot;[PASS]\n&quot;;
}

int main() {
    test_unit_step();

    std::cout &lt;&lt; &quot;All P-controller tests passed.\n&quot;;
    return 0;
}

</code></pre>
<h2 id="line-following-with-pid-control-approx-1-hour"><a class="header" href="#line-following-with-pid-control-approx-1-hour">Line Following with PID Control (Approx. 1 hour)</a></h2>
<p>In this part, you will refine your <strong>P-Control implementation</strong> by adding <strong>Integral (I)</strong> and <strong>Derivative (D)</strong> components, creating a <strong>PID controller</strong>. This will improve stability, reduce oscillations, and enhance the robot’s ability to follow curves accurately.</p>
<p>While <strong>P-Control</strong> adjusts the robot’s angular velocity based on the current error, it <strong>does not account for past errors or predict future corrections</strong>. This can result in oscillations or slow responses in certain situations. <strong>PID control</strong> solves these issues by incorporating two additional terms:</p>
<p>$$
ω = K_{P}e + K_{i}\int e dt + K_{d}\frac{de}{dt}
$$</p>
<ul>
<li><strong>$$K_{P}e$$ (Proportional term)</strong>: Reacts to the current error.</li>
<li><strong>$$K_{i}\int e dt$$ (Integral term)</strong>: Corrects accumulated past errors.</li>
<li><strong>$$K_{d}\frac{de}{dt}$$ (Derivative term)</strong>: Predicts future errors and reduces overshooting.</li>
</ul>
<p>The <strong>integral term</strong> helps eliminate steady-state errors, ensuring the robot remains centered over time. The <strong>derivative term</strong> improves responsiveness by counteracting rapid changes, preventing overshooting and oscillations.</p>
<p>The overall process is illustrated in <a href="2_labs/text/pidContDiagram">Figure 3</a>. The robot reads the estimated line position, computes the error, applies the PID formula, and sends the adjusted velocity command to the motion control node.</p>
<p id="pidContDiagram" align="center">
  <img src="2_labs/text/../images/pid_flowchart.png" alt="PID Control Flowchart" width="200" height="400">
</p>
<p align="center">
    <em> Figure 3:  Flowchart for PID Control </em>
</p>
<p>Tuning <em>K<sub>P</sub></em>, <em>K<sub>i</sub></em>, <em>K<sub>d</sub></em> is essential for optimal performance. If <em>K<sub>P</sub></em> is too high, the robot may oscillate. If <em>K<sub>i</sub></em> is too high, the robot may overcorrect. If <em>K<sub>d</sub></em> is too high, the robot may become too sensitive to small errors. A common approach is to start with only <em>K<sub>P</sub></em>, then add <em>K<sub>d</sub></em>, and finally fine-tune <em>K<sub>d</sub></em> to eliminate steady-state error.</p>
<p><strong>For more information on PID Control implementation and tuning methods, please refer to the <a href="https://github.com/Robotics-BUT/BPC-PRP/blob/master/src/3_navigation/text/2_pid.md"><strong>PID section</strong></a></strong></p>
<hr />
<p><strong>TASK 3</strong></p>
<ol>
<li>Just like in the previous tasks, extend your <code>LineLoop</code> class to <strong>implement full PID control</strong> using the provided <code>Pid</code> class. Also, don’t forget to <strong>extend your unit tests</strong> (<code>pid_test.cpp</code>) to verify the behavior of all PID components.</li>
<li>Choose a <strong>tuning method</strong> (either manual tuning or the Ziegler-Nichols method) and find the optimal values for <em>K<sub>P</sub></em>, <em>K<sub>i</sub></em>, <em>K<sub>d</sub></em>.</li>
<li>Observe the differences between PID control and the previous line-following methods. Analyze how each component affects the robot’s performance.</li>
<li>(Optional) Implement output saturation (clamping). Real robots cannot turn infinitely fast. If your PID controller outputs a very large value (e.g. due to a sharp error), you should <strong>limit (saturate) it to a safe range.</strong></li>
<li>(Optional) Implement Anti-Windup. The integral term in a PID controller can sometimes accumulate too much (especially when the output is saturated), which leads to overshooting or instability. This is called integral windup. To prevent this, implement anti-windup, for example disabling integration when output is saturated or limiting the maximum integral value</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-8---midterm-test-line-following-1"><a class="header" href="#lab-8---midterm-test-line-following-1">Lab 8 - Midterm Test (Line Following)</a></h1>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<p>Up to 50 points can be earned through two practical demonstrations of task solutions during the semester.</p>
<p>8th week - Line Following (25 points)</p>
<p>12th week - Corridor Following (25 points)</p>
<h2 id="line-following-rules"><a class="header" href="#line-following-rules">Line Following Rules</a></h2>
<p>There are 3 tracks:</p>
<ul>
<li>Straight Line (5 points)</li>
<li>Simple Loop (10 points)</li>
<li>Complex Loop (10 points)</li>
</ul>
<p>To pass the track robot have to follow the full length of the line.</p>
<p>If no part of the robot's body covers the line, attempt fails.</p>
<p>The points are awarded only for completing the entire track.</p>
<p>Teams have 3 attempts per track, with a time limit of 3 minutes per attempt.</p>
<p>All 3 attempts have to be performed during a single lab.</p>
<h2 id="test-tracks"><a class="header" href="#test-tracks">Test Tracks</a></h2>
<p><img src="2_labs/text/../images/line_tracks.png" alt="Test Track" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-9---obstacle-detection--corridor-following"><a class="header" href="#lab-9---obstacle-detection--corridor-following">Lab 9 - Obstacle Detection &amp; Corridor Following</a></h1>
<p><strong>Responsible:</strong> Ing. Petr Šopák</p>
<h3 id="learning-objectives-2"><a class="header" href="#learning-objectives-2">Learning Objectives</a></h3>
<p><strong>1) Understanding and working with LiDAR and/or Ultrasonic Sensors</strong></p>
<ul>
<li>Interpreting range data based on sensor principles</li>
<li>Visualizing live sensor output in RViz</li>
</ul>
<p><strong>2) Implementing basic Obstacle Detection</strong></p>
<ul>
<li>Detecting nearby obstacles</li>
<li>Implementing basic obstacle avoidance strategy</li>
</ul>
<p><strong>3) Implementing Corridor following behavior</strong></p>
<hr />
<p>In the previous labs, you implemented <strong>line following</strong> — the robot follows a visible line on the floor. This method is useful in controlled environments, such as factory floors or predefined paths. However, <strong>line following relies on the presence of artificial markings</strong> and provides limited flexibility in more general environments.</p>
<p>In this and next labs, you will begin working on <strong>corridor following</strong>, a more natural and scalable navigation strategy. Instead of relying on a line, the robot uses <strong>range sensors</strong> (LiDAR or ultrasonic) to perceive the environment and <strong>stay centered between two walls or obstacles</strong>, just like navigating a hallway. This approach is closer to what real autonomous robots do in indoor spaces, such as offices, hospitals, or warehouses.</p>
<p>You will first learn how to <strong>interpret range data</strong> and <strong>detect nearby obstacles</strong>. Then, you will <strong>implement a simple reactive controller that enables the robot to stay within a corridor</strong>.</p>
<h2 id="understanding-and-working-with-lidar-andor-ultrasonic-sensors-approx-40-minutes"><a class="header" href="#understanding-and-working-with-lidar-andor-ultrasonic-sensors-approx-40-minutes">Understanding and working with LiDAR and/or Ultrasonic Sensors (Approx. 40 minutes)</a></h2>
<p>In this part of the lab, you will get familiar with your chosen range sensor — either LiDAR or ultrasonic. You will explore how it measures distance, how the data is represented in ROS 2, and how to visualize it in RViz. This will give you the foundation needed for obstacle detection and corridor following tasks in the rest of the lab.</p>
<blockquote>
<p>For these labs, please <strong>choose one type of range sensor</strong> — either ultrasonic or LiDAR. You will work with the selected sensor throughout the exercises.
If you later decide to switch to the other sensor or want to use both for comparison or improvement, feel free to do so.
The instructions are written to support both sensor types.</p>
</blockquote>
<h3 id="a-light-detection-and-ranging-lidar-sensor"><a class="header" href="#a-light-detection-and-ranging-lidar-sensor">A) Light Detection and Ranging (LiDAR) sensor</a></h3>
<p>LiDAR sensors are commonly used in robotics to <strong>measure precise distances to surrounding objects</strong>. A LiDAR device emits rapid laser pulses and measures the time it takes for each pulse to bounce back from a surface. Using the known speed of light, it calculates the exact distance to each point. Most LiDARs used in mobile robots operate in 2D, scanning a horizontal plane around the robot to produce a range profile of the environment. This allows the robot to detect walls, obstacles, and open spaces with high accuracy and resolution.</p>
<p><strong>When implementing the tasks, please refer to the official documentation of the sensor. You can find the RPLiDAR A1 datasheet here:</strong> <a href="https://www.generationrobots.com/media/rplidar-a1m8-360-degree-laser-scanner-development-kit-datasheet-1.pdf?srsltid=AfmBOooj2AiNYBC8o8kbJgSheC_A-9984T-XY20x4SDBgRdxRKcWEVNh">URL</a></p>
<hr />
<p><strong>TASK 1 - A</strong></p>
<ol>
<li><strong>Explore the data</strong> provided by the sensor - Inspect the raw data in the terminal (Refer to the datasheet if needed to understand parameters)
<blockquote>
<p>Understand the meaning of the main fields in the message: <code>angle_min</code>, <code>angle_max</code>, <code>angle_increment</code>, <code>ranges[]</code>, <code>range_max</code>, <code>range_min</code>.</p>
</blockquote>
</li>
<li><strong>Visualize the LiDAR data</strong> in <code>RViz 2</code>
<ol>
<li>Launch <code>RViz 2</code> and add a <code>LaserScan</code> display (add-&gt;By Topic-&gt;LaserScan)</li>
<li>Set the correct topic name and <code>Fixed Frame</code> as <code>lidar</code></li>
<li>(Optional) Customize the display: point size, color, decay time, etc.</li>
</ol>
<blockquote>
<p>Don’t forget to launch RViz in a sourced terminal, otherwise topics will not be visible.</p>
</blockquote>
</li>
<li><strong>Create a new <code>ROS 2</code> node</strong> for your LiDAR processing
<ul>
<li>Create <code>lidar_node.hpp</code> and <code>lidar_node.cpp</code> in <code>nodes</code> directories</li>
<li>In this node, <strong>subscribe to the LiDAR topic and process incoming data</strong></li>
</ul>
</li>
<li><strong>Think critically about the data</strong>
<ul>
<li>Are all values in <code>ranges[]</code> useful for your application?</li>
</ul>
<blockquote>
<p><strong>TIP:</strong> LiDAR may return very small values (e.g. 0) or extremely large values (inf). These are usually best ignored.</p>
</blockquote>
<ul>
<li>Do all directions matter for your robot’s task?</li>
</ul>
<blockquote>
<p><strong>TIP:</strong> You can filter only specific angular sectors depending on what you need. (e.g. Front, Right, Left, Back)</p>
</blockquote>
<ul>
<li>(Optional) Example skeleton for implementing sector-based LiDAR filtering. You may use this as inspiration or create your own version:</li>
</ul>
<pre><code class="language-c++">#include &lt;cmath&gt;
#include &lt;vector&gt;
#include &lt;numeric&gt;

namespace algorithms {

    // Structure to store filtered average distances in key directions
    struct LidarFiltrResults {
        float front;
        float back;
        float left;
        float right;
    };

    class LidarFiltr {
    public:
        LidarFiltr() = default;

        LidarFiltrResults apply_filter(std::vector&lt;float&gt; points, float angle_start, float angle_end) {

            // Create containers for values in different directions
            std::vector&lt;float&gt; left{};
            std::vector&lt;float&gt; right{};
            std::vector&lt;float&gt; front{};
            std::vector&lt;float&gt; back{};

            // TODO: Define how wide each directional sector should be (in radians)
            constexpr float angle_range = ;

            // Compute the angular step between each range reading
            auto angle_step = (angle_end - angle_start) / points.size();

            for (size_t i = 0; i &lt; points.size(); ++i) {
                auto angle = angle_start + i * angle_step;

                // TODO: Skip invalid (infinite) readings

                // TODO: Sort the value into the correct directional bin based on angle
                
            }

            // TODO: Return the average of each sector (basic mean filter)
            return LidarFiltrResults{
                .front = ,
                .back = ,
                .left = ,
                .right = ,
            };
        }
    };
}
</code></pre>
</li>
</ol>
<h3 id="b-ultrasonic-sensors"><a class="header" href="#b-ultrasonic-sensors">B) Ultrasonic sensors</a></h3>
<p>Ultrasonic sensors are widely used in robotics for short-range obstacle detection. They work by emitting a high-frequency sound wave and measuring the time it takes for the echo to return after bouncing off an object. Unlike LiDAR, ultrasonic sensors typically measure in a narrow cone, and their readings can be affected by surface material, angle, or ambient noise. They are cost-effective, but require more filtering and careful placement to be reliable.</p>
<p><strong>When implementing the tasks, please refer to the official documentation of the sensor. You can find the HY-SRF05 datasheet here:</strong> <a href="https://dratek.cz/arduino/1735-meric-vzdalenosti-ultrazvukovy-5pin-hy-srf05-pro-arduino.html?gad_source=1&amp;gclid=Cj0KCQiAr7C6BhDRARIsAOUKifhd7u9T5IjiCyc4w0n-WqehlzG5F2pNwJ4JP5M_eQDHW-daU_NkSKYaAn-_EALw_wcB">URL</a></p>
<hr />
<p><strong>TASK 1 - B</strong></p>
<ol>
<li><strong>Explore the data</strong> provided by the sensor - Inspect the raw data in the terminal (Refer to the datasheet if needed to understand parameters - max/min measurable range, FOW, etc.)</li>
<li><strong>Visualize the data</strong> in <code>rqt</code> (or <code>Rviz</code> - use <code>Range</code> display)</li>
<li><strong>Create a new ROS 2 node</strong> for processing ultrasonic data
<ul>
<li>Create <code>ultrasonic_node.hpp</code> and <code>ultrasonic_node.cpp</code> in <code>nodes</code> directories</li>
<li>In this node, <strong>subscribe to the topic and process incoming data</strong></li>
</ul>
</li>
<li><strong>Think critically about the data</strong>
<ul>
<li>What do the sensor values actually represent?</li>
<li>Are the sensor readings stable and consistent over time?</li>
</ul>
<blockquote>
<p><strong>TIP:</strong> Data is often affected by noise, reflections, and material properties. You may want to ignore extreme or invalid values. Consider applying filtering, such as a moving average or median filter</p>
</blockquote>
<ul>
<li>If needed, implement a simple filtering algorithm to reduce noise or focus only on relevant angles (e.g. front, sides)</li>
</ul>
</li>
</ol>
<h2 id="implementing-basic-obstacle-detection-approx-40-minutes"><a class="header" href="#implementing-basic-obstacle-detection-approx-40-minutes">Implementing basic Obstacle Detection (Approx. 40 minutes)</a></h2>
<p>Use your chosen sensor (LiDAR or ultrasonic) to detect whether an object is too close to the robot — for example, less than 30 cm in front. If an obstacle is detected, the robot should stop and wait instead of continuing forward. This simple reactive behavior is an essential first step toward more advanced navigation strategies such as obstacle avoidance, corridor following, or autonomous path planning.</p>
<hr />
<p><strong>TASK 2</strong></p>
<ol>
<li><strong>Create a new ROS 2 node</strong> called <code>corridor_loop</code> in the <code>loops</code> directory. This node should be similar to the <code>line_loop</code> from the previous labs. In this node, you will gradually implement the entire functionality for <em>Corridor Following</em></li>
<li>Use the sensor data from <em>Task 1</em>. Based on this data, <strong>implement a simple algorithm for Obstacle Detection</strong>:</li>
<li>Retrieve the data from the sensors</li>
<li>If the reading is <strong>below a threshold you define</strong>, this means the <strong>robot is close enough to detect the obstacle</strong></li>
<li><strong>Test the obstacle detection</strong> to ensure the robot detects objects correctly when they are within the defined range.</li>
<li><strong>Create basic obstacle avoidance</strong> logic:</li>
<li>Make the robot drive forward</li>
<li>When an obstacle is detected, the robot <strong>must stop and not continue moving!</strong></li>
</ol>
<blockquote>
<p>More <strong>advanced avoidance behaviors</strong> (e.g., turning) will be covered in next lab.</p>
</blockquote>
<h2 id="implementing-corridor-following-behavior-approx-60-minutes"><a class="header" href="#implementing-corridor-following-behavior-approx-60-minutes">Implementing Corridor Following behavior (Approx. 60 minutes)</a></h2>
<p><em>Corridor following</em> allows the robot to stay centered between two walls by adjusting its heading based on distance measurements from both sides. In this task, you will use your sensor data (e.g. LiDAR or ultrasonic) to calculate the lateral error (difference between left and right distances) and correct the robot’s trajectory using proportional control.</p>
<p id="bangDiagram" align="center">
  <img src="2_labs/text/../images/corridor_following.png" alt="alt text" width="620" height="410">
</p>
<p align="center">
    <em> Figure 1: Corridor following Behavior. a) <strong>Flowchart</strong> of the corridor following algorithm; b) Robot behavior based on the computed lateral error <code>e</code> </em>
</p>
<hr />
<p><strong>TASK 3</strong></p>
<ol>
<li><strong>Implement the corridor-following algorithm</strong> based on the flowchart displayed above.</li>
<li><strong>Test and tune the algorithm</strong> to find the optimal solution for corridor following. (You may use the <code>pid.hpp</code> for advanced control if desired.)</li>
</ol>
<blockquote>
<p><strong>Note:</strong> It is recommended to test corridor following in environments where the turns are not too sharp. This issue will be addressed in the next lab.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-10--orientation-aware-corridor-navigation"><a class="header" href="#lab-10--orientation-aware-corridor-navigation">Lab 10 – Orientation-Aware Corridor Navigation</a></h1>
<p><strong>Responsible:</strong> Ing. Petr Šopák</p>
<h3 id="learning-objectives-3"><a class="header" href="#learning-objectives-3">Learning Objectives</a></h3>
<p><strong>1) Understanding robot orientation using IMU (MPU6050)</strong></p>
<ul>
<li>Interpreting raw gyroscope data</li>
<li>Calibrating and integrating gyro values to estimate yaw</li>
</ul>
<p><strong>2) Extending corridor following with corner handling</strong></p>
<ul>
<li>Detecting turns (e.g. 90° corners) using range sensors</li>
<li>Executing rotation using IMU feedback</li>
</ul>
<p><strong>3) Implementing a state-based navigation strategy</strong></p>
<ul>
<li>Designing a simple state machine</li>
<li>Switching between corridor following and turning behavior</li>
</ul>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>In <strong>Lab 9</strong>, you implemented a basic reactive controller that allowed the robot to follow straight corridors using range sensors such as LiDAR or ultrasonic. However, this approach assumes that the path is straight and cannot handle corners or sharp turns.</p>
<p>In this lab, you will enhance that behavior by enabling your robot to detect and turn into new corridor directions (e.g., 90° left or right turns). To accomplish this, you will use an <strong>Inertial Measurement Unit (IMU)</strong> — specifically the <strong>MPU6050</strong> (<a href="https://www.alldatasheet.com/datasheet-pdf/pdf/1132807/TDK/MPU-6050.html#:%7E:text=Part%20#:%20MPU-6050.%20Download.%20File%20Size:%20905Kbytes.%20Page:,MotionTracking%20Device%20with%20DMP%20(MPU-6050/-6000).%20Manufacturer:%20TDK%20Electronics.">LINK</a>) — to estimate the robot's yaw (rotation around the vertical axis).</p>
<p>The robot will:</p>
<ul>
<li>Follow the corridor as before</li>
<li>Detect the corner</li>
<li>Rotate in place until it is aligned with the new corridor direction</li>
<li>Resume forward motion</li>
</ul>
<p>To implement this, you will also develop a simple <strong>finite state machine</strong> with at least two states: <em>CORRIDOR_FOLLOWING</em> and <em>TURNING</em>.</p>
<h2 id="imu-and-orientation-estimation-approx-70-minutes"><a class="header" href="#imu-and-orientation-estimation-approx-70-minutes">IMU and Orientation Estimation (Approx. 70 minutes)</a></h2>
<p>The MPU6050 sensor provides raw data from a gyroscope and accelerometer. Unlike more advanced IMUs, it does not provide direct orientation estimates such as yaw, pitch, or roll.</p>
<p>To estimate yaw (rotation angle), you will:</p>
<ol>
<li><strong>Read the raw gyroscope value for the z-axis</strong> (<code>gyro_z</code>), which represents angular velocity around the vertical axis.</li>
<li><strong>Calibrate</strong>:
<ul>
<li>Keep the robot still for 2–5 seconds after startup.</li>
<li>Collect multiple <code>gyro_z</code> values.</li>
<li>Compute the average value as the <code>gyro_offset</code>.</li>
</ul>
</li>
<li><strong>Integrate over time</strong>:
<ul>
<li>Subtract the offset from each reading.</li>
<li>Multiply by the time delta (<code>dt</code>) to obtain the yaw angle increment.</li>
<li>Accumulate this over time to estimate the current yaw:</li>
</ul>
</li>
</ol>
<pre><code class="language-cpp">yaw += (gyro_z - offset) * dt;
</code></pre>
<h3 id="practical-integration-tip"><a class="header" href="#practical-integration-tip">Practical Integration Tip</a></h3>
<p>In this lab, you are required to implement the yaw integration yourself. No sensor fusion libraries will be used. Keep in mind that this method is sensitive to drift, so proper calibration is critical.</p>
<h3 id="corner-detection"><a class="header" href="#corner-detection">Corner Detection</a></h3>
<p>When following a corridor, the robot can monitor the side range sensors. If a wall suddenly &quot;disappears&quot; on one side (i.e., the distance becomes much larger), and the front is also open, it likely means the corridor turns in that direction.</p>
<p>An alternative strategy is to detect a wall in front of the robot (i.e., front distance drops below a defined threshold), and then search for an opening on the sides to determine where the corridor continues. However, this method is problematic in case of intersections, as the robot may overshoot the corner and fail to turn properly. </p>
<hr />
<p><strong>TASK 1 – IMU Integration and Yaw Estimation</strong></p>
<ol>
<li>Create a new ROS 2 node for the IMU (e.g., imu_node)</li>
<li><strong>Subscribe to the MPU6050 data</strong> and read <code>gyro_z</code> values from the topic. <em>A suggested node structure and a helper class are provided below this task</em></li>
<li><strong>Implement gyroscope calibration</strong>:
<ul>
<li>At the beginning of the program, keep the robot completely still for 2–5 seconds</li>
<li>During this time, collect several <code>gyro_z</code> values.</li>
<li>Compute the average of these samples to obtain the gyroscope offset <code>gyro_offset</code>.</li>
</ul>
<blockquote>
<p>You will subtract this offset from all future gyro readings to reduce drift</p>
</blockquote>
</li>
<li><strong>Estimate yaw (heading)</strong>:
<ul>
<li>In a timed loop, Subtract the <code>gyro_offset</code> from the current <code>gyro_z</code> value to get the <strong>corrected angular velocity</strong></li>
<li>Multiply the corrected value by the time delta <code>dt</code> to get the yaw increment</li>
<li>Accumulate this increment into a variable yaw that represents the current robot orientation (the formula was described before)</li>
</ul>
</li>
<li><strong>Test IMU-based yaw estimation and implement basic heading correction</strong>
<ol>
<li><strong>Manual Rotation test</strong>
<ul>
<li>Calibrate the IMU and after store the current yaw</li>
<li>Pick up or gently rotate the robot by approximately 90° (by hand)</li>
<li>The robot should detect the yaw error:
<pre><code class="language-c++">float yaw_error = yaw_ref - current_yaw;
</code></pre>
</li>
<li>If the error exceeds a threshold (e.g. 5°), apply a corrective rotation using differential motor speeds:
<pre><code class="language-c++">float correction = Kp * yaw_error;
motor_node-&gt;set_motor_speed(127 - correction, 127 + correction);
</code></pre>
</li>
<li><strong>The robot should rotate back toward its original orientation</strong></li>
</ul>
</li>
<li><strong>External Disturbance test</strong>
<ul>
<li>While the robot is driving straight or standing still, apply a light push to rotate it</li>
<li>The robot should detect the change in yaw and try to rotate back to its original heading based on the integrated yaw </li>
</ul>
<blockquote>
<p><strong>Always calibrate the IMU at the beginning</strong> — without proper calibration, even small disturbances will cause significant drift over time!</p>
</blockquote>
</li>
</ol>
</li>
</ol>
<p>Example of <code>imu_node.hpp</code>:</p>
<pre><code class="language-c++">#include &lt;rclcpp/rclcpp.hpp&gt;
#include &lt;sensor_msgs/msg/imu.hpp&gt;
#include &quot;solution/algorithms/planar_imu_integrator.hpp&quot;

namespace nodes {

    enum class ImuNodeMode {
        CALIBRATE,
        INTEGRATE,
    };

    class ImuNode : public rclcpp::Node {
    public:
        ImuNode();
        ~ImuNode() override = default;

        // Set the IMU Mode
        void setMode(const ImuNodeMode setMode)

        // Get the current IMU Mode
        ImuNodeMode getMode();

        // Get the results after Integration
        auto getIntegratedResults();

        // Reset the class
        void reset_imu();

    private:

        void calibrate();
        void integrate();

        ImuNodeMode mode = ImuNodeMode::INTEGRATE;

        rclcpp::Subscription&lt;sensor_msgs::msg::Imu&gt;::SharedPtr imu_subscriber_;
        algorithms::PlanarImuIntegrator planar_integrator_;

        std::vector&lt;float&gt; gyro_calibration_samples_;

        void on_imu_msg(const sensor_msgs::msg::Imu::SharedPtr msg);
    };
}
</code></pre>
<p>To simplify your IMU logic, use a helper class <code>planar_imu_integrator.hpp</code> to encapsulate yaw estimation. If you later want to include velocity or position tracking, you’ll need to extend the structure. (Don't forget to write the tests)</p>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;cmath&gt;
#include &lt;numeric&gt;

namespace algorithms {

    class PlanarImuIntegrator {
    public:

        PlanarImuIntegrator() : theta_(0.0f), gyro_offset_(0.0f) {}

        // TODO: Call this regularly to integrate gyro_z over time
        void update(float gyro_z, double dt);

        // TODO: Calibrate the gyroscope by computing average from static samples
        void setCalibration(std::vector&lt;float&gt; gyro);

        // TODO: Return the current estimated yaw
        [[nodiscard]] float getYaw() const;

        // TODO: Reset orientation and calibration
        void reset();

    private:
        float theta_;       // Integrated yaw angle (radians)
        float gyro_offset_; // Estimated gyro bias
    };
}
</code></pre>
<h2 id="state-machine-for-corridor-navigation-approx-70-minutes"><a class="header" href="#state-machine-for-corridor-navigation-approx-70-minutes">State Machine for Corridor Navigation (Approx. 70 minutes)</a></h2>
<p>If you have implemented the IMU, you are now ready to <strong>extend your corridor-following behavior</strong>. In this lab, you will implement a simple <strong>state machine</strong> to structure the robot's behavior during navigation. Instead of relying on a single control strategy, your robot will dynamically switch between multiple modes:</p>
<ul>
<li><strong>CALIBRATION</strong> – the robot stays still and computes IMU offset before navigation begins</li>
<li><strong>CORRIDOR_FOLLOWING</strong> – the robot drives straight and uses side range sensors to stay centered between walls</li>
<li><strong>TURNING</strong> – the robot rotates in place using the IMU until a 90° turn is completed</li>
<li><em>(Later additions:)</em> <strong>INTERSECTION_HANDLING</strong>, <strong>DEAD_END_HANDLING</strong>, etc.</li>
</ul>
<p>This modular architecture will make your logic easier to extend in future — for example, adding states <strong>INTERSECTION_HANDLING</strong> (dvě či tři cesty), <strong>DEAD_END_HANDLING</strong> (slepá ulička) and more...</p>
<p id="state_machine" align="center">
  <img src="2_labs/text/../images/lab_10_state_machine.png" alt="alt text" width="400" height="200">
</p>
<p align="center">
    <em> Figure 1: Example state diagram for corridor-following behavior </em>
</p>
<blockquote>
<p><strong>Notes:</strong></p>
<ul>
<li>The structure below is just an example. You are free to design your own solution — <strong>don’t feel limited by this template!</strong></li>
<li>Keep your implementation modular so it can be extended in future</li>
<li>Always calibrate the IMU at startup to avoid drift in yaw estimation</li>
</ul>
</blockquote>
<hr />
<p><strong>TASK 2 - Implementing Corner Detection and Turning</strong></p>
<ol>
<li>In your <strong>corridor loop node</strong>, integrate the <strong>state machine logic</strong>
<ul>
<li>Example Structure:
<pre><code class="language-c++"> switch (state) {
  case CALIBRATION:
 // Wait until enough samples are collected
 // Once done, switch to CORRIDOR_FOLLOWING
 break;

   case CORRIDOR_FOLLOWING:
     // Keep centered using P/PID based on side distances
     // If front is blocked and one side is open → switch to TURNING
     break;
 
   case TURNING:
     // Use IMU to track rotation
     // Rotate until yaw changes by ±90°
     // Then return to CORRIDOR_FOLLOWING
     break;
 }
</code></pre>
</li>
</ul>
</li>
<li>In the <code>CORRIDOR_FOLLOWING</code> state:
<ul>
<li>Use side range sensor data to stay centered between walls.</li>
<li><strong>Monitor the front sensor</strong>: if the front distance falls below a threshold (e.g., &lt; 10 cm) and one side is open, detect a corner</li>
<li>Based on which side is open, decide the direction to turn (left or right)</li>
<li>Switch to the <code>TURNING</code> state</li>
</ul>
</li>
<li>In the <code>TURNING</code> state:
<ul>
<li>Store the current yaw as <code>yaw_start</code></li>
<li>Command the robot to rotate</li>
<li>Continuously read yaw and compare with <code>yaw_start</code></li>
<li>When the yaw change reaches ~90°, stop the rotation and switch back to <code>CORRIDOR_FOLLOWING</code></li>
</ul>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-11---visual-navigation-using-aruco-markers"><a class="header" href="#lab-11---visual-navigation-using-aruco-markers">Lab 11 - Visual Navigation Using ArUco Markers</a></h1>
<p>Responsible: Ing. Petr Šopák</p>
<h3 id="learning-objectives-4"><a class="header" href="#learning-objectives-4">Learning Objectives</a></h3>
<p><strong>1) Camera-based detection of visual markers</strong></p>
<ul>
<li>Subscribing to a camera image topic</li>
<li>Converting ROS image messages to OpenCV format</li>
<li>Detecting ArUco markers using a provided detector</li>
</ul>
<p><strong>2) Using markers for high-level decision making</strong></p>
<ul>
<li>Associating marker IDs with semantic instructions (e.g., “turn left”, “goal”)</li>
<li>Storing and reusing symbolic information</li>
<li>Implementing logic that uses past observations during navigation</li>
</ul>
<h2 id="requirement"><a class="header" href="#requirement">Requirement</a></h2>
<p>For this lab, you need to have the <code>image transport compressed package</code> installed:</p>
<pre><code class="language-shell">sudo apt update
sudo apt install ros-humble-image-transport-plugins -y
</code></pre>
<p>To check all available transport plugins, run:</p>
<pre><code class="language-shell">ros2 run image_transport list
</code></pre>
<p>You should see an output similar to:</p>
<pre><code class="language-shell">Declared transports:
image_transport/compressed
image_transport/compressedDepth
image_transport/raw
image_transport/theora

Details:
...
</code></pre>
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<p>In previous labs, you explored sensor-based navigation using range sensors and IMUs. These approaches allowed the robot to react to its surroundings, but they did not provide access to symbolic information or long-term guidance.</p>
<p>In this lab, your robot will <strong>navigate through a maze where ArUco markers act as visual hints</strong>. These markers are placed at strategic locations and convey semantic instructions, such as which direction to take at an intersection, or where a shortcut to a goal (e.g., treasure) can be found.</p>
<p>The robot’s goal is to <strong>detect the markers, interpret their meaning, and use this information later</strong> when making decisions in the maze. This symbolic memory allows the robot to act in a more informed and efficient way, rather than relying solely on reactive behaviors.</p>
<h2 id="camera-and-marker-detection-approx-50-minutes"><a class="header" href="#camera-and-marker-detection-approx-50-minutes">Camera and Marker Detection (Approx. 50 minutes)</a></h2>
<p>In the first part of the lab, you will implement a ROS 2 node (<code>CameraNode</code>) that subscribes to a camera image stream, converts the received image into OpenCV format, and detects ArUco markers.</p>
<h2 id="you-are-provided-with-a-partial-implementation-of-the-arucodetector-class-your-task-is-to-complete-this-class-and-integrate-it-into-your-ros-node"><a class="header" href="#you-are-provided-with-a-partial-implementation-of-the-arucodetector-class-your-task-is-to-complete-this-class-and-integrate-it-into-your-ros-node">You are provided with a partial implementation of the <code>ArucoDetector</code> class. Your task is to complete this class and integrate it into your ROS node.</a></h2>
<p><strong>TASK 1 – Camera Subscription and Marker Detection</strong></p>
<ol>
<li>Create a new ROS 2 node - <code>camera_node</code>
<ul>
<li>Subscribe to a camera image topic (<code>/bpc_prp_robot/camera/compressed</code>) using <code>sensor_msgs/msg/compressed_image.hpp</code></li>
<li>In the callback, decode the incoming compressed image message using <code>cv::imdecode</code> to obtain a <code>cv::Mat</code> in <code>BGR</code> format (equivalent to <code>bgr8</code>)</li>
<li>Check if the decoded image is valid (not empty) before processing</li>
</ul>
</li>
<li><strong>Detect ArUco markers in the image</strong>:
<ul>
<li>Use the provided <code>aruco_detector.hpp</code> (insert it to <code>algorithms</code> folder) and complete the class</li>
<li>The detector will return a list of marker IDs and corner coordinates
<pre><code class="language-c++"> #include &lt;opencv2/opencv.hpp&gt;
 #include &lt;opencv2/aruco.hpp&gt;
 
 namespace algorithms {
 
     class ArucoDetector {
     public:
 
         // Represents one detected marker
         struct Aruco {
             int id;
             std::vector&lt;cv::Point2f&gt; corners;
         };
 
         ArucoDetector() {
             // Initialize dictionary with 4x4 markers (50 possible IDs)
             dictionary_ = cv::aruco::getPredefinedDictionary(cv::aruco::DICT_4X4_50);
         }
 
         ~ArucoDetector() = default;
 
         // Detect markers in the input image
         std::vector&lt;Aruco&gt; detect(cv::Mat frame) {
             std::vector&lt;Aruco&gt; arucos;
 
             std::vector&lt;int&gt; marker_ids;
             std::vector&lt;std::vector&lt;cv::Point2f&gt;&gt; marker_corners;
 
             // TODO: Detect markers using OpenCV
             // cv::aruco::detectMarkers(...);
 
             if (!marker_ids.empty()) {
                 std::cout &lt;&lt; &quot;Arucos found: &quot;;
                 for (size_t i = 0; i &lt; marker_ids.size(); i++) {
                     std::cout &lt;&lt; marker_ids[i] &lt;&lt; &quot; &quot;;
 
                     // TODO: Create Aruco struct and add to result vector
                     // arucos.emplace_back(...);
                 }
                 std::cout &lt;&lt; std::endl;
             }
 
             return arucos;
         }
 
     private:
         cv::Ptr&lt;cv::aruco::Dictionary&gt; dictionary_;
     };
 }
</code></pre>
</li>
</ul>
</li>
<li><strong>Store the last frame and detection results</strong>:
<ul>
<li>Save the latest image (<code>cv::Mat</code>) and detection data (<code>std::vector&lt;Aruco&gt;</code>)</li>
</ul>
</li>
<li><strong>Visualize the incoming camera stream</strong>
<ul>
<li>Publish the (optionally annotated) image using <code>image_transport::Publisher</code></li>
<li>View the image in <strong>rqt_image_view</strong> or <strong>RViz</strong> for debugging</li>
</ul>
<blockquote>
<p><strong>RViz Tip:</strong> Add -&gt; By Topic -&gt; Image -&gt; Rewrite Image Topic (in Displays) to <code>/bpc_prp_robot/camera/compressed</code></p>
</blockquote>
<ul>
<li>(Optional) Overlay detected markers on the image using <code>cv::aruco::drawDetectedMarkers</code> before publishing</li>
</ul>
</li>
</ol>
<h2 id="symbolic-navigation-logic-approx-40-minutes"><a class="header" href="#symbolic-navigation-logic-approx-40-minutes">Symbolic Navigation Logic (Approx. 40 minutes)</a></h2>
<p>In the second part of the lab, you will design logic that interprets the detected ArUco markers as instructions for maze navigation. Some markers indicate directions that lead to the exit, while others point toward the treasure. Your robot must recognize and remember these instructions, and then apply them later at decision points.</p>
<p>As illustrated in the figure 1, each instruction obtained from an ArUco marker is <strong>always intended for the next upcoming intersection</strong>. The robot must remember the marker’s content and apply it at the first junction it encounters after reading the marker.</p>
<p id="state_machine" align="center">
  <img src="2_labs/text/../images/lab11_maze_example.png" alt="alt text" width="450" height="600">
</p>
<p align="center">
    <em> Figure 1: Example of decision-making using ArUco markers in a maze </em>
</p>
<hr />
<p><strong>TASK 2 - Maze Logic and Decision Making</strong></p>
<ol>
<li>In your <strong>maze loop node</strong> (or a separate logic node):
<ul>
<li>Use the data obtained from the previous task</li>
<li>Define a mapping between marker IDs and symbolic instructions (see table below)</li>
<li>Remember that there are two types of markers: one for the <strong>exit path</strong>, and one for the <strong>treasure path</strong></li>
</ul>
<pre><code class="language-c++">Escape path:              Treasure Path:
ID = 0 -&gt; straight        ID = 10 -&gt; straight
ID = 1 -&gt; left            ID = 11 -&gt; left
ID = 2 -&gt; right           ID = 12 -&gt; right
</code></pre>
</li>
<li>Integrate the symbolic information into navigation logic
<ul>
<li>When a marker is detected, store the ID and its meaning</li>
<li>When the robot reaches the first intersection or decision point, use the stored instruction to select the direction</li>
<li>Based on the instruction (e.g., turn left), command the robot to rotate and follow the chosen path</li>
</ul>
<blockquote>
<p>TIP: Define which path (escape or treasure) has higher priority</p>
</blockquote>
</li>
<li>Test your logic and outputs</li>
</ol>
<h2 id="final-note"><a class="header" href="#final-note">Final Note</a></h2>
<p>This is the last lab in the course. We hope it helped you better understand the connection between perception, memory, and decision-making in robotics. You’ve now completed a full pipeline—from reading sensor data to interpreting symbolic cues and applying them in complex navigation tasks.</p>
<p>Good luck with your upcoming <strong>exam and final evaluation</strong>. Stay curious, keep experimenting, and don’t be afraid to challenge your solutions. We’ll be happy to see if you decide to join another course from our <strong>Robotics group</strong> in the future.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lab-12---midterm-test-corridor-following-1"><a class="header" href="#lab-12---midterm-test-corridor-following-1">Lab 12 - Midterm Test (Corridor Following)</a></h1>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<p>Up to 50 points can be earned through two practical demonstrations of task solutions during the semester.</p>
<p>8th week - Line Following (25 points)</p>
<p>12th week - Corridor Following (25 points)</p>
<h2 id="corridor-following-rules"><a class="header" href="#corridor-following-rules">Corridor Following Rules</a></h2>
<p>There are 3 tracks:</p>
<ul>
<li>Straight Corridor (5 points)</li>
<li>Simple Loop (10 points)</li>
<li>Complex Loop (10 points)</li>
</ul>
<p>Corridor is defined by walls.</p>
<p>All tracks are in rectangular grid of 40x40cm</p>
<p>Cells are marked by black tape on the ground.</p>
<p>The points are awarded only for completing the entire track.</p>
<ul>
<li>pass straight corridor without touching the wall</li>
<li>pass full loop</li>
<li>no wall touch allowed</li>
<li>no multiple cell entrance allowed</li>
</ul>
<p>Teams have 3 attempts per track, with a time limit of 3 minutes per attempt.</p>
<p>All 3 attempts have to be performed during a single lab.</p>
<h2 id="test-tracks-1"><a class="header" href="#test-tracks-1">Test Tracks</a></h2>
<ul>
<li>Walls - red lines</li>
<li>Path - green line</li>
<li>Start - green cell</li>
</ul>
<p><img src="2_labs/text/../images/corridor_tracks.png" alt="Test Track" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="final-exam---maze-escape-1"><a class="header" href="#final-exam---maze-escape-1">Final Exam - Maze Escape</a></h1>
<p>Responsible: Ing. Adam Ligocki, Ph.D.</p>
<p>The final exam is organized as a competition. Each team has 3 attempts to escape the maze with their robot, using the robot's full sensor capabilities. The score for the exam is based on the best of the three attempts.</p>
<ul>
<li>The robot starts inside the maze, in the center of the starting cell.</li>
<li>There is only one optimal escape path from the maze.</li>
<li>The maze contains no loops.</li>
<li>There are 3 randomly placed minotaurs and 1 treasure.
<ul>
<li>Each encounter with a minotaur results in a 30 seconds penalty.</li>
<li>Finding the treasure reduces the final time by 30 seconds.</li>
</ul>
</li>
<li>The maze consists of 8x8 cells, with each cell measuring 40x40 cm. Black lines on the floor mark the boundaries between cells.</li>
<li>ArUco tags will be placed on the maze ground, providing hints about the escape route, the presence of minotaurs, or the path to the treasure.</li>
</ul>
<p>In total for final exam the team can earn up to 50 points</p>
<ul>
<li>Maze escape up to 40 points
<ul>
<li>The formula for calculating the score is: <code>y=min(max(kx+q),0,40)</code></li>
</ul>
</li>
<li>Git and project documentation quality gives up to 10 points</li>
</ul>
<h2 id="attempt-rules"><a class="header" href="#attempt-rules">Attempt Rules</a></h2>
<ul>
<li>Teams have at least 45 minutes between attempts to modify their program.</li>
<li>The code used during the competition must be uploaded to Git by 11:59 PM on the same day.</li>
<li>The competition code must not contain specific information about the maze (e.g., paths, minotaur locations, etc.). Pre-known information, such as cell size, may be included.</li>
<li>Wall touching not allowed</li>
</ul>
<h2 id="maze-example"><a class="header" href="#maze-example">Maze Example</a></h2>
<ul>
<li>Walls - red lines</li>
<li>Escape path - green line</li>
<li>Start - green cell</li>
<li>Treasure (bonus) - blue cell</li>
<li>Minotaur (penalty) - red cell</li>
</ul>
<p><img src="2_labs/text/../images/maze.png" alt="Maze" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="robotic-topics"><a class="header" href="#robotic-topics">Robotic Topics</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="differential-chassis"><a class="header" href="#differential-chassis">Differential Chassis</a></h1>
<p>The differential drive chassis is one of the most common configurations for mobile robots. It consists of two independently controlled wheels mounted on the same axis and optionally a passive caster wheel for stability.</p>
<p>This tutorial introduces the fundamental concepts of differential drive kinematics and demonstrates how to derive the forward and inverse kinematics equations.</p>
<h2 id="components-of-a-differential-drive-chassis"><a class="header" href="#components-of-a-differential-drive-chassis">Components of a Differential Drive Chassis</a></h2>
<ul>
<li>Two wheels: Independently driven, providing linear and rotational motion.</li>
<li>Chassis: Holds the wheels, motors, and sensors.</li>
<li>Center of the robot: Defined as the midpoint between the two wheels.</li>
<li>Wheel radius (<code>r</code>): Radius of each wheel.</li>
<li>Wheel separation (<code>L</code>): Distance between the two wheels.</li>
</ul>
<h2 id="kinematic-model"><a class="header" href="#kinematic-model">Kinematic Model</a></h2>
<p>Pose <code>(x,y,θ)</code>: The robot's position <code>(x,y)</code> and orientation <code>θ</code> in a 2D plane. <code>[m, m, rad]</code></p>
<p>Linear velocity <code>(v)</code>: Forward speed of the robot. <code>[m/s]</code></p>
<p>Angular velocity <code>(ω)</code>: Rate of rotation of the robot. <code>[rad/s]</code></p>
<h2 id="wheel-velocities"><a class="header" href="#wheel-velocities">Wheel Velocities</a></h2>
<p>Left wheel angular velocity: <code>ωL</code>
Right wheel angular velocity: <code>ωR</code></p>
<p>The linear velocities of the wheels are:</p>
<p><img src="3_navigation/text/../images/dif_chass_vl_vr.png" alt="pid equation"/></p>
<h2 id="forward-kinematics"><a class="header" href="#forward-kinematics">Forward Kinematics</a></h2>
<p>Forward kinematics calculates the robot's linear and angular velocities based on wheel velocities.</p>
<h3 id="linear-and-angular-velocities"><a class="header" href="#linear-and-angular-velocities">Linear and Angular Velocities</a></h3>
<p>The robot's linear velocity <code>(v)</code> and angular velocity <code>(ω)</code> are:</p>
<p><img src="3_navigation/text/../images/dif_chass_v_omega.png" alt="forward kinematics"/></p>
<h3 id="pose-update"><a class="header" href="#pose-update">Pose Update</a></h3>
<p>Given the robot's current pose <code>(x,y,θ)</code>, the new pose after a small time step <code>dt</code> can be computed as:</p>
<p><img src="3_navigation/text/../images/dif_chass_update.png" alt="pose update"/></p>
<h2 id="inverse-kinematics"><a class="header" href="#inverse-kinematics">Inverse Kinematics</a></h2>
<p>Inverse kinematics computes the wheel velocities required to achieve a desired linear and angular velocity.</p>
<p>Given:</p>
<ul>
<li>Desired linear velocity <code>v</code>.</li>
<li>Desired angular velocity <code>ω</code>.</li>
</ul>
<p>The wheel velocities are:</p>
<p><img src="3_navigation/text/../images/dif_chass_inverse_v.png" alt="inverse kinematics, wheel speed"/></p>
<p>To compute angular velocities:</p>
<p><img src="3_navigation/text/../images/dif_chass_inverse_omega.png" alt="inverse kinematics, wheel speed"/></p>
<h2 id="example-code"><a class="header" href="#example-code">Example Code</a></h2>
<pre><code class="language-python">def forward_kinematics(v_L, v_R, L):
    v = (v_R + v_L) / 2
    omega = (v_R - v_L) / L
    return v, omega
</code></pre>
<pre><code class="language-python">def update_pose(x, y, theta, v, omega, dt):
    x_new = x + v * math.cos(theta) * dt
    y_new = y + v * math.sin(theta) * dt
    theta_new = theta + omega * dt
    return x_new, y_new, theta_new
</code></pre>
<pre><code class="language-python">def inverse_kinematics(v, omega, L):
    v_L = v - (omega * L / 2)
    v_R = v + (omega * L / 2)
    return v_L, v_R
</code></pre>
<h2 id="exercise-2"><a class="header" href="#exercise-2">Exercise</a></h2>
<p>Write program which simulates differential chassis based on given input parameters.</p>
<h3 id="simulation-parameters"><a class="header" href="#simulation-parameters">Simulation Parameters</a></h3>
<ul>
<li>Wheel radius: <code>r = 0.1 m</code></li>
<li>Wheel separation: <code>L = 0.15 m</code></li>
<li>Time step: <code>dt = 0.01 s</code></li>
</ul>
<h3 id="tasks-1"><a class="header" href="#tasks-1">Tasks</a></h3>
<ul>
<li>Compute the pose of the robot after moving straight for 5 seconds with <code>v = 1 m/s</code>.</li>
<li>Simulate a circular motion with <code>v = 1 m/s</code> and <code>ω = 0.5 rad/s</code> .</li>
<li>Simulate a circular motion with <code>ωl = 1 m/s</code> and <code>ωr = 0.5 rad/s</code> .</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pid"><a class="header" href="#pid">PID</a></h1>
<p>This tutorial introduces the concept of PID control and demonstrates how to implement it in a step-by-step manner, suitable for university-level students.</p>
<p>Proportional-Integral-Derivative (PID) control is one of the most widely used control algorithms in engineering and robotics. It is a feedback control mechanism used to maintain a desired setpoint by minimizing error in dynamic systems. PID controllers are found in applications ranging from industrial machinery to autonomous robots.</p>
<h2 id="pid-basics"><a class="header" href="#pid-basics">PID Basics</a></h2>
<p>A PID controller continuously calculates an error value <code>e(t)</code>, which is the difference between a desired setpoint <code>r(t)</code> and a measured process variable <code>y(t)</code>:</p>
<p><img src="3_navigation/text/../images/pid_e_equation.png" alt="error equation"/></p>
<p>The controller output <code>u(t)</code> is computed as:</p>
<p><img src="3_navigation/text/../images/pid_pid_equation.png" alt="pid equation"/></p>
<p>where:</p>
<ul>
<li><code>Kp</code> is Proportional gain.</li>
<li><code>Ki</code> is Integral gain.</li>
<li><code>Kd</code> is Derivative gain.</li>
</ul>
<h3 id="proportional-control-kp"><a class="header" href="#proportional-control-kp">Proportional Control <code>Kp</code>:</a></h3>
<p>Responds to the current error.
Larger <code>Kp</code> leads to a faster response but may overshoot.</p>
<p><img src="3_navigation/text/../images/pid_p_equation.png" alt="p equation"/></p>
<h3 id="integral-control-ki"><a class="header" href="#integral-control-ki">Integral Control <code>Ki</code></a></h3>
<p>Responds to the accumulation of past errors.
Helps eliminate steady-state error.</p>
<p><img src="3_navigation/text/../images/pid_i_equation.png" alt="i equation"/></p>
<h3 id="derivative-control-kd"><a class="header" href="#derivative-control-kd">Derivative Control <code>Kd</code></a></h3>
<p>Responds to the rate of change of the error.
Predicts future behavior and reduces overshoot.</p>
<p><img src="3_navigation/text/../images/pid_d_equation.png" alt="d equation"/></p>
<h2 id="pid-implementation"><a class="header" href="#pid-implementation">PID Implementation</a></h2>
<p>In digital systems, the continuous equation is approximated using discrete time intervals (dt):</p>
<p><img src="3_navigation/text/../images/pid_psd_equation.png" alt="psd equation"/></p>
<h3 id="algorithm"><a class="header" href="#algorithm">Algorithm</a></h3>
<ul>
<li>Measure the current system output <code>y[k]</code>.</li>
<li>Calculate the error: <code>e[k] = r[k] − y[k]</code>.</li>
<li>Compute the proportional, integral, and derivative terms.</li>
<li>Combine the terms to compute <code>u[k]</code>.</li>
<li>Apply <code>u[k]</code> to the system.</li>
<li>Repeat.</li>
</ul>
<h2 id="example-code-1"><a class="header" href="#example-code-1">Example Code</a></h2>
<pre><code class="language-python">class PIDController:

    def __init__(self, kp, ki, kd, setpoint):
        self.kp = kp 
        self.ki = ki  
        self.kd = kd 
        self.setpoint = setpoint

        self.previous_error = 0
        self.integral = 0

    def update(self, measured_value, dt):
        error = self.setpoint - measured_value
        
        # P
        proportional = self.kp * error
        
        # I
        self.integral += error * dt
        integral = self.ki * self.integral
        
        # D
        derivative = self.kd * (error - self.previous_error) / dt
        
        self.previous_error = error
        output = proportional + integral + derivative
        return output
</code></pre>
<h2 id="pid-tuning"><a class="header" href="#pid-tuning">PID Tuning</a></h2>
<h3 id="manual-tuning"><a class="header" href="#manual-tuning">Manual Tuning</a></h3>
<p>Start with <code>Ki = 0</code> and <code>Kd = 0</code>.
Increase <code>Kp</code> until the system oscillates.
Increase <code>Kd</code> to dampen oscillations.
Introduce <code>Ki</code> to eliminate steady-state error.</p>
<h3 id="ziegler-nichols-method"><a class="header" href="#ziegler-nichols-method">Ziegler-Nichols Method</a></h3>
<p>Set <code>Ki=0</code> and <code>Kd = 0</code>.
Increase <code>Kp</code> until the system oscillates with constant amplitude.
Note the critical gain <code>Ku</code> and period <code>Tu</code>.
Set parameters as:</p>
<ul>
<li><code>Kp = 0.6 * Ku</code></li>
<li><code>Ki = 2 * Kp / Tu</code></li>
<li><code>Kd = Kp * Tu / 8</code></li>
</ul>
<h3 id="common-problems"><a class="header" href="#common-problems">Common Problems</a></h3>
<p><img src="3_navigation/text/../images/pid_plot.png" alt="psd equation"/></p>
<ul>
<li>Low <code>Kp</code> (slow response): The system reacts very slowly, taking a long time to reach the setpoint.</li>
<li>High <code>Kp</code> (oscillations): The system overshoots and oscillates around the setpoint without damping.</li>
<li>Proportional + Integral (steady-state error eliminated): The system reaches the setpoint but with overshoot and slower settling time.</li>
<li>Proportional + Integral + Derivative (optimal tuning): The system reaches the setpoint quickly and without overshoot, showing balanced performance.</li>
<li>High <code>Ki</code> (overshoot and oscillations): Integral action dominates, causing overshoot and sustained oscillations.</li>
<li>High <code>Kd</code> (noise sensitivity): The derivative term overly reacts to changes, leading to instability or erratic behavior.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="line-following"><a class="header" href="#line-following">Line Following</a></h1>
<p>This guide explains how to regulate a differential chassis robot with two front-mounted line sensors to follow a line.</p>
<h2 id="basic-concepts"><a class="header" href="#basic-concepts">Basic Concepts</a></h2>
<h3 id="differential-chassis-1"><a class="header" href="#differential-chassis-1">Differential Chassis</a></h3>
<p>A differential chassis robot uses two independently controlled wheels to steer. Adjusting the speed of each wheel allows the robot to move forward, turn, or rotate in place. Key movements include:</p>
<p>Forward Movement: Both wheels move at the same speed.</p>
<p>Left Turn: The right wheel moves faster than the left.</p>
<p>Right Turn: The left wheel moves faster than the right.</p>
<h3 id="line-sensors"><a class="header" href="#line-sensors">Line Sensors</a></h3>
<p>Line sensors detect the contrast between a dark line and a lighter surface. Typically, two sensors are placed near the robot's front. Outputs:</p>
<p>Left Sensor (S1): Detects the line under the left side.</p>
<p>Right Sensor (S2): Detects the line under the right side.</p>
<p>Sensors usually output digital signals (1 for line detected, 0 for no line) or the analog signal (high voltage for line detected, low voltage for no line).</p>
<h3 id="control-principles"><a class="header" href="#control-principles">Control Principles</a></h3>
<p>Robots use control algorithms to maintain their position relative to the line. Key approaches:</p>
<p>Bang-Bang Control: Simple on/off control based on sensor inputs.</p>
<p>P(I)D Control: Smooth control using proportional and derivative terms based on sensor data.</p>
<h2 id="line-following-algorithm"><a class="header" href="#line-following-algorithm">Line Following Algorithm</a></h2>
<h3 id="bang-bang-control"><a class="header" href="#bang-bang-control">Bang-Bang Control</a></h3>
<p>Logic Table: Define responses based on sensor inputs:</p>
<table><thead><tr><th>S1</th><th>S2</th><th>Action</th></tr></thead><tbody>
<tr><td>1</td><td>1</td><td>Move forward</td></tr>
<tr><td>1</td><td>0</td><td>Turn left</td></tr>
<tr><td>0</td><td>1</td><td>Turn right</td></tr>
<tr><td>0</td><td>0</td><td>Stop or search</td></tr>
</tbody></table>
<p>Implementation:</p>
<p>If both sensors detect the line, drive both wheels forward.</p>
<p>If only the left sensor detects the line, slow down the left wheel and speed up the right wheel.</p>
<p>If only the right sensor detects the line, slow down the right wheel and speed up the left wheel.</p>
<p>If neither sensor detects the line, stop or initiate a search pattern.</p>
<h3 id="pid-control"><a class="header" href="#pid-control">P(I)D Control</a></h3>
<p>PD control improves performance by considering how far the robot deviates from the line and how fast the deviation changes.</p>
<p>Error Calculation:</p>
<ul>
<li>Define error as the difference between sensor readings, e.g., ε = S₁ - S₂.</li>
<li>Use sensor output characteristics to determinate how far is S1 and S2 from the line center and estimate most probable position of the robot with respect to the line center.</li>
</ul>
<p>Control Formula:</p>
<ul>
<li>Adjust motor speeds using:
<ul>
<li>P-Term: Proportional to error (ε).</li>
<li>D-Term: Proportional to the rate of change of error (∆ε / Δt).</li>
</ul>
</li>
</ul>
<pre><code>Left Motor Speed = Base Speed - (Kp * ε + Kd * ∆ε / Δt)
Right Motor Speed = Base Speed + (Kp * ε + Kd * ∆ε / Δt)
</code></pre>
<h3 id="flowchart-of-the-algorithm"><a class="header" href="#flowchart-of-the-algorithm">Flowchart of the Algorithm</a></h3>
<ul>
<li>Read sensor values.</li>
<li>Calculate the error (∆ε) and its derivative (Δ∆ε / Δt).</li>
<li>Determine motor speeds using the control formula.</li>
<li>Drive the motors.</li>
<li>Repeat.</li>
</ul>
<h3 id="example-arduino-implementation"><a class="header" href="#example-arduino-implementation">Example Arduino Implementation</a></h3>
<pre><code class="language-c++">#define S1_PIN A0
#define S2_PIN A1
#define MOTOR_LEFT_PWM 3
#define MOTOR_RIGHT_PWM 5

float Kp = 0.5, Kd = 0.1;
float baseSpeed = 150;
float lastError = 0;

void setup() {
  pinMode(S1_PIN, INPUT);
  pinMode(S2_PIN, INPUT);
}

void loop() {
  int S1 = digitalRead(S1_PIN);
  int S2 = digitalRead(S2_PIN);

  float error = S1 - S2;
  float dError = error - lastError;

  float leftSpeed = baseSpeed - (Kp * error + Kd * dError);
  float rightSpeed = baseSpeed + (Kp * error + Kd * dError);

  analogWrite(MOTOR_LEFT_PWM, constrain(leftSpeed, 0, 255));
  analogWrite(MOTOR_RIGHT_PWM, constrain(rightSpeed, 0, 255));

  lastError = error;
}
</code></pre>
<h2 id="testing-and-calibration"><a class="header" href="#testing-and-calibration">Testing and Calibration</a></h2>
<p>Initial Test:</p>
<ul>
<li>Run the robot on a simple track.</li>
<li>Observe behavior and ensure it detects and follows the line.</li>
</ul>
<p>Tuning:</p>
<ul>
<li>Adjust Kp to improve responsiveness.</li>
<li>Adjust Kd to reduce oscillations.</li>
</ul>
<p>Advanced Testing:</p>
<ul>
<li>Test on complex tracks with curves and intersections.</li>
<li>Optimize sensor placement for better detection.</li>
</ul>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<ul>
<li>Robot veers off-line: Increase Kp.</li>
<li>Robot oscillates too much: Decrease Kd.</li>
<li>Robot fails to detect line: Ensure proper sensor calibration and placement.</li>
</ul>
<h2 id="extensions"><a class="header" href="#extensions">Extensions</a></h2>
<ul>
<li>Implement intersection handling.</li>
<li>Use more sensors for better precision.</li>
<li>Add PID control for further optimization.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="corridor-following"><a class="header" href="#corridor-following">Corridor Following</a></h1>
<p>This guide explains how to regulate a differential chassis robot equipped with a 2D 360-degree LIDAR to follow a rectangular grid corridor.</p>
<h2 id="background-concepts"><a class="header" href="#background-concepts">Background Concepts</a></h2>
<h3 id="differential-chassis-2"><a class="header" href="#differential-chassis-2">Differential Chassis</a></h3>
<p>A differential chassis robot uses two independently controlled wheels to steer. By varying the speed of each wheel, the robot can:</p>
<ul>
<li>Move Forward: Both wheels at the same speed.</li>
<li>Turn Left: Right wheel faster than the left.</li>
<li>Turn Right: Left wheel faster than the right.</li>
<li>Rotate in Place: Wheels move in opposite directions.</li>
</ul>
<h3 id="2d-lidar"><a class="header" href="#2d-lidar">2D LIDAR</a></h3>
<p>A 2D LIDAR scans the environment by emitting laser beams and measuring distances to objects. For a 360-degree LIDAR:</p>
<ul>
<li>Distance Data: Provides distances to nearby obstacles in all directions.</li>
<li>Angle Data: Maps each distance reading to a specific angle.</li>
</ul>
<h3 id="rectangular-grid-and-corridors"><a class="header" href="#rectangular-grid-and-corridors">Rectangular Grid and Corridors</a></h3>
<p>Corridors on a rectangular grid are linear paths with walls on either side. Key features:</p>
<ul>
<li>Wall Alignment: Corridors are straight or have right-angle turns.</li>
<li>Center Line: The robot must maintain its position relative to the corridor’s center.</li>
<li>Obstacle Detection: Walls define the boundaries, and gaps or openings indicate intersections or exits.</li>
</ul>
<h2 id="corridor-following-algorithm"><a class="header" href="#corridor-following-algorithm">Corridor Following Algorithm</a></h2>
<h3 id="key-steps"><a class="header" href="#key-steps">Key Steps</a></h3>
<ul>
<li>
<p>LIDAR Data Processing: Analyze LIDAR scans to detect walls and the robot’s position relative to them.</p>
</li>
<li>
<p>Error Calculation: Determine the deviation from the corridor’s center line.</p>
</li>
<li>
<p>Control Response: Adjust wheel speeds to reduce the deviation.</p>
</li>
</ul>
<h3 id="wall-detection"><a class="header" href="#wall-detection">Wall Detection</a></h3>
<ul>
<li>Segment LIDAR Data: Divide the 360-degree scan into front, left, and right regions.</li>
<li>Identify Walls:
<ul>
<li>Use distance thresholds to detect walls.</li>
<li>(Optional) Fit linear equations to points to confirm wall alignment.</li>
</ul>
</li>
<li>Calculate Midpoint: Determine the midpoint between the detected walls to establish the center line.</li>
</ul>
<h3 id="error-calculation"><a class="header" href="#error-calculation">Error Calculation</a></h3>
<ul>
<li>Define Error: The lateral distance between the robot’s position and the center line.</li>
<li>Angle Deviation: If wall orientation is estimated use it to estimate the angular alignment of the robot relative to the corridor.</li>
<li>Combined Error: A weighted sum of lateral and angular errors.</li>
</ul>
<h3 id="control-algorithm"><a class="header" href="#control-algorithm">Control Algorithm</a></h3>
<p>Proportional-Derivative (PD) Control: Use proportional and derivative terms to regulate movement.</p>
<ul>
<li>P-Term: Corrects based on the current error.</li>
<li>D-Term: Dampens oscillations by considering the rate of error change.</li>
</ul>
<p>Control Formulas:</p>
<pre><code>Left Motor Speed = Base Speed - (Kp * Error + Kd * Derivative of Error)
Right Motor Speed = Base Speed + (Kp * Error + Kd * Derivative of Error)
</code></pre>
<p>Obstacle Handling: Stop or adjust speed if a sudden obstacle is detected within a threshold distance.</p>
<h2 id="example-pseudo-code"><a class="header" href="#example-pseudo-code">Example Pseudo Code</a></h2>
<pre><code class="language-python">import lidar_library
import motor_control

Kp = 0.5
Kd = 0.1
base_speed = 150
last_error = 0

lidar = lidar_library.LIDAR()
motors = motor_control.MotorDriver()

def detect_walls(scan):
    left_distances = [dist for angle, dist in scan if 80 &lt;= angle &lt;= 100]
    right_distances = [dist for angle, dist in scan if 260 &lt;= angle &lt;= 280]
    left_wall = min(left_distances)
    right_wall = min(right_distances)
    return left_wall, right_wall

while True:
    scan = lidar.get_scan()
    left_wall, right_wall = detect_walls(scan)

    error = (left_wall - right_wall) / 2
    d_error = error - last_error

    left_speed = base_speed - (Kp * error + Kd * d_error)
    right_speed = base_speed + (Kp * error + Kd * d_error)

    motors.set_speeds(left_speed, right_speed)
    last_error = error
</code></pre>
<h2 id="grid-pattern-following"><a class="header" href="#grid-pattern-following">Grid Pattern Following</a></h2>
<p>If the corridor is organized into rectangular grid. The algorithm is getting more complex.</p>
<p>Think about the corridor as a set of cells that contains spaces or obstacles between each other.</p>
<p>If the empty space appears on left or right, the algorithm have to overcome this difficulty and consider only existing walls.</p>
<p>If there is an obstacle in front of the robot, stop and consider turing robot left or right.</p>
<p>More advanced approach is to think about the grid corridor not as a continuous space, but rather discrete grid-cell space. Than the corridor following algorithm have to control robot during the inter-cell transitions. </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="imu-inertial-measurement-unit"><a class="header" href="#imu-inertial-measurement-unit">IMU (Inertial Measurement Unit)</a></h1>
<p>Note: in this tutorial, by using the &quot;gyroscope&quot; word, we mean angular speed sensor. Properly said, the gyroscope is device that keeps constant orientation.</p>
<p>In this tutorial, we will focus on how to process data from an Inertial Measurement Unit (IMU) to estimate orientation and position along a single degree of freedom (DoF). While an actual IMU measures 3-axis accelerations (from an accelerometer) and 3-axis angular velocities (from a gyroscope), we will simplify the problem by considering only one-dimensional motion and rotation. This simplification helps you gain intuition before extending the logic to three dimensions.</p>
<p>Key concepts:</p>
<ul>
<li>Angular velocity to orientation: If you know how fast something is rotating, you can integrate that angular rate over time to find how far it has rotated.</li>
<li>Acceleration to position: If you know the acceleration of something, you can integrate it once to get its velocity, and integrate again to find its position.</li>
</ul>
<p>This tutorial will walk you through the math and give you a step-by-step procedure, along with a conceptual example and code snippets.</p>
<h2 id="sensor-data-and-assumptions"><a class="header" href="#sensor-data-and-assumptions">Sensor Data and Assumptions</a></h2>
<p>An IMU in one dimension can be thought of as providing two main signals:</p>
<ul>
<li>Angular velocity, <code>ω(t)</code>, measured in radians per second <code>(rad/s)</code>. In a real IMU, this would come from the gyroscope (angular speed meter).</li>
<li>Linear acceleration, <code>a(t)</code>, measured in meters per second squared <code>(ms^-2)</code>. In a real IMU, this would come from the accelerometer.</li>
</ul>
<p>Assumptions to Simplify the Task:</p>
<ul>
<li>We assume motion and rotation occur along a single axis.</li>
<li>Gravity effects may be ignored or assumed to be pre-compensated. In practice, you must carefully handle gravity, but for this tutorial, we focus on the mechanics of integration only.</li>
<li>Noise and biases in the sensors are not considered for now. In reality, these need filtering and calibration.</li>
<li>Initial conditions (initial orientation and position) are known.</li>
</ul>
<p>Notation and Variables:</p>
<ul>
<li>Let <code>θ(t)</code> represent the orientation (angle) at time <code>t</code>.</li>
<li>Let <code>x(t)</code> represent the position at time <code>t</code>.</li>
<li>Given data: <code>ω(t)</code> and <code>a(t)</code>.</li>
<li>Known initial conditions: <code>θ(0) = θ</code> and <code>x(0) = x</code>, and possibly initial velocity <code>v(0) = v0</code>.</li>
</ul>
<h2 id="from-angular-velocity-to-orientation"><a class="header" href="#from-angular-velocity-to-orientation">From Angular Velocity to Orientation</a></h2>
<p>Orientation (in 1D, simply an angle) is related to angular velocity by the first-order differential equation:</p>
<p><img src="3_navigation/text/../images/imu_orientation_diff.png" alt="Derivation of orientation"/></p>
<p>To obtain <code>θ(t)</code>, you integrate the angular velocity over time:</p>
<p><img src="3_navigation/text/../images/imu_angular_speed_int.png" alt="Integration of angular velocity"/></p>
<p>If you sample <code>ω</code> at discrete time steps <code>tk = kΔt</code> (where <code>Δt</code> is the sampling period), you can approximate the integral numerically. A simple numerical integration (Euler method) is:</p>
<p><img src="3_navigation/text/../images/imu_orientatoin_int.png" alt="Integration of orientation"/></p>
<p>Here, <code>θk</code> and <code>ωk</code> are the angle and angular velocity at the kk-th timestep.</p>
<h2 id="from-linear-acceleration-to-position"><a class="header" href="#from-linear-acceleration-to-position">From Linear Acceleration to Position</a></h2>
<p>The position is related to acceleration by two integrations:</p>
<p>Acceleration to velocity:</p>
<p><img src="3_navigation/text/../images/imu_acc_to_vel.png" alt="Acceleration to velocity"/></p>
<p>Velocity to position:</p>
<p><img src="3_navigation/text/../images/imu_vel_to_position.png" alt="Velocity to position"/></p>
<p>Combining these, we get:</p>
<p><img src="3_navigation/text/../images/imu_acc_to_pose.png" alt="Acceleration to position"/></p>
<p>For discrete time steps, using Euler integration:</p>
<p>Update velocity:</p>
<p><img src="3_navigation/text/../images/imu_discrete_acc_to_speed.png" alt="Acceleration to velocity (discrete)"/></p>
<p>Update position:</p>
<p><img src="3_navigation/text/../images/imu_discrete_vel_to_pose.png" alt="Velocity to pose (discrete)"/></p>
<p>Note that the velocity used to update the position can be the already updated velocity <code>(vk+1)</code> or the old one <code>(vk)</code>, depending on your numerical integration choice. The simplest Euler method uses the old values:</p>
<p><img src="3_navigation/text/../images/imu_euler.png" alt="Euler method"/></p>
<p>But for clarity and consistency, you might update position using the updated velocity if you wish (this is a matter of integration scheme choice; either is acceptable for this tutorial).</p>
<h2 id="step-by-step-example"><a class="header" href="#step-by-step-example">Step-by-Step Example</a></h2>
<h3 id="setup"><a class="header" href="#setup">Setup:</a></h3>
<p>Assume a sampling frequency of <code>fs = 100 Hz</code> (<code>Δt = 0.01s</code>).</p>
<p>Suppose we have a constant angular velocity <code>ω = 0.1 rad/s</code> and a constant acceleration <code>a = 0.2 m/s</code>.</p>
<p>Initial orientation: <code>θ0 = 0 rad</code>.</p>
<p>Initial velocity: <code>v0 = 0 m/s</code>.</p>
<p>Initial position: <code>x0 = 0 m</code>.</p>
<h3 id="orientation-calculation"><a class="header" href="#orientation-calculation">Orientation Calculation:</a></h3>
<p><code>θk+1 = θk + ωkΔt</code>.</p>
<p>Since <code>ωk = 0.1 rad/s</code> is constant, after one step:</p>
<p><img src="3_navigation/text/../images/imu_ang_vel_int_step_1.png" alt="Angular velocity integration (1st step)"/></p>
<p>After 100 steps (1 second):</p>
<p><img src="3_navigation/text/../images/imu_ang_vel_int_step_100.png" alt="Angular velocity integration (after 100 steps)"/></p>
<h3 id="position-calculation"><a class="header" href="#position-calculation">Position Calculation:</a></h3>
<p>Velocity update:</p>
<p><img src="3_navigation/text/../images/imu_vel_update_step_1.png" alt="Velocity update, step 1"/></p>
<p>After the first step:</p>
<p><img src="3_navigation/text/../images/imu_vel_update_step_1_2.png" alt="Velocity update, step 1"/></p>
<p>Position update:</p>
<p><img src="3_navigation/text/../images/imu_pose_update_step_1.png" alt="Pose update, step 1"/></p>
<p>(Since initial velocity is zero, position doesn't change in the first iteration.)</p>
<p>Next step:</p>
<p><img src="3_navigation/text/../images/imu_vel_pose_update_step_2.png" alt="Velocity and pose update, step 2"/></p>
<h2 id="practical-considerations"><a class="header" href="#practical-considerations">Practical Considerations</a></h2>
<ul>
<li>Noise and Biases: Real IMU data is noisy. Integrating noisy data leads to drift. In practice, filtering (e.g., using a Kalman filter or complementary filter) is essential.</li>
<li>Gravity Compensation: If you are working in 3D, you must subtract the gravity vector from the accelerometer reading to isolate the linear acceleration. In 1D, if your axis is aligned vertically, you must subtract out <code>g = 9.81 ms^-2</code>.</li>
<li>Sampling Rate and Integration Method: We used a simple Euler method. More accurate integration schemes (e.g., trapezoidal, Runge-Kutta) can improve accuracy.</li>
</ul>
<h2 id="example-code-2"><a class="header" href="#example-code-2">Example Code</a></h2>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# Simulation parameters
fs = 100.0              # sampling frequency (Hz)
dt = 1.0/fs             # time step
t_end = 5.0             # total duration (s)
t = np.arange(0, t_end, dt)

# Given sensor readings (for demonstration)
omega = 0.1 * np.ones_like(t)  # rad/s
a = 0.2 * np.ones_like(t)       # m/s^2

# Initial conditions
theta_0 = 0.0
x_0 = 0.0
v_0 = 0.0

# Allocate arrays for orientation, velocity, and position
theta = np.zeros_like(t)
v = np.zeros_like(t)
x = np.zeros_like(t)

theta[0] = theta_0
v[0] = v_0
x[0] = x_0

# Numerical integration
for k in range(len(t)-1):
    # Integrate orientation
    theta[k+1] = theta[k] + omega[k]*dt

    # Integrate velocity
    v[k+1] = v[k] + a[k]*dt

    # Integrate position
    x[k+1] = x[k] + v[k]*dt

# Plot results
plt.figure(figsize=(12,6))

plt.subplot(3,1,1)
plt.plot(t, theta, label='Orientation (rad)')
plt.xlabel('Time (s)')
plt.ylabel('Theta (rad)')
plt.title('Orientation from Angular Velocity')

plt.subplot(3,1,2)
plt.plot(t, v, label='Velocity (m/s)')
plt.xlabel('Time (s)')
plt.ylabel('Velocity (m/s)')
plt.title('Velocity from Acceleration')

plt.subplot(3,1,3)
plt.plot(t, x, label='Position (m)')
plt.xlabel('Time (s)')
plt.ylabel('Position (m)')
plt.title('Position from Acceleration')

plt.tight_layout()
plt.show()
</code></pre>
<p><img src="3_navigation/text/../images/imu_plot.png" alt="Simulation plot"/></p>
<p>Tip: Try to add some random noise to measured signals.</p>
<h2 id="advanced-topics-future-robotics-courses"><a class="header" href="#advanced-topics-future-robotics-courses">Advanced Topics (future robotics courses)</a></h2>
<ul>
<li>Extend the logic to 3D, working with vectors and rotation representations (e.g., Euler angles, quaternions).</li>
<li>Implement filtering techniques to handle noise (e.g., a complementary filter to fuse accelerometer and gyroscope data).</li>
<li>Learn how to remove gravity from the accelerometer measurements in real-world scenarios.</li>
<li>Implement full 3D orientation estimation with drift compensation (lin acc to estimate gravity direction, gyro for quick orientation updates).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="maze-escape"><a class="header" href="#maze-escape">Maze Escape</a></h1>
<p>Lorem Ipsum</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="others-intro"><a class="header" href="#others-intro">Others Intro</a></h1>
<p>Lorem Ipsum</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="linux"><a class="header" href="#linux">Linux</a></h1>
<h2 id="installation-1"><a class="header" href="#installation-1">Installation</a></h2>
<p>To install Linux Ubuntu, please follow the <a href="https://ubuntu.com/tutorials/install-ubuntu-desktop#1-overview">official documentation</a>.</p>
<h3 id="virtualbox-installation-vb"><a class="header" href="#virtualbox-installation-vb">VirtualBox Installation (VB)</a></h3>
<p>In case you have no physical computer available for clean Linux installation nor the possibility for a dual boot, consider installing the Linux into the virtual machine.</p>
<p>The VirtualBox is and example of the virtual machine engine that allows you to run Linux on a different host system.</p>
<p>Install VirtualBox following the instructions for your respective operating system.</p>
<p>Steps for <a href="https://www.virtualbox.org/wiki/Downloads">Windows a Mac</a>.</p>
<p>For Linux, the installation process depends on your distribution and package management system. On Debian, use the command sudo apt install virtualbox. After installation, you can launch VirtualBox either from the terminal by typing virtualbox or by clicking its icon in the list of installed programs.</p>
<p>To install the Ubuntu Linux into the virtual machine, please follow the <a href="https://ubuntu.com/tutorials/how-to-run-ubuntu-desktop-on-a-virtual-machine-using-virtualbox#1-overview">official documentation</a></p>
<h2 id="cli-command-line-interface"><a class="header" href="#cli-command-line-interface">CLI (Command Line Interface)</a></h2>
<p>Consider this chapter as a guide for working in the Linux operating system.</p>
<p>You don't need to memorize all the commands and their parameters, but you should be familiar with them and able to look up their </p>
<p>For more details, please find the detail <a href="https://assets.ubuntu.com/v1/2950553c-OpenStack%20cheat%20sheet%20-%20revised%20v3.pdf?_gl=1*112oq19*_gcl_au*MTE5NjAyMjU0Ni4xNzM1OTQyNzI4&amp;_ga=2.153041082.2070240710.1735942727-373166696.1735942726">cheat sheet</a> at official web site</p>
<h3 id="command"><a class="header" href="#command">Command</a></h3>
<p>Explanation of function</p>
<pre><code>Example usage      ...      Explanation
</code></pre>
<h3 id="ls---list"><a class="header" href="#ls---list">ls - (list)</a></h3>
<p>Displays all files and directories (a directory is also a type of file) in the current point of the file system.</p>
<pre><code>ls
ls -la      ...      lists all files, including hidden ones, and provides detailed information
</code></pre>
<h3 id="cd---change-directory"><a class="header" href="#cd---change-directory">cd - (change directory)</a></h3>
<p>Changes the current directory.</p>
<pre><code>cd my_directory      ...      moves into the directory named &quot;my_directory&quot;
cd ~                 ...      returns to the home directory (referred to as &quot;home&quot; in Linux)
cd ..                ...      moves up one directory level
cd /                 ...      returns to the root of the file system (called &quot;root&quot; in Linux)
cd ../my_folder      ...      moves up one directory level and then into the &quot;my_folder&quot; directory
cd .                 ...      stays in the current directory. Essentially does nothing, illustrating the use of &quot;.&quot; for the current directory.
</code></pre>
<h3 id="pwd---print-working-directory"><a class="header" href="#pwd---print-working-directory">pwd - print working directory</a></h3>
<p>Displays the current position in the file system.</p>
<pre><code>pwd
</code></pre>
<h3 id="mkdir---make-directory"><a class="header" href="#mkdir---make-directory">mkdir - (make directory)</a></h3>
<p>Creates a new directory.</p>
<pre><code>mkdir my_folder      ...      creates a new directory named &quot;my_folder&quot;
</code></pre>
<h3 id="cp---copy"><a class="header" href="#cp---copy">cp - (copy</a></h3>
<p>Copies a file.</p>
<pre><code>cp source_file destination_file                    ...      creates a new copy of &quot;source_file&quot; named &quot;destination_file&quot;
cp ../secret.txt secret_folder/supersecret.txt      ...      takes the &quot;secret.txt&quot; file located one directory up and copies it to the &quot;secret_folder&quot;. The copy will be named &quot;supersecret.txt&quot;.
</code></pre>
<h3 id="mv---move"><a class="header" href="#mv---move">mv - (move)</a></h3>
<p>Originally used for moving files, but is now primarily used to rename files.</p>
<pre><code>mv old_name.txt new_name.html      ...      renames the file &quot;old_name.txt&quot; to &quot;new_name.html&quot;
</code></pre>
<h3 id="rm---remove"><a class="header" href="#rm---remove">rm - (remove)</a></h3>
<p>Deletes a file or directory.</p>
<pre><code>rm old_file.txt      ...      deletes the file &quot;old_file.txt&quot;
rm -r my_folder      ...      deletes a directory. The recursive modifier (-r) must always be used to delete a directory, as it specifies that the directory's contents should also be deleted.
</code></pre>
<h3 id="chmod---change-mode"><a class="header" href="#chmod---change-mode">chmod - (change mode)</a></h3>
<p>Changes file access permissions.</p>
<pre><code>chmod 777 /dev/ttyUSB0      ...      grants all users access to USB port 0. For details on file system permissions, see [7].
</code></pre>
<h3 id="sudo"><a class="header" href="#sudo">sudo</a></h3>
<p>A meta command. Operations executed with this command are performed with administrator privileges. Commonly used for modifying system files.</p>
<pre><code>sudo mkdir /etc/config      ...      creates a &quot;config&quot; directory in the system folder &quot;/etc&quot;.
sudo rm -r /                ...      recursively deletes the root directory (essentially wipes the entire disk, including the OS).
</code></pre>
<h3 id="cat---concatenate-files-to-standard-output"><a class="header" href="#cat---concatenate-files-to-standard-output">cat - (Concatenate FILE(s) to standard output)</a></h3>
<p>Displays the contents of a file in the terminal.</p>
<pre><code>cat ~/my_config_file.txt      ...      prints the contents of the specified file in the terminal
</code></pre>
<h3 id="man---manual-referenční-manuál-operačního-systému"><a class="header" href="#man---manual-referenční-manuál-operačního-systému">man - (manual) referenční manuál operačního systému</a></h3>
<p>Quick help if you forget how to use a specific program.</p>
<pre><code>man ls      ...      prints the manual for the &quot;ls&quot; program in the terminal
</code></pre>
<h3 id="linux-distributions"><a class="header" href="#linux-distributions">Linux Distributions</a></h3>
<p>When we talk about Linux, we refer to the kernel of the operating system, which is managed by an authority (its creator, Linus Torvalds) that ensures the integrity of all code integrated into the OS kernel.</p>
<p>Above the operating system kernel lies an additional layer of package management systems, graphical interfaces, and other supporting software. A &quot;distribution&quot; in Linux refers to a bundle of these supporting software components, provided and guaranteed by a specific legal entity (commercial company, organization, etc.).</p>
<p>Commonly used distributions:</p>
<ul>
<li>Debian - The most widespread Linux distribution.</li>
<li>Ubuntu - A derivative of Debian. The most popular distribution for home workstations.</li>
<li>Mint - A derivative of Ubuntu. Its GUI is similar to Windows.</li>
<li>RaspberryOS (formerly Raspbian) - A Debian derivative for Raspberry Pi.</li>
<li>Arch Linux - A distribution aimed at advanced users, offering great freedom in system configuration.</li>
<li>Fedora - An alternative to Debian.</li>
<li>ElementaryOS - A minimalist and fast distribution. Suitable for low-performance computers.</li>
<li>... and many more.</li>
</ul>
<h2 id="essential-programs"><a class="header" href="#essential-programs">Essential Programs</a></h2>
<h3 id="apt"><a class="header" href="#apt">apt</a></h3>
<p>This is Debian's package management system. On Linux, we typically install programs by downloading them from a public repository, which is usually a verified and secure server.</p>
<p>You always need administrative privileges to install programs.</p>
<p>Example of installing Git:</p>
<pre><code>sudo apt update
sudo apt install git
</code></pre>
<p>This means: &quot;With administrative privileges, run the apt program to update repository records&quot; and &quot;With administrative privileges, run the apt program to install Git.&quot;</p>
<h3 id="nano"><a class="header" href="#nano">nano</a></h3>
<p>A text editor similar to Notepad.</p>
<ul>
<li>Ctrl + X - Exits the program. It will ask if you want to save changes.</li>
</ul>
<h3 id="vim"><a class="header" href="#vim">vim</a></h3>
<p>A professional text editor. However, its operation is somewhat complex and requires an understanding of several principles. Working with vim is significantly faster than with nano. Before using it, it is recommended to go through any &quot;vim noob tutorial&quot; on YouTube.</p>
<p>If you accidentally open vim, you can close it with the key combination <strong>Shift + Z + Z</strong> (hold Shift and press 'Z' twice).</p>
<h3 id="mc"><a class="header" href="#mc">mc</a></h3>
<p><strong>Midnight Commander</strong> - A graphical interface for navigating the file system, resembling MS-DOS.</p>
<ul>
<li>Exits with the <strong>F10</strong> key.</li>
</ul>
<h3 id="curl"><a class="header" href="#curl">curl</a></h3>
<p>A command-line tool for transferring data using various protocols. Curl is often used for HTTP communication, installing programs, or downloading files.</p>
<h3 id="wget"><a class="header" href="#wget">wget</a></h3>
<p>A program for downloading files from the internet.
Example of downloading the latest WordPress release:</p>
<pre><code>wget https://wordpress.org/latest.zip
</code></pre>
<h2 id="final-words"><a class="header" href="#final-words">Final Words</a></h2>
<p>If you're new to Linux, don't be afraid to experiment. Ideally, install the system in VirtualBox and create a backup of the virtual disk. If you manage to mess up the system, simply restore the backup and continue working.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="c"><a class="header" href="#c">C++</a></h1>
<h2 id="warmup-quiz"><a class="header" href="#warmup-quiz">Warmup Quiz</a></h2>
<ol>
<li>What will be the output of the following code?</li>
</ol>
<pre><code class="language-c++">#include &lt;iostream&gt;
int main() {
    int x = 5;
    int* p = &amp;x;
    *p = 10;
    std::cout &lt;&lt; x &lt;&lt; '\n';
    return 0;
}
</code></pre>
<ol start="2">
<li>
<p>What does the <code>const</code> keyword do when applied to a variable?</p>
</li>
<li>
<p>What is the difference between <code>struct</code> and <code>class</code> in C++?</p>
</li>
<li>
<p>What is the purpose of a constructor in a class?</p>
</li>
<li>
<p>Explain the difference between the <code>pointer</code> and <code>reference</code>.</p>
</li>
<li>
<p>What will be the output of the following code?</p>
</li>
</ol>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;vector&gt;
int main() {
    std::vector&lt;int&gt; v = {1, 2, 3};
    for (auto it = v.begin(); it != v.end(); ++it) {
        std::cout &lt;&lt; *it &lt;&lt; &quot; &quot;;
    }
    return 0;
}
</code></pre>
<ol start="7">
<li>
<p>In your onw words, explain what is the Standard Template Library (STL).</p>
</li>
<li>
<p>What will be the output of the following code?</p>
</li>
</ol>
<pre><code class="language-c++">#include &lt;iostream&gt;
class Base {
public:
    virtual void print() {
        std::cout &lt;&lt; &quot;Base class\n&quot;;
    }
};

class Derived : public Base {
public:
    void print() override {
        std::cout &lt;&lt; &quot;Derived class\n&quot;;
    }
};

int main() {
    Base* b = new Derived();
    b-&gt;print();
    delete b;
    return 0;
}
</code></pre>
<ol start="9">
<li>
<p>Explain difference between <code>std::array&lt;T, N&gt;</code> and <code>std::vector&lt;T&gt;</code>.</p>
</li>
<li>
<p>Explain the output of following Lambda-function based code.</p>
</li>
</ol>
<pre><code class="language-c++">#include &lt;iostream&gt;
int main() {
    int a = 10, b = 20;
    auto sum = [&amp;]() -&gt; int { return a + b; };
    b = 30;
    std::cout &lt;&lt; sum() &lt;&lt; '\n';
    return 0;
}
</code></pre>
<h2 id="revisiting-fundamentals"><a class="header" href="#revisiting-fundamentals">Revisiting Fundamentals</a></h2>
<h3 id="functions-and-pointers"><a class="header" href="#functions-and-pointers">Functions and Pointers</a></h3>
<p>Functions are the building blocks of C++ programs, and pointers are fundamental for memory management. Let’s revisit these concepts with an example.&quot;</p>
<pre><code class="language-c++">#include &lt;iostream&gt;
void swap(int* a, int* b) {
    int temp = *a;
    *a = *b;
    *b = temp;
}

int main() {
    int x = 5, y = 10;
    std::cout &lt;&lt; &quot;Before swap: x = &quot; &lt;&lt; x &lt;&lt; &quot;, y = &quot; &lt;&lt; y &lt;&lt; '\n';
    swap(&amp;x, &amp;y);
    std::cout &lt;&lt; &quot;After swap: x = &quot; &lt;&lt; x &lt;&lt; &quot;, y = &quot; &lt;&lt; y &lt;&lt; '\n';
    return 0;
}
</code></pre>
<p>Discussion Points:</p>
<ul>
<li>What happens when you pass pointers versus values?</li>
<li>When would you use references instead of pointers?</li>
</ul>
<h3 id="object-oriented-programming-oop"><a class="header" href="#object-oriented-programming-oop">Object-Oriented Programming (OOP)</a></h3>
<p>Object-oriented programming is key to structuring large projects in C++. Let’s review how classes and inheritance work.</p>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;string&gt;

class BankAccount {
private:
    std::string owner;
    double balance;

public:
    BankAccount(const std::string&amp; owner, double balance) 
        : owner(owner), balance(balance) {}

    void deposit(double amount) {
        balance += amount;
    }

    void withdraw(double amount) {
        if (amount &lt;= balance)
            balance -= amount;
        else
            std::cout &lt;&lt; &quot;Insufficient funds!\n&quot;;
    }

    void display() const {
        std::cout &lt;&lt; owner &lt;&lt; &quot;'s balance: $&quot; &lt;&lt; balance &lt;&lt; '\n';
    }
};

int main() {
    BankAccount account(&quot;John Doe&quot;, 1000.0);
    account.display();
    account.deposit(500);
    account.withdraw(300);
    account.display();
    return 0;
}
</code></pre>
<p>Discussion Points:</p>
<ul>
<li>What is the purpose of the private keyword?</li>
<li>How does the const qualifier ensure safety in display()?</li>
</ul>
<h3 id="modern-c-features"><a class="header" href="#modern-c-features">Modern C++ Features</a></h3>
<p>Raw pointers are error-prone. Smart pointers, introduced in C++11, simplify memory management.</p>
<p><code>std::unique_ptr</code>: </p>
<ul>
<li>Exclusive ownership: only one std::unique_ptr can point to a resource at a time.</li>
</ul>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;memory&gt;

class MyClass {
public:
    MyClass(std::string name) : name_{name} { std::cout &lt;&lt; &quot;Constructor called &quot; + name_ &lt;&lt; std::endl; }
    ~MyClass() { std::cout &lt;&lt; &quot;Destructor called &quot; + name_ &lt;&lt; std::endl; }
private:
    std::string name_;
};

int main() {
    {   // Create a scope to demonstrate smart pointer behavior
        std::unique_ptr&lt;MyClass&gt; u_ptr = std::make_unique&lt;MyClass&gt;(&quot;unique&quot;);
        MyClass* raw_ptr = new MyClass(&quot;raw&quot;);
    }   // end of scope; u_ptr goes out of scope, destructor is called automatically
    // raw_ptr is not deleted, causing a potential memory leak
    
    return 0;
}
</code></pre>
<p><code>std::shared_ptr</code>: </p>
<ul>
<li>Shared ownership: multiple std::shared_ptr can point to the same resource.</li>
<li>Reference counting: the resource is deleted when the last std::shared_ptr goes out of scope.</li>
</ul>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;memory&gt;

class MyClass {
public:
    MyClass() { std::cout &lt;&lt; &quot;MyClass constructor\n&quot;; }
    ~MyClass() { std::cout &lt;&lt; &quot;MyClass destructor\n&quot;; }
};

int main() {
    std::shared_ptr&lt;MyClass&gt; sp1 = std::make_shared&lt;MyClass&gt;();
    std::cout &lt;&lt; &quot;Use count: &quot; &lt;&lt; sp1.use_count() &lt;&lt; std::endl;

    {
        std::shared_ptr&lt;MyClass&gt; sp2 = sp1; 
        std::cout &lt;&lt; &quot;Use count: &quot; &lt;&lt; sp1.use_count() &lt;&lt; std::endl;
    }

    std::cout &lt;&lt; &quot;Use count: &quot; &lt;&lt; sp1.use_count() &lt;&lt; std::endl;
    return 0;
}
</code></pre>
<p><code>std::weak_ptr</code></p>
<ul>
<li>Weak reference: does not affect the reference count of the shared resource.</li>
<li>Desn't increase the reference count.</li>
<li>Used to prevent circular references in shared ownership.</li>
</ul>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;memory&gt;

class NodeB; // forward declaration

class NodeA {
public:
    std::shared_ptr&lt;NodeB&gt; strong_ptr; // Strong reference to NodeB
    std::weak_ptr&lt;NodeB&gt; weak_ptr; // Strong reference to NodeA
    NodeA() { std::cout &lt;&lt; &quot;NodeStrong constructor\n&quot;; }
    ~NodeA() {  std::cout &lt;&lt; &quot;NodeStrong destructor\n&quot;;  }
};

class NodeB {
public:
    std::shared_ptr&lt;NodeA&gt; strong_ptr; // Strong reference to NodeA
    std::weak_ptr&lt;NodeA&gt; weak_ptr; // Strong reference to NodeA
    NodeB() { std::cout &lt;&lt; &quot;NodeWeak constructor&quot; &lt;&lt; std::endl; }
    ~NodeB() { std::cout &lt;&lt; &quot;NodeWeak destructor\n&quot;; }
};

int main() {

    { // create scope
        std::cout &lt;&lt; &quot;Entering first scope...&quot; &lt;&lt; std::endl;
        // Create NodeA and NodeB, each referencing the other.
        auto a = std::make_shared&lt;NodeA&gt;();
        auto b = std::make_shared&lt;NodeB&gt;();
        a-&gt;strong_ptr = b; // NodeA has a strong reference to b
        b-&gt;strong_ptr = a; // NodeB has a strong reference to a
        std::cout &lt;&lt; &quot;Exiting first scope...&quot; &lt;&lt; std::endl;
    } // end scope

    // Here, a and b go out of scope, but each Node holds a strong pointer to the other.
    // Their reference counts never reach zero, so destructors are NOT called.
    // This leads to a memory leak because NodeA and NodeB remain alive, referencing each other.

    { // create new scope
        std::cout &lt;&lt; &quot;Entering second scope...&quot; &lt;&lt; std::endl;
        auto a = std::make_shared&lt;NodeA&gt;();
        auto b = std::make_shared&lt;NodeB&gt;();
        a-&gt;strong_ptr = b; // NodeA has a strong reference to b
        b-&gt;weak_ptr = a; // NodeB has a weak reference to a
        std::cout &lt;&lt; &quot;Exiting second scope...&quot; &lt;&lt; std::endl;
    }
    
    return 0;
}
</code></pre>
<p>Discussion Points:</p>
<ul>
<li>What happens when the std::unique_ptr goes out of scope?</li>
<li>Compare std::shared_ptr and std::unique_ptr.</li>
<li>When should you use std::weak_ptr?</li>
<li>Should we use raw pointers in modern C++? ... No we should not!</li>
</ul>
<h3 id="functions-as-object"><a class="header" href="#functions-as-object">Functions as Object</a></h3>
<h3 id="lambda-functions"><a class="header" href="#lambda-functions">Lambda Functions</a></h3>
<p>Lambda functions (also called lambda expressions) in C++ are unnamed (anonymous) functions that you can define inline. They were introduced in C++11 to make it easier to create small, concise functions, especially for use with the Standard Template Library (STL) algorithms or as callbacks. Unlike regular functions, they can capture variables from their surrounding scope. This is incredibly useful for passing context to a function on-the-fly.</p>
<p>Syntax:</p>
<pre><code class="language-c++">[ capture_list ] ( parameter_list ) -&gt; return_type {
    // function body
}
</code></pre>
<ul>
<li>capture_list: Specifies which variables from the enclosing scope are available inside the lambda and how they are captured (by value, by reference, etc.).</li>
<li>parameter_list: The parameters the lambda accepts (similar to a function’s parameter list).</li>
<li>return_type: Often omitted because it can be deduced by the compiler, but can be specified explicitly using -&gt; return_type.</li>
<li>function body: The code that executes when the lambda is called.</li>
</ul>
<p>Example of lambda function usage:</p>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;algorithm&gt;

int main() {
    std::vector&lt;int&gt; nums = {5, 2, 8, 3, 1};

    std::sort(nums.begin(), nums.end(), [](int a, int b) { return a &lt; b; });

    for (int num : nums) {
        std::cout &lt;&lt; num &lt;&lt; ' ';
    }
    return 0;
}
</code></pre>
<p>Discussion Points:</p>
<ul>
<li>How does the lambda function work in std::sort?</li>
<li>When should you use lambdas over named functions?</li>
</ul>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;algorithm&gt;

int main() {
    std::vector&lt;int&gt; values = {1, 2, 3, 4, 5};
    int offset = 10;

    auto printValue = [](int val) {
        std::cout &lt;&lt; val &lt;&lt; &quot; &quot;;
    };

    // Capture everything by value (copy
    std::for_each(values.begin(), values.end(), [=](int val)  {
        // modifies copy of 'val', not `val` itself
        val += offset;
        // offset += 1; // error: 'offset' cannot be modified. Can use [=]() mutable {...} to modify
    });
    std::for_each(values.begin(), values.end(), printValue);

    // Capture everything by reference
    std::for_each(values.begin(), values.end(), [&amp;](int &amp;val) {
        val += offset; // modifies 'val' directly in the vector via reference
         offset += 1;
    });
    std::for_each(values.begin(), values.end(), printValue);
    
    std::cout &lt;&lt; std::endl;
    return 0;
}
</code></pre>
<h3 id="stdfunction"><a class="header" href="#stdfunction"><code>std::function</code></a></h3>
<p>A flexible, type-erased wrapper that can store function pointers, lambdas, or functor objects. It is part of the C++ Standard Library and is useful for creating callbacks or function objects that can be passed around like variables.</p>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;functional&gt;

int sum(int a, int b) {
    return a + b;
}

int main() {
    std::function&lt;int(int, int)&gt; func1 = sum;
    std::function&lt;int(int, int)&gt; func2 = [](int a, int b) { return a * b; };

    std::cout &lt;&lt; &quot;sum(3, 4): &quot; &lt;&lt; func1(3, 4) &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;multiply(3, 4): &quot; &lt;&lt; func2(3, 4) &lt;&lt; std::endl;

    return 0;
}
</code></pre>
<h3 id="coding-challenge"><a class="header" href="#coding-challenge">Coding Challenge</a></h3>
<p>Task: Create a simple program to manage student records, including adding and displaying students.</p>
<ul>
<li>Use a Student class with properties for name, age, and grades.</li>
<li>Store students in a std::vector.</li>
<li>Implement a menu-driven program for user interaction.</li>
</ul>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;string&gt;

class Student {
private:
    std::string name;
    int age;
    std::vector&lt;int&gt; grades;

public:
    Student(const std::string&amp; name, int age) : name(name), age(age) {}

    void addGrade(int grade) {
        grades.push_back(grade);
    }

    void display() const {
        std::cout &lt;&lt; &quot;Name: &quot; &lt;&lt; name &lt;&lt; &quot;, Age: &quot; &lt;&lt; age &lt;&lt; &quot;, Grades: &quot;;
        for (int grade : grades) {
            std::cout &lt;&lt; grade &lt;&lt; ' ';
        }
        std::cout &lt;&lt; '\n';
    }
};

int main() {
    std::vector&lt;Student&gt; students;

    // Add menu-driven functionality here
    return 0;
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cmake"><a class="header" href="#cmake">CMake</a></h1>
<p><a href="https://cmake.org/">CMake</a> is a set of tools that simplifies the compilation of projects and libraries in a way that makes them independent of the operating system and compiler. It works by using a unified configuration file, <code>CMakeLists.txt</code>, to generate a Makefile for UNIX-like systems or MSVC workspaces for Windows.</p>
<p>A major advantage of CMake is its dependency management. Applications can define the libraries they depend on, and CMake checks if these libraries are available and, importantly, if they meet the required version. Another significant benefit is the ability to create both executable files and libraries using a single, simple configuration in the <code>CMakeLists.txt</code> file.</p>
<p>One way to look at CMake is as another programming language - there are variables, functions, conditions and loops.
The way in which CMake is developed is emphatizing on using targets, because of that most function will begin by <code>target_</code> and the first argument will be target.
For some of them there is equivalent without it. These function are global and set the parameters, include directories etc. for the file.</p>
<h2 id="basic-example"><a class="header" href="#basic-example">Basic example</a></h2>
<p>Made up C++ project stucture:</p>
<pre><code>MyProject/
    include/
        movement/
            move.hpp
            turn.hpp
        talk.hpp
    src/
        movement/
            move.cpp
            turn.cpp
        talk.cpp
        main.cpp
    CMakeLists.txt
</code></pre>
<p>CMakeLists.txt:</p>
<pre><code class="language-cmake">cmake_minimum_required(VERSION 3.15)

project(MyProject VERSION 1.0
                  DESCRIPTION &quot;Very nice project&quot;
                  LANGUAGES CXX)
set(CXX_STANDARD 17) # Can also set custom variables

add_executable(MyProject src/main.cpp src/talk.cpp src/movement/move.cpp src/movement/turn.cpp)
target_include_directories(MyProject include)
</code></pre>
<p>Lets take a look at the file:</p>
<pre><code>cmake_minimum_required(VERSION 3.15)
</code></pre>
<p>First line tells cmake minimu required version for running the script.</p>
<pre><code>project(MyProject VERSION 1.0
                  DESCRIPTION &quot;Very nice project&quot;
                  LANGUAGES CXX)
</code></pre>
<p>Function <code>project</code> have one mandatory argument name of the project. Other arguments are optional. <code>VERSION</code> sets multiple cmake variables like PROJECT_VERSION. Default <code>LANGUAGE</code> is <code>C CXX</code>. The function does not create target <code>MyProject</code> which we will use in other functions.</p>
<pre><code>set(CXX_STANDARD 17)
</code></pre>
<p>This function call to set variable <code>CXX_STANDARD</code>.  This is the simplest way to set C++ standard, but it will set C++ standard globally to whole project. The others ways have little bit more flexibility.</p>
<pre><code>add_executable(MyProject src/main.cpp src/talk.cpp src/movement/move.cpp src/movement/turn.cpp)
</code></pre>
<p>Function target - executable, first argument is the name of target, others argument are all source files in the project. Header files can by also included, but by cmake they are ignored for compilation.</p>
<pre><code>target_include_directories(MyProject include)
</code></pre>
<p>Functions add include directories to target. Any other argument is assumed to be folder with header file.</p>
<h3 id="build-basic-example-project"><a class="header" href="#build-basic-example-project">Build basic example project</a></h3>
<p>To run the project:</p>
<pre><code class="language-shell">cd MyProject
mkdir build     #create folder build
cd build
cmake ..        #run cmake
make            #run make - build project
./MyCoolProject #run executable
</code></pre>
<p>For debuging (eg. <code>gdb</code>) add variable <code>CMAKE_BUILD_TYPE</code> with value <code>Debug</code> - When variable is not specified value used last time is run, if its first run value used is <code>Release</code></p>
<pre><code>cmake -DCMAKE_BUILD_TYPE=Debug ..
</code></pre>
<h2 id="including-libraries"><a class="header" href="#including-libraries">Including libraries</a></h2>
<p>This example assumes you have installed the library and it's only used to show bare basics, many external libraries have examples how to use and include them.</p>
<pre><code class="language-cmake">cmake_minimum_required(VERSION 3.15)
project(MyProject)

find_package( OpenCV REQUIRED ) #find library in the system path if not found cmake will fail

add_executable(MyProject main.cpp)

target_include_directories(MyProject ${OpenCV_INCLUDE_DIRS}) #adds include folders to target

target_link_libraries(MyProject ${OpenCV_LIBS}) #Link library to target
</code></pre>
<h2 id="resources"><a class="header" href="#resources">Resources</a></h2>
<p><a href="https://cliutils.gitlab.io/modern-cmake/README.html">An Introduction to Modern CMake</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="git---version-control-system"><a class="header" href="#git---version-control-system">Git - Version Control System</a></h1>
<p>Git is a distributed system for versioning and managing backups of source code. However, Git also works well for versioning any kind of text. The primary motivation for teaching Git in this course is the fact that Git is the most widely used version control system in the commercial sphere today, and there is a vast array of Git-based online version control services available on the web.</p>
<hr />
<h2 id="basic-terminology"><a class="header" href="#basic-terminology">Basic Terminology</a></h2>
<p>Let’s define some basic terms to ensure we’re on the same page.</p>
<h3 id="repository-repo"><a class="header" href="#repository-repo">Repository (repo)</a></h3>
<p>A set of versioned files and records of their history. If the repository is stored on our computer, it is called a local repository (local repo). If it is stored on another machine, it is referred to as a remote repository (remote repo).</p>
<h3 id="cloning"><a class="header" href="#cloning">Cloning</a></h3>
<p>Downloading a repository from a remote repo. Cloning occurs when the repository does not yet exist on the local machine.</p>
<h3 id="snapshot"><a class="header" href="#snapshot">Snapshot</a></h3>
<p>The state of the repository at a specific point in its history.</p>
<h3 id="diff"><a class="header" href="#diff">Diff</a></h3>
<p>The difference between two snapshots, i.e., the changes in the state of versioned files.</p>
<h3 id="commit"><a class="header" href="#commit">Commit</a></h3>
<p>A record that contains a reference to the previous and next snapshot, as well as the diff between them. Each commit has a unique 20-byte hash that identifies it within the repository.</p>
<h3 id="push"><a class="header" href="#push">Push</a></h3>
<p>Uploading new commits to the remote repository.</p>
<h3 id="fetch"><a class="header" href="#fetch">Fetch</a></h3>
<p>Downloading commits from a remote repo to the local machine. Fetching is done when the local repository is already cloned but does not have the latest commits downloaded.</p>
<h3 id="branch"><a class="header" href="#branch">Branch</a></h3>
<p>A sequence of interconnected commits. By default, every repository has one branch (typically named &quot;master&quot; or &quot;main&quot;). If multiple features are being developed simultaneously, these developments can be divided into separate branches and merged back into the main branch once the feature is complete.</p>
<h2 id="how-git-works"><a class="header" href="#how-git-works">How Git Works</a></h2>
<p>The primary function of Git is versioning text files. It is important to note that Git is NOT suitable for versioning binary files. When developing a program and using Git for version control, you should always version source code only, never compiled executable files (binaries).</p>
<p>Git also enables highly efficient collaboration among multiple people working on the same project (repository). Developers can work together or individually on separate branches. However, a key rule is that two people must not overwrite the same line of code in two different commits, as this will cause a conflict. A general recommendation is that two people should avoid modifying the same file.</p>
<p>Unlike SVN, Git is a decentralized system. This means there is no superior, central repository or server. All repositories have the same functionality, can maintain the full history of the project, and can seamlessly communicate with all other clones. In practice, however, there is often a repository that acts as a central point for sharing commits between developers, commonly referred to as &quot;origin&quot;.</p>
<p>It is important to note that any repository can download the complete history from the origin. In the event of an origin failure, no data is lost, as each developer has a complete copy of the repository on their computer.</p>
<hr />
<h3 id="typical-workflow-with-git"><a class="header" href="#typical-workflow-with-git">Typical Workflow with Git:</a></h3>
<ol>
<li>A repository is created on the server for the project.</li>
<li>Developers clone the repository to their local machines. From their perspective, the server is referred to as &quot;origin&quot;.</li>
<li>Developers work on their local machines, creating code and committing changes.</li>
<li>At the end of the day, each developer pushes their daily commits to the origin.</li>
<li>The next morning, each developer fetches the commits from their colleagues made the previous day.</li>
</ol>
<hr />
<h2 id="installing-git-on-linux"><a class="header" href="#installing-git-on-linux">Installing Git on Linux</a></h2>
<p>If you are using a Debian-based distribution, Git can be installed using the following commands:</p>
<pre><code class="language-bash">sudo apt install git
</code></pre>
<p>or</p>
<pre><code class="language-bash">sudo snap install git
</code></pre>
<h2 id="command-overview"><a class="header" href="#command-overview">Command Overview</a></h2>
<h3 id="git-init"><a class="header" href="#git-init">git init</a></h3>
<p>Initializes a repository, turning a regular folder in the file system into a repository. A repository differs from a regular folder because it contains a hidden <code>.git</code> folder that stores the repository's history.</p>
<pre><code class="language-bash">git init     # Initializes a repository
</code></pre>
<hr />
<h3 id="git-add"><a class="header" href="#git-add">git add</a></h3>
<p>Adds changes made since the last commit to the index. The index is a staging area where changes are prepared for the next commit. This allows selective inclusion of changes in a commit.</p>
<pre><code class="language-bash">git add myfile.txt     # Adds changes made to 'myfile.txt' to the index
git add .              # Adds all current changes to the index
</code></pre>
<hr />
<h3 id="git-commit"><a class="header" href="#git-commit">git commit</a></h3>
<p>Creates a new commit derived from the last commit in the current branch. Includes changes (diffs) staged in the index.</p>
<pre><code class="language-bash">git commit -m &quot;Commit message&quot;     # Creates a new commit in the current branch
</code></pre>
<hr />
<h3 id="git-checkout"><a class="header" href="#git-checkout">git checkout</a></h3>
<p>Switches between snapshots.</p>
<pre><code class="language-bash">git checkout .          # Reverts the branch to the last commit, discarding all changes
git checkout abcdef     # Switches to the state after commit 'abcdef'
git checkout master     # Switches to the last available commit in the 'master' branch
</code></pre>
<hr />
<h3 id="git-clone"><a class="header" href="#git-clone">git clone</a></h3>
<p>Creates a local clone of a remote repository. No need to initialize with <code>git init</code>, as repository metadata is automatically downloaded along with the content.</p>
<pre><code class="language-bash">git clone https://remote_repo_address.git     # Clones the repository to the local machine
</code></pre>
<hr />
<h3 id="git-remote"><a class="header" href="#git-remote">git remote</a></h3>
<p>Manages connections to remote repositories.</p>
<pre><code class="language-bash">git remote -v                                            # Lists the configuration of remote repositories
git remote add origin https://remote_repo_address.git    # Adds a remote alias named 'origin'
git remote remove origin                                 # Removes the 'origin' alias
</code></pre>
<hr />
<h3 id="git-push"><a class="header" href="#git-push">git push</a></h3>
<p>Uploads new commits from the local repository to the remote repository.</p>
<pre><code class="language-bash">git push origin master     # Pushes new commits from the 'master' branch to the remote repository
</code></pre>
<hr />
<h3 id="git-fetch"><a class="header" href="#git-fetch">git fetch</a></h3>
<p>Downloads commits from the remote repository to the local repository. These commits are not automatically merged into the current branch.</p>
<pre><code class="language-bash">git fetch origin           # Fetches all new commits from all branches of the 'origin'
git fetch origin master    # Fetches new commits for the 'master' branch from the 'origin'
</code></pre>
<hr />
<h3 id="git-merge"><a class="header" href="#git-merge">git merge</a></h3>
<p>Creates a new commit in the current branch by merging changes from another branch, combining all their changes.</p>
<pre><code class="language-bash">git merge cool_branch        # Merges the changes from 'cool_branch' into the current branch
</code></pre>
<hr />
<h3 id="git-pull"><a class="header" href="#git-pull">git pull</a></h3>
<p>Combines <code>git fetch</code> and <code>git merge</code>. Commonly used to pull changes from a remote repository. It fetches commits from the remote repository and then merges them into the current branch.</p>
<pre><code class="language-bash">git pull origin master        # Fetches and merges commits from 'master' branch of 'origin'
</code></pre>
<hr />
<h3 id="git-diff"><a class="header" href="#git-diff">git diff</a></h3>
<p>Displays the difference between two snapshots (commits).</p>
<pre><code class="language-bash">git diff abcdef 012345        # Shows the difference between commits 'abcdef' and '012345'
</code></pre>
<hr />
<h3 id="git-status"><a class="header" href="#git-status">git status</a></h3>
<p>Shows the current state of changes since the last commit, including changes already staged in the index.</p>
<pre><code class="language-bash">git status        # Displays the current state of changes
</code></pre>
<hr />
<h3 id="git-log"><a class="header" href="#git-log">git log</a></h3>
<p>Displays a chronological history of commits along with their metadata (timestamp, commit message, hash, etc.).</p>
<pre><code class="language-bash">git log        # Displays the history of the current branch
</code></pre>
<hr />
<h3 id="git-stash"><a class="header" href="#git-stash">git stash</a></h3>
<p>Saves and retrieves changes to/from a stack. Useful when you realize you are working on the wrong branch. Changes can be stashed, allowing you to switch branches and reapply the changes later.</p>
<pre><code class="language-bash">git stash        # Saves changes to the stack and reverts the branch to its state after the last commit
git stash pop    # Retrieves changes from the stack and applies them to the current state
</code></pre>
<h2 id="exercise-3"><a class="header" href="#exercise-3">Exercise</a></h2>
<h3 id="basic-operations"><a class="header" href="#basic-operations">Basic Operations</a></h3>
<ol>
<li>Create a repository.</li>
<li>Create two text files in the repository and write a few lines in each.</li>
<li>Add the changes to the index and then commit them.</li>
<li>Edit one of the files and commit the changes.</li>
<li>Edit the second file and commit the changes.</li>
<li>Create an account on <a href="https://github.com">GitHub</a> and create a new repository there.</li>
<li>Add the remote repository as &quot;origin&quot; to your local repository and push the changes to the origin.</li>
<li>Verify the repository's contents in the GitHub web interface.</li>
<li>On another location on your computer, or on a different computer, clone the repository you just pushed.</li>
<li>In the new clone, make a change, commit it, and push it to the origin.</li>
<li>In the original folder, pull the new commits from the origin.</li>
<li>Use the <code>git log</code> command to view the commit history.</li>
</ol>
<hr />
<h3 id="conflict"><a class="header" href="#conflict">Conflict</a></h3>
<p>An example of what happens when two developers change the same code.</p>
<ol>
<li>Following the steps from the previous exercise, create two copies of the repository on the same computer or two different computers, both with the same origin on GitHub.</li>
<li>In the first clone, modify a specific line in a file, commit the change, and push it to the origin.</li>
<li>In the second clone, modify the same line, commit the change, and try to push (this will result in an error).</li>
<li>A conflict has been created. Two conflicting changes occurred at the same point in the repository's branch history.</li>
<li>Resolve the conflict by pulling from the origin in the second clone where the push failed.</li>
<li>Open the file containing the conflict. The conflict will be marked with special syntax:
<pre><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; local_change
=======
change_from_origin
&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</code></pre>
Choose the desired version, remove the conflict markers, and save the file. The conflict is now resolved.</li>
<li>Run the <code>git commit</code> command without additional parameters to commit the resolved conflict. An automatic commit message will indicate that this is a conflict resolution.</li>
<li>Push the new commit to the origin, then pull it into the original repository.</li>
<li>Use the <code>git log</code> command to view the commit history.</li>
</ol>
<h2 id="other-resources"><a class="header" href="#other-resources">Other Resources</a></h2>
<ul>
<li><a href="https://education.github.com/git-cheat-sheet-education.pdf">Git Cheat Sheet</a></li>
<li><a href="https://atlassian.com">Atlassian Tutorial</a></li>
<li><a href="https://git.com">Official Documentation</a></li>
<li><a href="https://ohshitgit.com/">Helpful Advisor</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="clion"><a class="header" href="#clion">CLion</a></h1>
<p>CLion is a program made by JetBrains that helps people write and test code. It is similar to other coding programs like Eclipse or NetBeans but is faster, easier to use, and looks more modern.</p>
<p>Because CLion is part of the JetBrains family, users can add extra tools and languages by installing plugins. It also has built-in support for Git, which helps with managing code changes.</p>
<p>This guide explains how to use CLion for the BPC-PRP course. It starts with a short introduction to CMake, a tool used to build programs. Then, it explains how to install CLion, create a simple &quot;Hello World&quot; program, and run it.</p>
<p>The examples in this guide use CLion version 2024.3.3, so some steps might be different in newer versions.</p>
<h2 id="clion-installation"><a class="header" href="#clion-installation">CLion Installation</a></h2>
<p>There are two ways to install CLion</p>
<ul>
<li><code>sudo snap install clion --classic</code> in command line</li>
<li>download software from https://www.jetbrains.com/clion/.</li>
</ul>
<p>Students can use the full version for free while they are studying. Just request the student licence at the web.</p>
<h2 id="hello-world-project"><a class="header" href="#hello-world-project">Hello World Project</a></h2>
<p>Let's make a simple Hello World project to learn how to create a project, use the CLion environment, and develop on a local computer.</p>
<p>When you open CLion, you will see a welcome screen with a list of your recent projects. To start a new project, click the &quot;New Project&quot; button.</p>
<p><img src="4_others/text/../images/clion_welcome.png" alt="Welcome screen" /></p>
<p>After clicking &quot;New Project&quot;, a window will open where you can set up your project. Here, you can choose where to save the project and select the C++ language standard. For this guide, we will use C++17.</p>
<p><img src="4_others/text/../images/clion_new_project.png" alt="Creating a project" /></p>
<p>After clicking &quot;Create,&quot; CLion will open the development environment, where you can start working on your project. The interface will look similar to the image below.</p>
<p><img src="4_others/text/../images/clion_home.png" alt="IDE" /></p>
<p>Let's take a closer look at the different parts of the screen and what they do.</p>
<ul>
<li>On the left, there is project overview pane</li>
<li>In the center there is the source code editor</li>
<li>Above the source code, there is a debug/release picker, program picker and build, run and bebug buttons.</li>
<li>Icons on the left bottom are CMake, Services, Terminal, Problems and Version Control.</li>
</ul>
<p>When the program starts, the console window appears, displaying the program's output. This is where you can see messages from your code, such as the &quot;Hello, World!&quot; text printed by your program. If there are any errors, they will also appear here, helping you debug your code.</p>
<p><img src="4_others/text/../images/clion_program_terminal.png" alt="Program console" /></p>
<p>If porogram debug started, the debug console and related controls appears.</p>
<p><img src="4_others/text/../images/clion_debug.png" alt="IDE description" /></p>
<h2 id="integrated-tutorial"><a class="header" href="#integrated-tutorial">Integrated Tutorial</a></h2>
<p>The current CLion version contains the onboarding tutorial. Follow it to learn more.</p>
<p><img src="4_others/text/../images/clion_tutorial.png" alt="CLion Tutorial" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multithreading"><a class="header" href="#multithreading">Multithreading</a></h1>
<h2 id="motivation"><a class="header" href="#motivation">Motivation</a></h2>
<p>Why use multiple threads?</p>
<ul>
<li>Modern CPUs have multiple cores; using multiple threads can improve performance by performing tasks in parallel.</li>
<li>Some tasks, like handling multiple network connections, benefit from concurrent operations to remain responsive.</li>
</ul>
<p>Key Concepts</p>
<ul>
<li>Concurrency vs. Parallelism:
<ul>
<li>Concurrency is the composition of independently executing processes or threads.</li>
<li>Parallelism is the simultaneous execution of (possibly related) computations, using multiple physical CPU cores.</li>
</ul>
</li>
<li>Threads: A thread is the smallest sequence of programmed instructions that can be managed independently by a scheduler.</li>
</ul>
<h2 id="risks--challenges-of-multithreading"><a class="header" href="#risks--challenges-of-multithreading">Risks &amp; Challenges of Multithreading</a></h2>
<ul>
<li>Data Races: Two or more threads access a shared variable without proper synchronization, and at least one thread writes to the variable.</li>
<li>Deadlocks: Two or more threads are blocked forever, each waiting for the other to release a resource.</li>
<li>Race Conditions: A program’s outcome depends on the sequence of events or timings of threads.</li>
<li>Complexity: Debugging and reasoning about concurrent programs is generally harder than single-threaded ones.</li>
</ul>
<h2 id="basic-thread-creation-and-management"><a class="header" href="#basic-thread-creation-and-management">Basic Thread Creation and Management</a></h2>
<h3 id="the-thread-header"><a class="header" href="#the-thread-header">The <code>&lt;thread&gt;</code> Header</a></h3>
<p>Modern C++ (C++11 and above) provides a standard way to create and manage threads through the <code>&lt;thread&gt;</code> header.</p>
<pre><code class="language-c++">// Example 1: Creating a Simple Thread
#include &lt;iostream&gt;
#include &lt;thread&gt;

void helloFunction() {
    std::cout &lt;&lt; &quot;Hello from thread!\n&quot;;
}

int main() {
    std::thread t(helloFunction); // Create a thread running helloFunction
    t.join();                     // Wait for the thread to finish
    std::cout &lt;&lt; &quot;Hello from main!\n&quot;;
    return 0;
}
</code></pre>
<p>Explanation:</p>
<ul>
<li><code>std::thread t(helloFunction);</code> creates a new thread that executes <code>helloFunction</code>.</li>
<li><code>t.join();</code> ensures the main thread waits until <code>t</code> finishes.</li>
<li>If you omit <code>t.join()</code>, the program may exit before the thread finishes, or you must call <code>t.detach()</code> if you intend the thread to run independently.</li>
</ul>
<h3 id="lambda-functions-with-threads"><a class="header" href="#lambda-functions-with-threads">Lambda Functions with Threads</a></h3>
<p>Instead of passing a function pointer, you can also pass a lambda:</p>
<pre><code class="language-c++">// Example 2: Using a Lambda
#include &lt;iostream&gt;
#include &lt;thread&gt;

int main() {
    std::thread t([](){
        std::cout &lt;&lt; &quot;Hello from a lambda thread!\n&quot;;
    });

    t.join();
    std::cout &lt;&lt; &quot;Hello from main!\n&quot;;
    return 0;
}
</code></pre>
<h3 id="passing-arguments-to-threads"><a class="header" href="#passing-arguments-to-threads">Passing Arguments to Threads</a></h3>
<p>You can pass arguments to the thread function by specifying them after the callable:</p>
<pre><code class="language-c++">// Example 3: Passing Arguments
#include &lt;iostream&gt;
#include &lt;thread&gt;

void printValue(int x) {
    std::cout &lt;&lt; &quot;Value: &quot; &lt;&lt; x &lt;&lt; &quot;\n&quot;;
}

int main() {
    int num = 42;
    std::thread t(printValue, num);
    t.join();
    return 0;
}
</code></pre>
<p>Note: Arguments are passed by value by default. To pass references, use std::ref().</p>
<h3 id="detaching-threads"><a class="header" href="#detaching-threads">Detaching Threads</a></h3>
<ul>
<li><code>t.detach()</code> makes the thread run independently; the main thread does not wait for it.</li>
<li>Use with caution: A detached thread can lead to tricky bugs if you rely on shared data in it.</li>
</ul>
<h2 id="synchronization-mechanisms"><a class="header" href="#synchronization-mechanisms">Synchronization Mechanisms</a></h2>
<h3 id="mutex-and-lock-guards"><a class="header" href="#mutex-and-lock-guards">Mutex and Lock Guards</a></h3>
<p>To avoid data races, you typically protect shared data with a mutex. Only one thread can lock a mutex at a time.</p>
<pre><code class="language-c++">`
// Example 4: Using std::mutex and std::lock_guard
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;mutex&gt;
#include &lt;vector&gt;

std::mutex m;
int sharedCounter = 0;

void increment(int iterations) {
    for(int i = 0; i &lt; iterations; ++i) {
        // Lock the mutex before modifying shared resource
        std::lock_guard&lt;std::mutex&gt; lock(m);
        ++sharedCounter;
    }
}

int main() {
    std::vector&lt;std::thread&gt; threads;
    for(int i = 0; i &lt; 5; ++i) {
        threads.emplace_back(increment, 10000);
    }

    for(auto&amp; t : threads) {
        t.join();
    }

    std::cout &lt;&lt; &quot;Final value of sharedCounter: &quot; &lt;&lt; sharedCounter &lt;&lt; &quot;\n&quot;;
    return 0;
}

</code></pre>
<p>Important Points:</p>
<ul>
<li><code>std::lock_guard&lt;std::mutex&gt;</code> automatically locks the mutex upon creation and unlocks it when it goes out of scope.</li>
<li>This prevents forgetting to unlock, especially in the presence of exceptions or multiple return statements.</li>
</ul>
<h3 id="unique-lock"><a class="header" href="#unique-lock">Unique Lock</a></h3>
<p><code>std::unique_lock&lt;std::mutex&gt;</code> is more flexible than std::lock_guard, allowing you to lock/unlock explicitly.</p>
<h3 id="condition-variables"><a class="header" href="#condition-variables">Condition Variables</a></h3>
<ul>
<li>Condition variables allow threads to wait (block) until they are notified that some condition is true.</li>
<li>They typically work with a mutex to ensure correct data access.</li>
</ul>
<pre><code class="language-c++">// Example 5: Producer-Consumer with Condition Variables
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;mutex&gt;
#include &lt;condition_variable&gt;
#include &lt;queue&gt;

std::mutex mtx;
std::condition_variable cv;
std::queue&lt;int&gt; dataQueue;
bool finished = false;

void producer() {
    for(int i = 1; i &lt;= 5; ++i) {
        {
            std::lock_guard&lt;std::mutex&gt; lock(mtx);
            dataQueue.push(i);
            std::cout &lt;&lt; &quot;Produced: &quot; &lt;&lt; i &lt;&lt; &quot;\n&quot;;
        }
        cv.notify_one(); // Notify one waiting thread
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
    }

    // Signal that production is finished
    {
        std::lock_guard&lt;std::mutex&gt; lock(mtx);
        finished = true;
    }
    cv.notify_all();
}

void consumer() {
    while(true) {
        std::unique_lock&lt;std::mutex&gt; lock(mtx);
        cv.wait(lock, []{ return !dataQueue.empty() || finished; });
        if(!dataQueue.empty()) {
            int value = dataQueue.front();
            dataQueue.pop();
            std::cout &lt;&lt; &quot;Consumed: &quot; &lt;&lt; value &lt;&lt; &quot;\n&quot;;
        }
        else if(finished) {
            break; // No more data
        }
    }
}

int main() {
    std::thread prod(producer);
    std::thread cons(consumer);

    prod.join();
    cons.join();

    return 0;
}

</code></pre>
<p>Explanation:</p>
<ul>
<li>The producer thread pushes data to <code>dataQueue</code> and notifies the consumer.</li>
<li>The consumer thread waits (<code>cv.wait</code>) until it is notified that either new data is available or production is finished.</li>
<li><code>cv.wait(lock, condition)</code> atomically unlocks the mutex and sleeps until <code>condition</code> is true, then locks the mutex again before returning.</li>
</ul>
<h3 id="atomic-operations"><a class="header" href="#atomic-operations">Atomic Operations</a></h3>
<p>For simple operations like incrementing a counter, you can use <code>std::atomic</code> instead of a mutex:</p>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;atomic&gt;
#include &lt;vector&gt;

std::atomic&lt;int&gt; sharedCounter(0);

void increment(int iterations) {
    for(int i = 0; i &lt; iterations; ++i) {
        ++sharedCounter;
    }
}

int main() {
    const int threadCount = 5;
    std::vector&lt;std::thread&gt; threads;

    for(int i = 0; i &lt; threadCount; ++i) {
        threads.emplace_back(increment, 10000);
    }

    for(auto&amp; t : threads) {
        t.join();
    }

    std::cout &lt;&lt; &quot;Final Counter: &quot; &lt;&lt; sharedCounter.load() &lt;&lt; &quot;\n&quot;;
    return 0;
}

</code></pre>
<p>Note: Atomic operations are typically more efficient than locking but only suitable for simple scenarios (increment, bitwise operations, etc.).</p>
<h2 id="practical-examples-and-exercise-ideas"><a class="header" href="#practical-examples-and-exercise-ideas">Practical Examples and Exercise Ideas</a></h2>
<h3 id="summation-of-large-array-in-parallel"><a class="header" href="#summation-of-large-array-in-parallel">Summation of Large Array in Parallel</a></h3>
<p>One common pattern is to split a task into chunks that multiple threads work on.</p>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;
#include &lt;numeric&gt;

void partialSum(const std::vector&lt;int&gt;&amp; data, int start, int end, long long&amp; result) {
    long long sum = 0;
    for(int i = start; i &lt; end; ++i) {
        sum += data[i];
    }
    result = sum;
}

int main() {
    // Example data
    std::vector&lt;int&gt; data(1000000, 1); // 1 million elements of value 1

    long long result1 = 0, result2 = 0;
    int mid = data.size() / 2;

    // Create 2 threads to handle half the data each
    std::thread t1(partialSum, std::cref(data), 0, mid, std::ref(result1));
    std::thread t2(partialSum, std::cref(data), mid, data.size(), std::ref(result2));

    t1.join();
    t2.join();

    long long total = result1 + result2;
    std::cout &lt;&lt; &quot;Total sum: &quot; &lt;&lt; total &lt;&lt; &quot;\n&quot;;
    return 0;
}
</code></pre>
<h3 id="exercise-extend-the-summation"><a class="header" href="#exercise-extend-the-summation">Exercise: Extend the Summation</a></h3>
<ul>
<li>Modify the code to use four threads instead of two.</li>
<li>Compare performance for different numbers of threads and array sizes.</li>
<li>Explore usage of std::mutex or <code>std::atomic&lt;long long&gt;</code> if you want to accumulate into a single variable, but be mindful of performance overheads.</li>
</ul>
<h3 id="exercise-calculate-pi-using-multiple-threads"><a class="header" href="#exercise-calculate-pi-using-multiple-threads">Exercise: Calculate Pi Using Multiple Threads</a></h3>
<ul>
<li>Create multiple threads to estimate π by generating random points in a square and checking how many fall within the unit circle (Monte Carlo method).</li>
<li>Each thread returns the count of points inside the circle; combine results in the main thread and compute the approximation of π. </li>
<li>Compare performance with different thread counts.</li>
</ul>
<h3 id="tips-and-best-practices"><a class="header" href="#tips-and-best-practices">Tips and Best Practices</a></h3>
<ul>
<li>
<p>Limit shared data</p>
<ul>
<li>Minimize the portion of code that needs synchronization to reduce contention.</li>
</ul>
</li>
<li>
<p>Avoid excessive locking</p>
<ul>
<li>Use finer-grained locks or lock-free structures where applicable, but only if you fully understand the concurrency implications.</li>
</ul>
</li>
<li>
<p>Use high-level concurrency abstractions if possible</p>
<ul>
<li>For example, C++17’s std::async and std::future or higher-level frameworks can simplify concurrency.</li>
</ul>
</li>
<li>
<p>Always check for data races</p>
<ul>
<li>Tools like ThreadSanitizer can help detect concurrency issues.</li>
</ul>
</li>
<li>
<p>Understand memory model</p>
<ul>
<li>C++ has a well-defined memory model for atomic operations and synchronization.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rviz2-visualizations"><a class="header" href="#rviz2-visualizations">RViz2 Visualizations</a></h1>
<p>explain how render in rviz</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="coordinate-system"><a class="header" href="#coordinate-system">Coordinate System</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="communication-buses"><a class="header" href="#communication-buses">Communication Buses</a></h1>
<h2 id="uart"><a class="header" href="#uart">UART</a></h2>
<p>A UART (Universal Asynchronous Receiver/Transmitter) is a simple device used to send and receive data in a serial format. This means it sends information one bit at a time, rather than sending multiple bits at once. It is found in many microcontrollers and computers because it is easy to use and does not require many wires.</p>
<p>UART topology:
<img src="4_others/text/../images/uart.png" alt="UART" /></p>
<p>With UART, the sender and receiver do not share a special clock line. Instead, both sides must agree on a speed called the baud rate. This speed decides how many bits per second they will send or receive. If both sides use the same speed, data moves from one device to the other without confusion.</p>
<p>A UART usually has two main lines for data: TX (transmit) and RX (receive). When one device transmits through TX, the other device reads the signal on its RX pin. To avoid errors, UART systems often include extra settings such as start bits, stop bits, and parity bits. These help confirm that each bit is received in the correct order.</p>
<p>Although UART is slower than some other communication methods, it is very popular. It requires few pins, is easy to set up, and works well for many simple and medium-speed data transfers.</p>
<p>UART timing:
<img src="4_others/text/../images/uart_timing.png" alt="UART" /></p>
<p>image source: https://vanhunteradams.com/Protocols/UART/UART.html</p>
<h2 id="i2c"><a class="header" href="#i2c">I2C</a></h2>
<p>I2C (Inter-Integrated Circuit) is a simple method for digital devices to talk to each other using just two wires. One wire is called SDA, which carries data. The other wire is called SCL, which provides the clock signal. In I2C, devices use this clock signal to stay in sync, so they can send and receive data at the right time.</p>
<p>I2C topology:
<img src="4_others/text/../images/i2c.png" alt="I2C" /></p>
<p>I2C follows a master-slave setup. The master device generates the clock signal and decides when to start or stop a communication. It also chooses which slave device to talk to by using an address. Each slave device listens for its address, then responds when asked.</p>
<p>Because I2C only needs two wires, it is a good choice when you want to connect multiple sensors or peripherals without adding many extra pins. It is also fairly easy to set different speeds, so you can adjust it for your needs. Common speeds are known as Standard Mode (up to 100 kHz) and Fast Mode (up to 400 kHz).</p>
<p>I2C is often found in microcontroller projects, temperature sensors, and various other small components. It helps keep connections simple and allows many devices to share the same two wires for data transfer.</p>
<p>I2C timing:
<img src="4_others/text/../images/i2c_timing.png" alt="I2C Timing" /></p>
<p>image source: https://www.youtube.com/watch?v=CAvawEcxoPU</p>
<h2 id="spi"><a class="header" href="#spi">SPI</a></h2>
<p>SPI (Serial Peripheral Interface) is a simple and fast way for digital devices to communicate using at least four main lines. The first line is SCLK (serial clock), which sets the timing for data transfers. MOSI (master out, slave in) is used by the master device to send data out to the slave. MISO (master in, slave out) is used by the slave device to send data back to the master. Finally, SS (slave select) or CS (chip select) is used by the master to choose which slave device to talk to.</p>
<p>SPI topology:
<img src="4_others/text/../images/spi.png" alt="SPI" /></p>
<p>In an SPI setup, the master is in charge of generating the clock signal and deciding when data is sent or received. Data shifts on MOSI and MISO with each clock pulse, allowing both devices to exchange information at the same time. SPI does not use addresses like I2C, so each slave device normally has its own SS line. This can mean extra wiring if you have many devices.</p>
<p>SPI can run at higher speeds than many other serial interfaces, often reaching several megahertz or more. This makes it good for applications where you need fast data transfers, such as reading data from a sensor or writing to a display. Because it is straightforward and efficient, SPI is frequently used in microcontrollers, sensors, memory chips, and other peripherals that require rapid, reliable communication.</p>
<p>SPI timing:
<img src="4_others/text/../images/spi_timing.png" alt="SPI Timing" /></p>
<p>imabe source: https://www.youtube.com/watch?v=0nVNwozXsIc </p>
<h2 id="can"><a class="header" href="#can">CAN</a></h2>
<p>CAN (Controller Area Network) is a communication system originally designed for vehicles, allowing different parts of a car—like the engine, brakes, and airbags—to talk with each other in a reliable way. It uses two main wires, often called CAN High and CAN Low, which together form a robust bus. Unlike protocols that need a separate line for every device, CAN allows multiple nodes to share the same pair of wires.</p>
<p>CAN topology:
<img src="4_others/text/../images/can.png" alt="CAN" /></p>
<p>In a CAN network, any node can send a message whenever the bus is free. Each message has an identifier that shows its priority. If two nodes try to send messages at the same time, the node with the higher-priority message keeps sending, and the lower-priority message waits, ensuring important signals go first. This makes CAN useful in safety-critical systems.</p>
<p>CAN also includes error detection features. For example, if a node reads back a wrong bit, it flags an error and can resend the message. Because of its high reliability and simplicity, CAN is widely used not only in automobiles but also in industrial equipment, medical devices, and other areas that need dependable data sharing.</p>
<p>CAN data frame:
<img src="4_others/text/../images/can_frame.png" alt="CAN Frame" /></p>
<p>image source: https://en.wikipedia.org</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ubuntu-environment"><a class="header" href="#ubuntu-environment">Ubuntu Environment</a></h1>
<p>This guide provides step-by-step instructions for setting up the system, installing essential tools, and configuring the environment for ROS2.</p>
<pre><code class="language-shell">sudo apt update
sudo apt upgrade

#swap
sudo fallocate -l 16G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
sudo swapon --show


# basic installs
sudo apt install vim git htop cmake build-essential clang net-tools -y openssh-server mc tree

# ROS2
locale  # check for UTF-8
sudo apt update &amp;&amp; sudo apt install locales
sudo locale-gen en_US en_US.UTF-8
sudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8
export LANG=en_US.UTF-8
locale  # verify settings

sudo apt install software-properties-common
sudo add-apt-repository universe

sudo apt update &amp;&amp; sudo apt install curl -y
sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg

echo &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release &amp;&amp; echo $UBUNTU_CODENAME) main&quot; | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null

sudo apt update
sudo apt upgrade
sudo apt install ros-humble-desktop
sudo apt install ros-dev-tools

sudo snap install code --classic
sudo snap install clion --classic
sudo snap install pycharm-community --classic
sudo snap install rustrover --classic

sudo apt update
sudo apt install ros-humble-image-transport-plugins -y

</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
                        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
                
    </body>
</html>
